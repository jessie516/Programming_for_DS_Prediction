{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b49464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc97e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2db4f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>BSR</th>\n",
       "      <th>Active Sellers #</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review Count</th>\n",
       "      <th>Images</th>\n",
       "      <th>Review velocity</th>\n",
       "      <th>Buy Box</th>\n",
       "      <th>...</th>\n",
       "      <th>Size Tier_Large Envelope</th>\n",
       "      <th>Size Tier_Large Letter</th>\n",
       "      <th>Size Tier_Large Oversize</th>\n",
       "      <th>Size Tier_Small Envelope</th>\n",
       "      <th>Size Tier_Small Oversize</th>\n",
       "      <th>Size Tier_Standard Envelope</th>\n",
       "      <th>Size Tier_Standard Parcel</th>\n",
       "      <th>Delivery_AMZ</th>\n",
       "      <th>Delivery_FBA</th>\n",
       "      <th>Delivery_MFN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>789</td>\n",
       "      <td>0.592125</td>\n",
       "      <td>1277</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.435086</td>\n",
       "      <td>1.010296</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278</td>\n",
       "      <td>-0.469718</td>\n",
       "      <td>10791</td>\n",
       "      <td>84</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.612788</td>\n",
       "      <td>1.352821</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>918</td>\n",
       "      <td>-0.343520</td>\n",
       "      <td>5111</td>\n",
       "      <td>179</td>\n",
       "      <td>1.281295</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.101895</td>\n",
       "      <td>-0.359806</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>894</td>\n",
       "      <td>-0.980881</td>\n",
       "      <td>99</td>\n",
       "      <td>15109</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>4</td>\n",
       "      <td>0.260913</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>588</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>894</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>122</td>\n",
       "      <td>7974</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>4</td>\n",
       "      <td>1.023550</td>\n",
       "      <td>0.325245</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>588</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>364</td>\n",
       "      <td>-0.470992</td>\n",
       "      <td>233</td>\n",
       "      <td>6768</td>\n",
       "      <td>0.670690</td>\n",
       "      <td>5</td>\n",
       "      <td>0.327551</td>\n",
       "      <td>0.325245</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>257</td>\n",
       "      <td>-0.725936</td>\n",
       "      <td>227</td>\n",
       "      <td>8054</td>\n",
       "      <td>1.891900</td>\n",
       "      <td>5</td>\n",
       "      <td>0.727380</td>\n",
       "      <td>-0.359806</td>\n",
       "      <td>0.212053</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>28</td>\n",
       "      <td>0.676256</td>\n",
       "      <td>340</td>\n",
       "      <td>6364</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>4</td>\n",
       "      <td>2.045335</td>\n",
       "      <td>1.010296</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>438</td>\n",
       "      <td>0.613795</td>\n",
       "      <td>162</td>\n",
       "      <td>6418</td>\n",
       "      <td>-0.550521</td>\n",
       "      <td>5</td>\n",
       "      <td>3.311460</td>\n",
       "      <td>-0.017280</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>227</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>135</td>\n",
       "      <td>-1.253671</td>\n",
       "      <td>208</td>\n",
       "      <td>7443</td>\n",
       "      <td>3.113110</td>\n",
       "      <td>4</td>\n",
       "      <td>1.312315</td>\n",
       "      <td>1.010296</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2002 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand     Price  Sales    BSR  Active Sellers #  Ratings  Review Count  \\\n",
       "0       789  0.592125   1277     59         -0.550521        5     -0.435086   \n",
       "1       278 -0.469718  10791     84         -0.550521        0     -0.612788   \n",
       "2       918 -0.343520   5111    179          1.281295        5     -0.101895   \n",
       "3       894 -0.980881     99  15109         -0.550521        4      0.260913   \n",
       "4       894  0.038896    122   7974         -0.550521        4      1.023550   \n",
       "...     ...       ...    ...    ...               ...      ...           ...   \n",
       "1997    364 -0.470992    233   6768          0.670690        5      0.327551   \n",
       "1998    257 -0.725936    227   8054          1.891900        5      0.727380   \n",
       "1999     28  0.676256    340   6364         -0.550521        4      2.045335   \n",
       "2000    438  0.613795    162   6418         -0.550521        5      3.311460   \n",
       "2001    135 -1.253671    208   7443          3.113110        4      1.312315   \n",
       "\n",
       "        Images  Review velocity  Buy Box  ...  Size Tier_Large Envelope  \\\n",
       "0     1.010296         0.003233       38  ...                         0   \n",
       "1     1.352821         0.003233       38  ...                         0   \n",
       "2    -0.359806         0.003233       38  ...                         0   \n",
       "3    -0.017280         0.003233      588  ...                         0   \n",
       "4     0.325245         0.142447      588  ...                         0   \n",
       "...        ...              ...      ...  ...                       ...   \n",
       "1997  0.325245         0.003233      589  ...                         0   \n",
       "1998 -0.359806         0.212053       38  ...                         0   \n",
       "1999  1.010296         0.142447       22  ...                         0   \n",
       "2000 -0.017280         0.142447      227  ...                         0   \n",
       "2001  1.010296         0.003233       38  ...                         0   \n",
       "\n",
       "      Size Tier_Large Letter  Size Tier_Large Oversize  \\\n",
       "0                          0                         1   \n",
       "1                          0                         1   \n",
       "2                          0                         0   \n",
       "3                          0                         1   \n",
       "4                          0                         1   \n",
       "...                      ...                       ...   \n",
       "1997                       0                         1   \n",
       "1998                       0                         1   \n",
       "1999                       0                         1   \n",
       "2000                       0                         1   \n",
       "2001                       0                         1   \n",
       "\n",
       "      Size Tier_Small Envelope  Size Tier_Small Oversize  \\\n",
       "0                            0                         0   \n",
       "1                            0                         0   \n",
       "2                            0                         1   \n",
       "3                            0                         0   \n",
       "4                            0                         0   \n",
       "...                        ...                       ...   \n",
       "1997                         0                         0   \n",
       "1998                         0                         0   \n",
       "1999                         0                         0   \n",
       "2000                         0                         0   \n",
       "2001                         0                         0   \n",
       "\n",
       "      Size Tier_Standard Envelope  Size Tier_Standard Parcel  Delivery_AMZ  \\\n",
       "0                               0                          0             1   \n",
       "1                               0                          0             1   \n",
       "2                               0                          0             1   \n",
       "3                               0                          0             0   \n",
       "4                               0                          0             0   \n",
       "...                           ...                        ...           ...   \n",
       "1997                            0                          0             0   \n",
       "1998                            0                          0             1   \n",
       "1999                            0                          0             0   \n",
       "2000                            0                          0             0   \n",
       "2001                            0                          0             1   \n",
       "\n",
       "      Delivery_FBA  Delivery_MFN  \n",
       "0                0             0  \n",
       "1                0             0  \n",
       "2                0             0  \n",
       "3                0             1  \n",
       "4                0             1  \n",
       "...            ...           ...  \n",
       "1997             1             0  \n",
       "1998             0             0  \n",
       "1999             1             0  \n",
       "2000             1             0  \n",
       "2001             0             0  \n",
       "\n",
       "[2002 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e765da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns!='Sales']\n",
    "y = df[['Sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8af407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1601, 26) (401, 26) (1601, 1) (401, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=34)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194c531f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af18348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    " \n",
    "model = RandomForestRegressor(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022cf78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21.505436408977555, 53.17747579727319, 0.8743898163250485)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e4e514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd60825",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ffb99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "51/51 - 1s - loss: 814416.8125 - mae: 429.9390 - 1s/epoch - 27ms/step\n",
      "Epoch 2/200\n",
      "51/51 - 0s - loss: 6579810.0000 - mae: 725.1823 - 103ms/epoch - 2ms/step\n",
      "Epoch 3/200\n",
      "51/51 - 0s - loss: 181726.4375 - mae: 132.0487 - 103ms/epoch - 2ms/step\n",
      "Epoch 4/200\n",
      "51/51 - 0s - loss: 276000.7812 - mae: 213.0212 - 88ms/epoch - 2ms/step\n",
      "Epoch 5/200\n",
      "51/51 - 0s - loss: 125795.3672 - mae: 105.1978 - 110ms/epoch - 2ms/step\n",
      "Epoch 6/200\n",
      "51/51 - 0s - loss: 1193491.0000 - mae: 517.7007 - 111ms/epoch - 2ms/step\n",
      "Epoch 7/200\n",
      "51/51 - 0s - loss: 91278.7031 - mae: 75.3900 - 96ms/epoch - 2ms/step\n",
      "Epoch 8/200\n",
      "51/51 - 0s - loss: 66709.6250 - mae: 46.4907 - 106ms/epoch - 2ms/step\n",
      "Epoch 9/200\n",
      "51/51 - 0s - loss: 62372.9023 - mae: 40.2977 - 101ms/epoch - 2ms/step\n",
      "Epoch 10/200\n",
      "51/51 - 0s - loss: 59086.2070 - mae: 40.0681 - 88ms/epoch - 2ms/step\n",
      "Epoch 11/200\n",
      "51/51 - 0s - loss: 56751.0898 - mae: 42.6181 - 106ms/epoch - 2ms/step\n",
      "Epoch 12/200\n",
      "51/51 - 0s - loss: 59233.0312 - mae: 54.2367 - 113ms/epoch - 2ms/step\n",
      "Epoch 13/200\n",
      "51/51 - 0s - loss: 2246219.2500 - mae: 441.7823 - 98ms/epoch - 2ms/step\n",
      "Epoch 14/200\n",
      "51/51 - 0s - loss: 7035808.0000 - mae: 1201.2333 - 102ms/epoch - 2ms/step\n",
      "Epoch 15/200\n",
      "51/51 - 0s - loss: 2493942.5000 - mae: 673.5705 - 101ms/epoch - 2ms/step\n",
      "Epoch 16/200\n",
      "51/51 - 0s - loss: 147456.3281 - mae: 127.4343 - 97ms/epoch - 2ms/step\n",
      "Epoch 17/200\n",
      "51/51 - 0s - loss: 55388.6758 - mae: 62.1133 - 101ms/epoch - 2ms/step\n",
      "Epoch 18/200\n",
      "51/51 - 0s - loss: 55199.3555 - mae: 64.6170 - 95ms/epoch - 2ms/step\n",
      "Epoch 19/200\n",
      "51/51 - 0s - loss: 61367.3555 - mae: 78.1038 - 98ms/epoch - 2ms/step\n",
      "Epoch 20/200\n",
      "51/51 - 0s - loss: 51376.1055 - mae: 57.8015 - 99ms/epoch - 2ms/step\n",
      "Epoch 21/200\n",
      "51/51 - 0s - loss: 51033.7578 - mae: 53.9242 - 90ms/epoch - 2ms/step\n",
      "Epoch 22/200\n",
      "51/51 - 0s - loss: 46266.9336 - mae: 49.6868 - 102ms/epoch - 2ms/step\n",
      "Epoch 23/200\n",
      "51/51 - 0s - loss: 55944.1758 - mae: 63.2193 - 139ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "51/51 - 0s - loss: 102141.3281 - mae: 116.2663 - 112ms/epoch - 2ms/step\n",
      "Epoch 25/200\n",
      "51/51 - 0s - loss: 47378.8516 - mae: 51.4269 - 96ms/epoch - 2ms/step\n",
      "Epoch 26/200\n",
      "51/51 - 0s - loss: 48774.4102 - mae: 63.4314 - 101ms/epoch - 2ms/step\n",
      "Epoch 27/200\n",
      "51/51 - 0s - loss: 59005.3867 - mae: 81.5042 - 103ms/epoch - 2ms/step\n",
      "Epoch 28/200\n",
      "51/51 - 0s - loss: 44505.5078 - mae: 59.3517 - 119ms/epoch - 2ms/step\n",
      "Epoch 29/200\n",
      "51/51 - 0s - loss: 47278.0703 - mae: 50.3464 - 109ms/epoch - 2ms/step\n",
      "Epoch 30/200\n",
      "51/51 - 0s - loss: 40723.5977 - mae: 41.6769 - 106ms/epoch - 2ms/step\n",
      "Epoch 31/200\n",
      "51/51 - 0s - loss: 45219.7578 - mae: 60.1808 - 90ms/epoch - 2ms/step\n",
      "Epoch 32/200\n",
      "51/51 - 0s - loss: 38203.6016 - mae: 45.2017 - 104ms/epoch - 2ms/step\n",
      "Epoch 33/200\n",
      "51/51 - 0s - loss: 35375.8867 - mae: 37.1431 - 101ms/epoch - 2ms/step\n",
      "Epoch 34/200\n",
      "51/51 - 0s - loss: 34933.8242 - mae: 36.6023 - 100ms/epoch - 2ms/step\n",
      "Epoch 35/200\n",
      "51/51 - 0s - loss: 34848.5156 - mae: 36.0424 - 106ms/epoch - 2ms/step\n",
      "Epoch 36/200\n",
      "51/51 - 0s - loss: 35004.8164 - mae: 36.1453 - 104ms/epoch - 2ms/step\n",
      "Epoch 37/200\n",
      "51/51 - 0s - loss: 33031.9219 - mae: 36.1294 - 99ms/epoch - 2ms/step\n",
      "Epoch 38/200\n",
      "51/51 - 0s - loss: 37554.4375 - mae: 36.2348 - 135ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "51/51 - 0s - loss: 30552.7500 - mae: 35.3801 - 101ms/epoch - 2ms/step\n",
      "Epoch 40/200\n",
      "51/51 - 0s - loss: 30538.2812 - mae: 46.8083 - 102ms/epoch - 2ms/step\n",
      "Epoch 41/200\n",
      "51/51 - 0s - loss: 40499.1445 - mae: 59.3298 - 105ms/epoch - 2ms/step\n",
      "Epoch 42/200\n",
      "51/51 - 0s - loss: 27401.4609 - mae: 40.7235 - 121ms/epoch - 2ms/step\n",
      "Epoch 43/200\n",
      "51/51 - 0s - loss: 25714.0762 - mae: 35.6960 - 109ms/epoch - 2ms/step\n",
      "Epoch 44/200\n",
      "51/51 - 0s - loss: 26174.0020 - mae: 42.5600 - 105ms/epoch - 2ms/step\n",
      "Epoch 45/200\n",
      "51/51 - 0s - loss: 29277.0098 - mae: 46.9359 - 109ms/epoch - 2ms/step\n",
      "Epoch 46/200\n",
      "51/51 - 0s - loss: 27104.4453 - mae: 33.9220 - 105ms/epoch - 2ms/step\n",
      "Epoch 47/200\n",
      "51/51 - 0s - loss: 22223.9121 - mae: 31.8709 - 101ms/epoch - 2ms/step\n",
      "Epoch 48/200\n",
      "51/51 - 0s - loss: 18562.8945 - mae: 32.2113 - 105ms/epoch - 2ms/step\n",
      "Epoch 49/200\n",
      "51/51 - 0s - loss: 19801.9043 - mae: 33.2547 - 96ms/epoch - 2ms/step\n",
      "Epoch 50/200\n",
      "51/51 - 0s - loss: 16766.9355 - mae: 31.3994 - 120ms/epoch - 2ms/step\n",
      "Epoch 51/200\n",
      "51/51 - 0s - loss: 16970.9336 - mae: 34.3936 - 125ms/epoch - 2ms/step\n",
      "Epoch 52/200\n",
      "51/51 - 0s - loss: 20332.3418 - mae: 34.6271 - 124ms/epoch - 2ms/step\n",
      "Epoch 53/200\n",
      "51/51 - 0s - loss: 31359.0176 - mae: 64.9322 - 123ms/epoch - 2ms/step\n",
      "Epoch 54/200\n",
      "51/51 - 0s - loss: 25883.9727 - mae: 60.9559 - 104ms/epoch - 2ms/step\n",
      "Epoch 55/200\n",
      "51/51 - 0s - loss: 15692.2021 - mae: 36.2875 - 92ms/epoch - 2ms/step\n",
      "Epoch 56/200\n",
      "51/51 - 0s - loss: 15990.6631 - mae: 38.6741 - 87ms/epoch - 2ms/step\n",
      "Epoch 57/200\n",
      "51/51 - 0s - loss: 21801.5820 - mae: 47.6414 - 93ms/epoch - 2ms/step\n",
      "Epoch 58/200\n",
      "51/51 - 0s - loss: 15717.4658 - mae: 40.2033 - 90ms/epoch - 2ms/step\n",
      "Epoch 59/200\n",
      "51/51 - 0s - loss: 28930.8477 - mae: 75.6096 - 87ms/epoch - 2ms/step\n",
      "Epoch 60/200\n",
      "51/51 - 0s - loss: 50800.1367 - mae: 107.6576 - 89ms/epoch - 2ms/step\n",
      "Epoch 61/200\n",
      "51/51 - 0s - loss: 11031.0420 - mae: 38.2274 - 92ms/epoch - 2ms/step\n",
      "Epoch 62/200\n",
      "51/51 - 0s - loss: 20148.8164 - mae: 64.6693 - 94ms/epoch - 2ms/step\n",
      "Epoch 63/200\n",
      "51/51 - 0s - loss: 16789.4609 - mae: 52.2694 - 86ms/epoch - 2ms/step\n",
      "Epoch 64/200\n",
      "51/51 - 0s - loss: 64832.8242 - mae: 88.3857 - 92ms/epoch - 2ms/step\n",
      "Epoch 65/200\n",
      "51/51 - 0s - loss: 54240.3633 - mae: 92.1961 - 88ms/epoch - 2ms/step\n",
      "Epoch 66/200\n",
      "51/51 - 0s - loss: 14490.6445 - mae: 37.3605 - 95ms/epoch - 2ms/step\n",
      "Epoch 67/200\n",
      "51/51 - 0s - loss: 11000.2949 - mae: 28.4818 - 101ms/epoch - 2ms/step\n",
      "Epoch 68/200\n",
      "51/51 - 0s - loss: 10747.8662 - mae: 37.2950 - 92ms/epoch - 2ms/step\n",
      "Epoch 69/200\n",
      "51/51 - 0s - loss: 175758.6875 - mae: 160.6552 - 93ms/epoch - 2ms/step\n",
      "Epoch 70/200\n",
      "51/51 - 0s - loss: 448965.3438 - mae: 304.2782 - 89ms/epoch - 2ms/step\n",
      "Epoch 71/200\n",
      "51/51 - 0s - loss: 514933.0938 - mae: 297.6784 - 93ms/epoch - 2ms/step\n",
      "Epoch 72/200\n",
      "51/51 - 0s - loss: 222644.6875 - mae: 200.4687 - 92ms/epoch - 2ms/step\n",
      "Epoch 73/200\n",
      "51/51 - 0s - loss: 162090.9531 - mae: 162.5599 - 88ms/epoch - 2ms/step\n",
      "Epoch 74/200\n",
      "51/51 - 0s - loss: 60706.4688 - mae: 112.4314 - 91ms/epoch - 2ms/step\n",
      "Epoch 75/200\n",
      "51/51 - 0s - loss: 14366.0166 - mae: 58.1108 - 91ms/epoch - 2ms/step\n",
      "Epoch 76/200\n",
      "51/51 - 0s - loss: 11120.7422 - mae: 38.1928 - 91ms/epoch - 2ms/step\n",
      "Epoch 77/200\n",
      "51/51 - 0s - loss: 12094.2578 - mae: 40.9928 - 89ms/epoch - 2ms/step\n",
      "Epoch 78/200\n",
      "51/51 - 0s - loss: 10344.9805 - mae: 35.9411 - 91ms/epoch - 2ms/step\n",
      "Epoch 79/200\n",
      "51/51 - 0s - loss: 13193.4707 - mae: 37.8767 - 90ms/epoch - 2ms/step\n",
      "Epoch 80/200\n",
      "51/51 - 0s - loss: 17670.0312 - mae: 48.5660 - 87ms/epoch - 2ms/step\n",
      "Epoch 81/200\n",
      "51/51 - 0s - loss: 208169.2500 - mae: 187.4472 - 89ms/epoch - 2ms/step\n",
      "Epoch 82/200\n",
      "51/51 - 0s - loss: 110709.7734 - mae: 131.9421 - 87ms/epoch - 2ms/step\n",
      "Epoch 83/200\n",
      "51/51 - 0s - loss: 1794693.3750 - mae: 443.7677 - 115ms/epoch - 2ms/step\n",
      "Epoch 84/200\n",
      "51/51 - 0s - loss: 654991.3750 - mae: 433.8760 - 87ms/epoch - 2ms/step\n",
      "Epoch 85/200\n",
      "51/51 - 0s - loss: 280627.8125 - mae: 241.9574 - 94ms/epoch - 2ms/step\n",
      "Epoch 86/200\n",
      "51/51 - 0s - loss: 10233.1094 - mae: 40.9494 - 112ms/epoch - 2ms/step\n",
      "Epoch 87/200\n",
      "51/51 - 0s - loss: 9457.0078 - mae: 28.9615 - 100ms/epoch - 2ms/step\n",
      "Epoch 88/200\n",
      "51/51 - 0s - loss: 8277.9473 - mae: 30.2809 - 98ms/epoch - 2ms/step\n",
      "Epoch 89/200\n",
      "51/51 - 0s - loss: 7599.8950 - mae: 27.8251 - 105ms/epoch - 2ms/step\n",
      "Epoch 90/200\n",
      "51/51 - 0s - loss: 8477.7227 - mae: 29.3334 - 126ms/epoch - 2ms/step\n",
      "Epoch 91/200\n",
      "51/51 - 0s - loss: 5801.9883 - mae: 25.9911 - 87ms/epoch - 2ms/step\n",
      "Epoch 92/200\n",
      "51/51 - 0s - loss: 6487.1011 - mae: 26.7094 - 103ms/epoch - 2ms/step\n",
      "Epoch 93/200\n",
      "51/51 - 0s - loss: 5645.3213 - mae: 27.2584 - 103ms/epoch - 2ms/step\n",
      "Epoch 94/200\n",
      "51/51 - 0s - loss: 6922.6172 - mae: 26.9614 - 96ms/epoch - 2ms/step\n",
      "Epoch 95/200\n",
      "51/51 - 0s - loss: 5709.3013 - mae: 25.6995 - 93ms/epoch - 2ms/step\n",
      "Epoch 96/200\n",
      "51/51 - 0s - loss: 5066.2153 - mae: 24.8977 - 101ms/epoch - 2ms/step\n",
      "Epoch 97/200\n",
      "51/51 - 0s - loss: 5615.0806 - mae: 26.1001 - 102ms/epoch - 2ms/step\n",
      "Epoch 98/200\n",
      "51/51 - 0s - loss: 5227.7212 - mae: 25.9346 - 161ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "51/51 - 0s - loss: 4388.3833 - mae: 24.8185 - 91ms/epoch - 2ms/step\n",
      "Epoch 100/200\n",
      "51/51 - 0s - loss: 4959.3203 - mae: 25.6470 - 236ms/epoch - 5ms/step\n",
      "Epoch 101/200\n",
      "51/51 - 0s - loss: 4149.0464 - mae: 24.4225 - 174ms/epoch - 3ms/step\n",
      "Epoch 102/200\n",
      "51/51 - 0s - loss: 4032.3547 - mae: 23.2803 - 127ms/epoch - 2ms/step\n",
      "Epoch 103/200\n",
      "51/51 - 0s - loss: 4067.1162 - mae: 23.6108 - 155ms/epoch - 3ms/step\n",
      "Epoch 104/200\n",
      "51/51 - 0s - loss: 4099.8848 - mae: 24.2959 - 150ms/epoch - 3ms/step\n",
      "Epoch 105/200\n",
      "51/51 - 0s - loss: 4167.3975 - mae: 24.6983 - 106ms/epoch - 2ms/step\n",
      "Epoch 106/200\n",
      "51/51 - 0s - loss: 3738.0144 - mae: 23.2220 - 98ms/epoch - 2ms/step\n",
      "Epoch 107/200\n",
      "51/51 - 0s - loss: 4225.1743 - mae: 23.8770 - 84ms/epoch - 2ms/step\n",
      "Epoch 108/200\n",
      "51/51 - 0s - loss: 4110.0854 - mae: 23.8173 - 111ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "51/51 - 0s - loss: 4196.5093 - mae: 23.8926 - 145ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "51/51 - 0s - loss: 3946.3018 - mae: 23.9011 - 102ms/epoch - 2ms/step\n",
      "Epoch 111/200\n",
      "51/51 - 0s - loss: 3573.3628 - mae: 23.1467 - 103ms/epoch - 2ms/step\n",
      "Epoch 112/200\n",
      "51/51 - 0s - loss: 3508.5276 - mae: 22.6946 - 117ms/epoch - 2ms/step\n",
      "Epoch 113/200\n",
      "51/51 - 0s - loss: 3656.9702 - mae: 23.4595 - 121ms/epoch - 2ms/step\n",
      "Epoch 114/200\n",
      "51/51 - 0s - loss: 3431.6680 - mae: 22.9117 - 97ms/epoch - 2ms/step\n",
      "Epoch 115/200\n",
      "51/51 - 0s - loss: 3386.8704 - mae: 22.3645 - 98ms/epoch - 2ms/step\n",
      "Epoch 116/200\n",
      "51/51 - 0s - loss: 3385.8301 - mae: 22.6737 - 88ms/epoch - 2ms/step\n",
      "Epoch 117/200\n",
      "51/51 - 0s - loss: 3288.3770 - mae: 22.5142 - 101ms/epoch - 2ms/step\n",
      "Epoch 118/200\n",
      "51/51 - 0s - loss: 3469.9141 - mae: 25.5331 - 98ms/epoch - 2ms/step\n",
      "Epoch 119/200\n",
      "51/51 - 0s - loss: 5486.8643 - mae: 34.9152 - 168ms/epoch - 3ms/step\n",
      "Epoch 120/200\n",
      "51/51 - 0s - loss: 3546.0132 - mae: 27.3927 - 124ms/epoch - 2ms/step\n",
      "Epoch 121/200\n",
      "51/51 - 0s - loss: 3427.5134 - mae: 24.9986 - 150ms/epoch - 3ms/step\n",
      "Epoch 122/200\n",
      "51/51 - 0s - loss: 3355.4873 - mae: 24.0894 - 187ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "51/51 - 0s - loss: 3467.7817 - mae: 26.4398 - 142ms/epoch - 3ms/step\n",
      "Epoch 124/200\n",
      "51/51 - 0s - loss: 3809.0056 - mae: 27.1943 - 110ms/epoch - 2ms/step\n",
      "Epoch 125/200\n",
      "51/51 - 0s - loss: 5449.5391 - mae: 40.0168 - 95ms/epoch - 2ms/step\n",
      "Epoch 126/200\n",
      "51/51 - 0s - loss: 3736.4087 - mae: 27.2507 - 104ms/epoch - 2ms/step\n",
      "Epoch 127/200\n",
      "51/51 - 0s - loss: 3684.0637 - mae: 24.5176 - 98ms/epoch - 2ms/step\n",
      "Epoch 128/200\n",
      "51/51 - 0s - loss: 3320.5779 - mae: 22.5962 - 89ms/epoch - 2ms/step\n",
      "Epoch 129/200\n",
      "51/51 - 0s - loss: 3346.2998 - mae: 22.4924 - 91ms/epoch - 2ms/step\n",
      "Epoch 130/200\n",
      "51/51 - 0s - loss: 3340.0862 - mae: 22.4860 - 95ms/epoch - 2ms/step\n",
      "Epoch 131/200\n",
      "51/51 - 0s - loss: 3344.8252 - mae: 22.0558 - 103ms/epoch - 2ms/step\n",
      "Epoch 132/200\n",
      "51/51 - 0s - loss: 3360.1465 - mae: 22.3071 - 105ms/epoch - 2ms/step\n",
      "Epoch 133/200\n",
      "51/51 - 0s - loss: 3370.3118 - mae: 22.2392 - 130ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "51/51 - 0s - loss: 7563.7134 - mae: 26.5879 - 95ms/epoch - 2ms/step\n",
      "Epoch 135/200\n",
      "51/51 - 0s - loss: 12191.8535 - mae: 32.9601 - 116ms/epoch - 2ms/step\n",
      "Epoch 136/200\n",
      "51/51 - 0s - loss: 13245.2754 - mae: 40.3876 - 88ms/epoch - 2ms/step\n",
      "Epoch 137/200\n",
      "51/51 - 0s - loss: 9594.4863 - mae: 34.1798 - 115ms/epoch - 2ms/step\n",
      "Epoch 138/200\n",
      "51/51 - 0s - loss: 6471.1572 - mae: 29.3083 - 105ms/epoch - 2ms/step\n",
      "Epoch 139/200\n",
      "51/51 - 0s - loss: 8586.0654 - mae: 33.5898 - 126ms/epoch - 2ms/step\n",
      "Epoch 140/200\n",
      "51/51 - 0s - loss: 4988.5146 - mae: 25.2289 - 140ms/epoch - 3ms/step\n",
      "Epoch 141/200\n",
      "51/51 - 0s - loss: 3825.4001 - mae: 23.1058 - 103ms/epoch - 2ms/step\n",
      "Epoch 142/200\n",
      "51/51 - 0s - loss: 5566.2661 - mae: 32.9599 - 110ms/epoch - 2ms/step\n",
      "Epoch 143/200\n",
      "51/51 - 0s - loss: 4420.5386 - mae: 31.4312 - 137ms/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "51/51 - 0s - loss: 3445.5098 - mae: 23.7923 - 108ms/epoch - 2ms/step\n",
      "Epoch 145/200\n",
      "51/51 - 0s - loss: 9534.3750 - mae: 48.3024 - 90ms/epoch - 2ms/step\n",
      "Epoch 146/200\n",
      "51/51 - 0s - loss: 61859.9609 - mae: 132.5873 - 147ms/epoch - 3ms/step\n",
      "Epoch 147/200\n",
      "51/51 - 0s - loss: 26986.4883 - mae: 82.4645 - 137ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "51/51 - 0s - loss: 9595.9297 - mae: 44.6851 - 90ms/epoch - 2ms/step\n",
      "Epoch 149/200\n",
      "51/51 - 0s - loss: 4070.7944 - mae: 32.5090 - 90ms/epoch - 2ms/step\n",
      "Epoch 150/200\n",
      "51/51 - 0s - loss: 3396.3042 - mae: 23.2626 - 85ms/epoch - 2ms/step\n",
      "Epoch 151/200\n",
      "51/51 - 0s - loss: 3299.4517 - mae: 22.9278 - 96ms/epoch - 2ms/step\n",
      "Epoch 152/200\n",
      "51/51 - 0s - loss: 3126.0549 - mae: 21.7283 - 87ms/epoch - 2ms/step\n",
      "Epoch 153/200\n",
      "51/51 - 0s - loss: 3212.7156 - mae: 22.0168 - 94ms/epoch - 2ms/step\n",
      "Epoch 154/200\n",
      "51/51 - 0s - loss: 3419.8430 - mae: 22.9175 - 94ms/epoch - 2ms/step\n",
      "Epoch 155/200\n",
      "51/51 - 0s - loss: 5507.5552 - mae: 33.6209 - 89ms/epoch - 2ms/step\n",
      "Epoch 156/200\n",
      "51/51 - 0s - loss: 9505.1895 - mae: 43.8104 - 99ms/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "51/51 - 0s - loss: 9464.4521 - mae: 46.0364 - 121ms/epoch - 2ms/step\n",
      "Epoch 158/200\n",
      "51/51 - 0s - loss: 8506.2539 - mae: 49.0199 - 102ms/epoch - 2ms/step\n",
      "Epoch 159/200\n",
      "51/51 - 0s - loss: 3660.6206 - mae: 24.8131 - 95ms/epoch - 2ms/step\n",
      "Epoch 160/200\n",
      "51/51 - 0s - loss: 3365.9526 - mae: 22.8774 - 99ms/epoch - 2ms/step\n",
      "Epoch 161/200\n",
      "51/51 - 0s - loss: 4291.8120 - mae: 25.2831 - 105ms/epoch - 2ms/step\n",
      "Epoch 162/200\n",
      "51/51 - 0s - loss: 3421.6316 - mae: 22.6536 - 103ms/epoch - 2ms/step\n",
      "Epoch 163/200\n",
      "51/51 - 0s - loss: 3304.5955 - mae: 21.5946 - 119ms/epoch - 2ms/step\n",
      "Epoch 164/200\n",
      "51/51 - 0s - loss: 3353.5884 - mae: 23.7527 - 98ms/epoch - 2ms/step\n",
      "Epoch 165/200\n",
      "51/51 - 0s - loss: 6784.4556 - mae: 39.8713 - 90ms/epoch - 2ms/step\n",
      "Epoch 166/200\n",
      "51/51 - 0s - loss: 12763.6123 - mae: 62.8502 - 93ms/epoch - 2ms/step\n",
      "Epoch 167/200\n",
      "51/51 - 0s - loss: 5415.9824 - mae: 36.5009 - 90ms/epoch - 2ms/step\n",
      "Epoch 168/200\n",
      "51/51 - 0s - loss: 4363.7959 - mae: 34.1234 - 90ms/epoch - 2ms/step\n",
      "Epoch 169/200\n",
      "51/51 - 0s - loss: 3456.2100 - mae: 22.6059 - 84ms/epoch - 2ms/step\n",
      "Epoch 170/200\n",
      "51/51 - 0s - loss: 3563.8203 - mae: 24.1165 - 117ms/epoch - 2ms/step\n",
      "Epoch 171/200\n",
      "51/51 - 0s - loss: 3653.8052 - mae: 25.4838 - 104ms/epoch - 2ms/step\n",
      "Epoch 172/200\n",
      "51/51 - 0s - loss: 4920.4146 - mae: 31.2632 - 93ms/epoch - 2ms/step\n",
      "Epoch 173/200\n",
      "51/51 - 0s - loss: 9424.9531 - mae: 43.9152 - 96ms/epoch - 2ms/step\n",
      "Epoch 174/200\n",
      "51/51 - 0s - loss: 27452.6621 - mae: 63.2130 - 109ms/epoch - 2ms/step\n",
      "Epoch 175/200\n",
      "51/51 - 0s - loss: 59281.2852 - mae: 99.4681 - 94ms/epoch - 2ms/step\n",
      "Epoch 176/200\n",
      "51/51 - 0s - loss: 8122.5942 - mae: 42.2495 - 87ms/epoch - 2ms/step\n",
      "Epoch 177/200\n",
      "51/51 - 0s - loss: 3493.0437 - mae: 23.9328 - 99ms/epoch - 2ms/step\n",
      "Epoch 178/200\n",
      "51/51 - 0s - loss: 3132.1208 - mae: 21.1523 - 95ms/epoch - 2ms/step\n",
      "Epoch 179/200\n",
      "51/51 - 0s - loss: 3133.5974 - mae: 20.7015 - 85ms/epoch - 2ms/step\n",
      "Epoch 180/200\n",
      "51/51 - 0s - loss: 2960.2800 - mae: 20.4440 - 124ms/epoch - 2ms/step\n",
      "Epoch 181/200\n",
      "51/51 - 0s - loss: 2929.3738 - mae: 20.1538 - 100ms/epoch - 2ms/step\n",
      "Epoch 182/200\n",
      "51/51 - 0s - loss: 2924.1511 - mae: 20.3321 - 94ms/epoch - 2ms/step\n",
      "Epoch 183/200\n",
      "51/51 - 0s - loss: 2931.9141 - mae: 20.2502 - 88ms/epoch - 2ms/step\n",
      "Epoch 184/200\n",
      "51/51 - 0s - loss: 3505.1289 - mae: 22.6031 - 88ms/epoch - 2ms/step\n",
      "Epoch 185/200\n",
      "51/51 - 0s - loss: 3678.2021 - mae: 23.9237 - 93ms/epoch - 2ms/step\n",
      "Epoch 186/200\n",
      "51/51 - 0s - loss: 3168.2510 - mae: 22.4317 - 105ms/epoch - 2ms/step\n",
      "Epoch 187/200\n",
      "51/51 - 0s - loss: 3081.4443 - mae: 21.0936 - 85ms/epoch - 2ms/step\n",
      "Epoch 188/200\n",
      "51/51 - 0s - loss: 3077.7258 - mae: 21.3639 - 89ms/epoch - 2ms/step\n",
      "Epoch 189/200\n",
      "51/51 - 0s - loss: 3102.1255 - mae: 20.7791 - 88ms/epoch - 2ms/step\n",
      "Epoch 190/200\n",
      "51/51 - 0s - loss: 3590.3064 - mae: 22.4878 - 98ms/epoch - 2ms/step\n",
      "Epoch 191/200\n",
      "51/51 - 0s - loss: 3459.2415 - mae: 21.5198 - 96ms/epoch - 2ms/step\n",
      "Epoch 192/200\n",
      "51/51 - 0s - loss: 3398.6316 - mae: 20.9305 - 90ms/epoch - 2ms/step\n",
      "Epoch 193/200\n",
      "51/51 - 0s - loss: 3208.3503 - mae: 21.5511 - 95ms/epoch - 2ms/step\n",
      "Epoch 194/200\n",
      "51/51 - 0s - loss: 3284.1812 - mae: 21.5718 - 143ms/epoch - 3ms/step\n",
      "Epoch 195/200\n",
      "51/51 - 0s - loss: 2964.9148 - mae: 21.1733 - 109ms/epoch - 2ms/step\n",
      "Epoch 196/200\n",
      "51/51 - 0s - loss: 2924.9556 - mae: 20.3342 - 132ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "51/51 - 0s - loss: 3000.9307 - mae: 21.8167 - 110ms/epoch - 2ms/step\n",
      "Epoch 198/200\n",
      "51/51 - 0s - loss: 3004.3335 - mae: 20.3235 - 91ms/epoch - 2ms/step\n",
      "Epoch 199/200\n",
      "51/51 - 0s - loss: 3133.9438 - mae: 21.4899 - 96ms/epoch - 2ms/step\n",
      "Epoch 200/200\n",
      "51/51 - 0s - loss: 2858.0234 - mae: 20.3962 - 87ms/epoch - 2ms/step\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 2687.6536 - mae: 23.9744\n",
      "Epoch 1/200\n",
      "38/38 - 2s - loss: 15640434.0000 - mae: 1236.9353 - val_loss: 382707.0000 - val_mae: 270.4036 - 2s/epoch - 42ms/step\n",
      "Epoch 2/200\n",
      "38/38 - 0s - loss: 241731.0938 - mae: 224.2373 - val_loss: 668198.6250 - val_mae: 347.4356 - 132ms/epoch - 3ms/step\n",
      "Epoch 3/200\n",
      "38/38 - 0s - loss: 1079231.8750 - mae: 422.0123 - val_loss: 276387.1250 - val_mae: 93.7000 - 122ms/epoch - 3ms/step\n",
      "Epoch 4/200\n",
      "38/38 - 0s - loss: 4825570.0000 - mae: 768.5721 - val_loss: 1390604.1250 - val_mae: 598.9148 - 141ms/epoch - 4ms/step\n",
      "Epoch 5/200\n",
      "38/38 - 0s - loss: 4453552.5000 - mae: 730.4142 - val_loss: 435034.9062 - val_mae: 265.3769 - 116ms/epoch - 3ms/step\n",
      "Epoch 6/200\n",
      "38/38 - 0s - loss: 3343755.2500 - mae: 679.4221 - val_loss: 816379.6875 - val_mae: 357.4149 - 117ms/epoch - 3ms/step\n",
      "Epoch 7/200\n",
      "38/38 - 0s - loss: 7663675.5000 - mae: 926.2115 - val_loss: 278555.8438 - val_mae: 119.6611 - 121ms/epoch - 3ms/step\n",
      "Epoch 8/200\n",
      "38/38 - 0s - loss: 445283.0938 - mae: 314.5329 - val_loss: 705327.8125 - val_mae: 434.7546 - 121ms/epoch - 3ms/step\n",
      "Epoch 9/200\n",
      "38/38 - 0s - loss: 119954.7734 - mae: 172.8957 - val_loss: 276208.7500 - val_mae: 175.9502 - 122ms/epoch - 3ms/step\n",
      "Epoch 10/200\n",
      "38/38 - 0s - loss: 84342.8438 - mae: 125.1337 - val_loss: 247252.0469 - val_mae: 72.8872 - 140ms/epoch - 4ms/step\n",
      "Epoch 11/200\n",
      "38/38 - 0s - loss: 32638.5391 - mae: 85.7111 - val_loss: 249370.8594 - val_mae: 98.5921 - 128ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "38/38 - 0s - loss: 30728.5527 - mae: 75.1898 - val_loss: 226004.0469 - val_mae: 63.4717 - 140ms/epoch - 4ms/step\n",
      "Epoch 13/200\n",
      "38/38 - 0s - loss: 19131.3750 - mae: 53.5912 - val_loss: 229256.7188 - val_mae: 79.6716 - 121ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "38/38 - 0s - loss: 16751.4648 - mae: 52.7678 - val_loss: 230538.7344 - val_mae: 75.5647 - 135ms/epoch - 4ms/step\n",
      "Epoch 15/200\n",
      "38/38 - 0s - loss: 14301.4863 - mae: 38.3671 - val_loss: 219626.4688 - val_mae: 57.1737 - 127ms/epoch - 3ms/step\n",
      "Epoch 16/200\n",
      "38/38 - 0s - loss: 13318.4971 - mae: 36.0018 - val_loss: 221105.2031 - val_mae: 62.5825 - 117ms/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "38/38 - 0s - loss: 13368.4619 - mae: 39.7687 - val_loss: 230978.0000 - val_mae: 62.1117 - 119ms/epoch - 3ms/step\n",
      "Epoch 18/200\n",
      "38/38 - 0s - loss: 13730.9580 - mae: 33.6855 - val_loss: 222767.7656 - val_mae: 58.8573 - 110ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "38/38 - 0s - loss: 15405.3770 - mae: 36.9115 - val_loss: 219185.2969 - val_mae: 51.9877 - 126ms/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "38/38 - 0s - loss: 12974.5791 - mae: 35.6481 - val_loss: 233918.4844 - val_mae: 57.2892 - 129ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "38/38 - 0s - loss: 11595.2383 - mae: 30.2854 - val_loss: 219884.2031 - val_mae: 52.6026 - 115ms/epoch - 3ms/step\n",
      "Epoch 22/200\n",
      "38/38 - 0s - loss: 12026.3555 - mae: 32.3638 - val_loss: 217903.6406 - val_mae: 53.7365 - 125ms/epoch - 3ms/step\n",
      "Epoch 23/200\n",
      "38/38 - 0s - loss: 12743.3174 - mae: 39.0144 - val_loss: 230363.1094 - val_mae: 60.0496 - 114ms/epoch - 3ms/step\n",
      "Epoch 24/200\n",
      "38/38 - 0s - loss: 13107.9980 - mae: 39.7499 - val_loss: 224704.0000 - val_mae: 74.4387 - 130ms/epoch - 3ms/step\n",
      "Epoch 25/200\n",
      "38/38 - 0s - loss: 60859.5195 - mae: 92.0729 - val_loss: 248377.5312 - val_mae: 108.3694 - 125ms/epoch - 3ms/step\n",
      "Epoch 26/200\n",
      "38/38 - 0s - loss: 57180.2461 - mae: 98.0276 - val_loss: 247569.6719 - val_mae: 127.0887 - 126ms/epoch - 3ms/step\n",
      "Epoch 27/200\n",
      "38/38 - 0s - loss: 86542.0000 - mae: 141.3901 - val_loss: 245997.9844 - val_mae: 96.2780 - 111ms/epoch - 3ms/step\n",
      "Epoch 28/200\n",
      "38/38 - 0s - loss: 76044.7578 - mae: 98.0325 - val_loss: 303836.4375 - val_mae: 169.7285 - 173ms/epoch - 5ms/step\n",
      "Epoch 29/200\n",
      "38/38 - 0s - loss: 54141.1445 - mae: 104.6791 - val_loss: 237417.1250 - val_mae: 71.0788 - 128ms/epoch - 3ms/step\n",
      "Epoch 30/200\n",
      "38/38 - 0s - loss: 27936.5859 - mae: 73.1066 - val_loss: 240557.5625 - val_mae: 72.1370 - 117ms/epoch - 3ms/step\n",
      "Epoch 31/200\n",
      "38/38 - 0s - loss: 20037.0996 - mae: 63.5700 - val_loss: 226541.2656 - val_mae: 56.7657 - 128ms/epoch - 3ms/step\n",
      "Epoch 32/200\n",
      "38/38 - 0s - loss: 13059.3584 - mae: 38.9223 - val_loss: 237573.8906 - val_mae: 51.7064 - 115ms/epoch - 3ms/step\n",
      "Epoch 33/200\n",
      "38/38 - 0s - loss: 11495.3271 - mae: 37.5813 - val_loss: 246717.1094 - val_mae: 102.5237 - 126ms/epoch - 3ms/step\n",
      "Epoch 34/200\n",
      "38/38 - 0s - loss: 54092.5117 - mae: 87.8822 - val_loss: 440207.0938 - val_mae: 270.8761 - 133ms/epoch - 4ms/step\n",
      "Epoch 35/200\n",
      "38/38 - 0s - loss: 739998.3125 - mae: 278.4282 - val_loss: 1101150.1250 - val_mae: 512.8008 - 157ms/epoch - 4ms/step\n",
      "Epoch 36/200\n",
      "38/38 - 0s - loss: 73676.8906 - mae: 134.0780 - val_loss: 236824.8438 - val_mae: 55.1882 - 131ms/epoch - 3ms/step\n",
      "Epoch 37/200\n",
      "38/38 - 0s - loss: 20839.6484 - mae: 52.0179 - val_loss: 255078.5625 - val_mae: 120.3181 - 106ms/epoch - 3ms/step\n",
      "Epoch 38/200\n",
      "38/38 - 0s - loss: 60539.0781 - mae: 114.3707 - val_loss: 261991.4688 - val_mae: 70.8973 - 111ms/epoch - 3ms/step\n",
      "Epoch 39/200\n",
      "38/38 - 0s - loss: 22123.3105 - mae: 64.7084 - val_loss: 254509.2656 - val_mae: 67.7037 - 122ms/epoch - 3ms/step\n",
      "Epoch 40/200\n",
      "38/38 - 0s - loss: 1072525.5000 - mae: 242.7223 - val_loss: 264004.5938 - val_mae: 88.4026 - 119ms/epoch - 3ms/step\n",
      "Epoch 41/200\n",
      "38/38 - 0s - loss: 13980075.0000 - mae: 1085.0803 - val_loss: 991128.6875 - val_mae: 454.1471 - 112ms/epoch - 3ms/step\n",
      "Epoch 42/200\n",
      "38/38 - 0s - loss: 5194162.0000 - mae: 767.7663 - val_loss: 2053487.8750 - val_mae: 732.9439 - 122ms/epoch - 3ms/step\n",
      "Epoch 43/200\n",
      "38/38 - 0s - loss: 525919.0625 - mae: 162.2614 - val_loss: 255782.9375 - val_mae: 88.5206 - 119ms/epoch - 3ms/step\n",
      "Epoch 44/200\n",
      "38/38 - 0s - loss: 107081.0781 - mae: 122.4608 - val_loss: 260266.7344 - val_mae: 92.9187 - 121ms/epoch - 3ms/step\n",
      "Epoch 45/200\n",
      "38/38 - 0s - loss: 19863.8340 - mae: 63.3710 - val_loss: 272130.4688 - val_mae: 65.5174 - 127ms/epoch - 3ms/step\n",
      "Epoch 46/200\n",
      "38/38 - 0s - loss: 63238.6250 - mae: 96.2431 - val_loss: 409948.5625 - val_mae: 234.2285 - 119ms/epoch - 3ms/step\n",
      "Epoch 47/200\n",
      "38/38 - 0s - loss: 116668.3203 - mae: 132.0212 - val_loss: 286265.6250 - val_mae: 135.7203 - 124ms/epoch - 3ms/step\n",
      "Epoch 48/200\n",
      "38/38 - 0s - loss: 19879.6719 - mae: 60.3374 - val_loss: 273387.6562 - val_mae: 74.4913 - 125ms/epoch - 3ms/step\n",
      "Epoch 49/200\n",
      "38/38 - 0s - loss: 21764.1309 - mae: 60.1337 - val_loss: 835544.5625 - val_mae: 413.0902 - 118ms/epoch - 3ms/step\n",
      "Epoch 50/200\n",
      "38/38 - 0s - loss: 721754.5000 - mae: 309.0274 - val_loss: 350187.8438 - val_mae: 173.3806 - 164ms/epoch - 4ms/step\n",
      "Epoch 51/200\n",
      "38/38 - 0s - loss: 22833.0293 - mae: 68.5197 - val_loss: 257427.8125 - val_mae: 70.8415 - 180ms/epoch - 5ms/step\n",
      "Epoch 52/200\n",
      "38/38 - 0s - loss: 247562.9844 - mae: 198.7937 - val_loss: 580142.0000 - val_mae: 330.5063 - 161ms/epoch - 4ms/step\n",
      "Epoch 53/200\n",
      "38/38 - 0s - loss: 308799.0000 - mae: 231.2617 - val_loss: 276828.9375 - val_mae: 65.5389 - 118ms/epoch - 3ms/step\n",
      "Epoch 54/200\n",
      "38/38 - 0s - loss: 738684.0000 - mae: 326.8199 - val_loss: 5256300.0000 - val_mae: 1198.5087 - 128ms/epoch - 3ms/step\n",
      "Epoch 55/200\n",
      "38/38 - 0s - loss: 1131018.6250 - mae: 399.1695 - val_loss: 999312.2500 - val_mae: 441.3001 - 115ms/epoch - 3ms/step\n",
      "Epoch 56/200\n",
      "38/38 - 0s - loss: 859757.7500 - mae: 353.9823 - val_loss: 328707.4375 - val_mae: 137.6014 - 126ms/epoch - 3ms/step\n",
      "Epoch 57/200\n",
      "38/38 - 0s - loss: 26560.1426 - mae: 64.5793 - val_loss: 281692.2188 - val_mae: 64.8007 - 122ms/epoch - 3ms/step\n",
      "Epoch 58/200\n",
      "38/38 - 0s - loss: 7925.7876 - mae: 38.8222 - val_loss: 276640.3125 - val_mae: 65.4510 - 116ms/epoch - 3ms/step\n",
      "Epoch 59/200\n",
      "38/38 - 0s - loss: 8793.1055 - mae: 40.2581 - val_loss: 282362.3750 - val_mae: 63.7326 - 145ms/epoch - 4ms/step\n",
      "Epoch 60/200\n",
      "38/38 - 0s - loss: 11914.7383 - mae: 50.2936 - val_loss: 301856.7812 - val_mae: 110.5824 - 109ms/epoch - 3ms/step\n",
      "Epoch 61/200\n",
      "38/38 - 0s - loss: 62894.1055 - mae: 103.7104 - val_loss: 313947.6875 - val_mae: 116.9089 - 116ms/epoch - 3ms/step\n",
      "Epoch 62/200\n",
      "38/38 - 0s - loss: 9574.2109 - mae: 41.6204 - val_loss: 295188.4375 - val_mae: 54.8590 - 160ms/epoch - 4ms/step\n",
      "Epoch 63/200\n",
      "38/38 - 0s - loss: 7547.8052 - mae: 31.4401 - val_loss: 293100.6562 - val_mae: 54.8827 - 141ms/epoch - 4ms/step\n",
      "Epoch 64/200\n",
      "38/38 - 0s - loss: 7041.7285 - mae: 31.0699 - val_loss: 295796.8438 - val_mae: 59.2737 - 129ms/epoch - 3ms/step\n",
      "Epoch 65/200\n",
      "38/38 - 0s - loss: 8582.6621 - mae: 30.3566 - val_loss: 290918.4375 - val_mae: 63.1199 - 142ms/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "38/38 - 0s - loss: 6138.0215 - mae: 28.9700 - val_loss: 296508.2812 - val_mae: 58.8536 - 134ms/epoch - 4ms/step\n",
      "Epoch 67/200\n",
      "38/38 - 0s - loss: 5955.4150 - mae: 30.0209 - val_loss: 296030.3125 - val_mae: 62.3353 - 241ms/epoch - 6ms/step\n",
      "Epoch 68/200\n",
      "38/38 - 0s - loss: 6219.5151 - mae: 32.0328 - val_loss: 299446.3750 - val_mae: 72.8633 - 145ms/epoch - 4ms/step\n",
      "Epoch 69/200\n",
      "38/38 - 0s - loss: 10084.3506 - mae: 48.8942 - val_loss: 336026.5312 - val_mae: 147.1890 - 141ms/epoch - 4ms/step\n",
      "Epoch 70/200\n",
      "38/38 - 0s - loss: 26064.6074 - mae: 72.2760 - val_loss: 320616.8438 - val_mae: 122.7293 - 153ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "38/38 - 0s - loss: 62918.0391 - mae: 123.8073 - val_loss: 314424.9062 - val_mae: 95.9395 - 140ms/epoch - 4ms/step\n",
      "Epoch 72/200\n",
      "38/38 - 0s - loss: 355268.3438 - mae: 236.5206 - val_loss: 1057252.8750 - val_mae: 474.4619 - 341ms/epoch - 9ms/step\n",
      "Epoch 73/200\n",
      "38/38 - 0s - loss: 374944.0625 - mae: 203.3232 - val_loss: 348578.6250 - val_mae: 163.0524 - 128ms/epoch - 3ms/step\n",
      "Epoch 74/200\n",
      "38/38 - 0s - loss: 285115.8125 - mae: 224.2108 - val_loss: 303304.0312 - val_mae: 87.6325 - 115ms/epoch - 3ms/step\n",
      "Epoch 75/200\n",
      "38/38 - 0s - loss: 10842.3057 - mae: 52.8263 - val_loss: 308153.7188 - val_mae: 108.9546 - 125ms/epoch - 3ms/step\n",
      "Epoch 76/200\n",
      "38/38 - 0s - loss: 11891.3916 - mae: 55.1208 - val_loss: 324932.4375 - val_mae: 138.4486 - 119ms/epoch - 3ms/step\n",
      "Epoch 77/200\n",
      "38/38 - 0s - loss: 12370.0146 - mae: 50.6811 - val_loss: 304018.5625 - val_mae: 93.4238 - 117ms/epoch - 3ms/step\n",
      "Epoch 78/200\n",
      "38/38 - 0s - loss: 4815.3726 - mae: 35.4801 - val_loss: 297075.1875 - val_mae: 58.8907 - 119ms/epoch - 3ms/step\n",
      "Epoch 79/200\n",
      "38/38 - 0s - loss: 5063.5928 - mae: 30.9788 - val_loss: 298128.2500 - val_mae: 55.1119 - 132ms/epoch - 3ms/step\n",
      "Epoch 80/200\n",
      "38/38 - 0s - loss: 5122.8145 - mae: 33.1074 - val_loss: 298249.1250 - val_mae: 64.3845 - 157ms/epoch - 4ms/step\n",
      "Epoch 81/200\n",
      "38/38 - 0s - loss: 4480.0947 - mae: 30.3353 - val_loss: 299442.7188 - val_mae: 56.0615 - 147ms/epoch - 4ms/step\n",
      "Epoch 82/200\n",
      "38/38 - 0s - loss: 6970.5474 - mae: 44.7747 - val_loss: 299036.2812 - val_mae: 66.6797 - 144ms/epoch - 4ms/step\n",
      "Epoch 83/200\n",
      "38/38 - 0s - loss: 23131.9570 - mae: 69.3806 - val_loss: 311937.5312 - val_mae: 108.3158 - 117ms/epoch - 3ms/step\n",
      "Epoch 84/200\n",
      "38/38 - 0s - loss: 9505.5273 - mae: 48.6789 - val_loss: 322228.2188 - val_mae: 128.4620 - 120ms/epoch - 3ms/step\n",
      "Epoch 85/200\n",
      "38/38 - 0s - loss: 49844.6367 - mae: 114.2091 - val_loss: 303428.5312 - val_mae: 97.3244 - 176ms/epoch - 5ms/step\n",
      "Epoch 86/200\n",
      "38/38 - 0s - loss: 67541.2031 - mae: 120.1284 - val_loss: 298063.2500 - val_mae: 71.0609 - 176ms/epoch - 5ms/step\n",
      "Epoch 87/200\n",
      "38/38 - 0s - loss: 43973.1562 - mae: 86.4116 - val_loss: 313159.4375 - val_mae: 94.3958 - 193ms/epoch - 5ms/step\n",
      "Epoch 88/200\n",
      "38/38 - 0s - loss: 11619.9805 - mae: 52.9597 - val_loss: 305688.5938 - val_mae: 104.8161 - 162ms/epoch - 4ms/step\n",
      "Epoch 89/200\n",
      "38/38 - 0s - loss: 9678.6963 - mae: 49.0782 - val_loss: 299432.2500 - val_mae: 79.6811 - 154ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "38/38 - 0s - loss: 8081.5864 - mae: 45.8934 - val_loss: 316511.1562 - val_mae: 125.5145 - 127ms/epoch - 3ms/step\n",
      "Epoch 91/200\n",
      "38/38 - 0s - loss: 70790.6172 - mae: 120.8428 - val_loss: 799894.7500 - val_mae: 411.3705 - 124ms/epoch - 3ms/step\n",
      "Epoch 92/200\n",
      "38/38 - 0s - loss: 2896670.0000 - mae: 641.1062 - val_loss: 2873310.7500 - val_mae: 811.9797 - 151ms/epoch - 4ms/step\n",
      "Epoch 93/200\n",
      "38/38 - 0s - loss: 355882.6875 - mae: 182.0202 - val_loss: 314300.1250 - val_mae: 130.7135 - 174ms/epoch - 5ms/step\n",
      "Epoch 94/200\n",
      "38/38 - 0s - loss: 12064.2246 - mae: 55.7837 - val_loss: 301097.8438 - val_mae: 69.6845 - 173ms/epoch - 5ms/step\n",
      "Epoch 95/200\n",
      "38/38 - 0s - loss: 5149.4014 - mae: 30.9043 - val_loss: 298510.1562 - val_mae: 59.1235 - 159ms/epoch - 4ms/step\n",
      "Epoch 96/200\n",
      "38/38 - 0s - loss: 4765.2202 - mae: 29.4573 - val_loss: 295745.3125 - val_mae: 55.6223 - 147ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "38/38 - 0s - loss: 4321.6260 - mae: 27.8985 - val_loss: 296967.8125 - val_mae: 55.0523 - 139ms/epoch - 4ms/step\n",
      "Epoch 98/200\n",
      "38/38 - 0s - loss: 3999.1367 - mae: 26.4162 - val_loss: 295773.0938 - val_mae: 55.3146 - 133ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "38/38 - 0s - loss: 3991.1904 - mae: 26.5631 - val_loss: 297022.4688 - val_mae: 55.6260 - 142ms/epoch - 4ms/step\n",
      "Epoch 100/200\n",
      "38/38 - 0s - loss: 4272.8149 - mae: 26.7143 - val_loss: 296973.0938 - val_mae: 55.7502 - 163ms/epoch - 4ms/step\n",
      "Epoch 101/200\n",
      "38/38 - 0s - loss: 3936.9753 - mae: 26.3386 - val_loss: 296204.5312 - val_mae: 54.7644 - 147ms/epoch - 4ms/step\n",
      "Epoch 102/200\n",
      "38/38 - 0s - loss: 3825.7188 - mae: 25.6071 - val_loss: 295371.0000 - val_mae: 54.2850 - 125ms/epoch - 3ms/step\n",
      "Epoch 103/200\n",
      "38/38 - 0s - loss: 3994.3147 - mae: 25.6183 - val_loss: 296034.9062 - val_mae: 54.9438 - 125ms/epoch - 3ms/step\n",
      "Epoch 104/200\n",
      "38/38 - 0s - loss: 4659.9844 - mae: 27.7518 - val_loss: 297038.2500 - val_mae: 58.9854 - 135ms/epoch - 4ms/step\n",
      "Epoch 105/200\n",
      "38/38 - 0s - loss: 4363.0991 - mae: 27.1542 - val_loss: 294945.1875 - val_mae: 55.5228 - 133ms/epoch - 4ms/step\n",
      "Epoch 106/200\n",
      "38/38 - 0s - loss: 3946.5046 - mae: 25.5913 - val_loss: 303395.3438 - val_mae: 59.8905 - 138ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "38/38 - 0s - loss: 5458.4077 - mae: 27.5527 - val_loss: 296946.9062 - val_mae: 56.1418 - 144ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "38/38 - 0s - loss: 5552.9214 - mae: 27.2874 - val_loss: 297453.8438 - val_mae: 54.6379 - 127ms/epoch - 3ms/step\n",
      "Epoch 109/200\n",
      "38/38 - 0s - loss: 5338.1914 - mae: 28.6046 - val_loss: 294995.7812 - val_mae: 55.2705 - 127ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "38/38 - 0s - loss: 4226.6821 - mae: 26.0391 - val_loss: 296376.5938 - val_mae: 56.1468 - 192ms/epoch - 5ms/step\n",
      "Epoch 111/200\n",
      "38/38 - 0s - loss: 3699.0300 - mae: 24.9434 - val_loss: 294751.6562 - val_mae: 56.2503 - 229ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "38/38 - 0s - loss: 6534.0586 - mae: 40.1142 - val_loss: 295474.5312 - val_mae: 54.2243 - 171ms/epoch - 4ms/step\n",
      "Epoch 113/200\n",
      "38/38 - 0s - loss: 5357.0806 - mae: 33.5811 - val_loss: 296486.4688 - val_mae: 62.3813 - 192ms/epoch - 5ms/step\n",
      "Epoch 114/200\n",
      "38/38 - 0s - loss: 4185.7661 - mae: 29.4245 - val_loss: 296253.2188 - val_mae: 60.6996 - 197ms/epoch - 5ms/step\n",
      "Epoch 115/200\n",
      "38/38 - 0s - loss: 4496.2598 - mae: 33.2462 - val_loss: 297974.9688 - val_mae: 69.0228 - 138ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "38/38 - 0s - loss: 4038.4062 - mae: 29.7805 - val_loss: 296430.7500 - val_mae: 54.7236 - 133ms/epoch - 4ms/step\n",
      "Epoch 117/200\n",
      "38/38 - 0s - loss: 3813.4270 - mae: 27.7669 - val_loss: 296328.9062 - val_mae: 57.4510 - 135ms/epoch - 4ms/step\n",
      "Epoch 118/200\n",
      "38/38 - 0s - loss: 3828.8230 - mae: 26.7533 - val_loss: 296727.9375 - val_mae: 57.9586 - 136ms/epoch - 4ms/step\n",
      "Epoch 119/200\n",
      "38/38 - 0s - loss: 3642.2100 - mae: 25.6472 - val_loss: 296114.8750 - val_mae: 53.5810 - 121ms/epoch - 3ms/step\n",
      "Epoch 120/200\n",
      "38/38 - 0s - loss: 3472.8625 - mae: 23.5280 - val_loss: 296240.9062 - val_mae: 53.5873 - 158ms/epoch - 4ms/step\n",
      "Epoch 121/200\n",
      "38/38 - 0s - loss: 3456.9814 - mae: 23.4640 - val_loss: 295802.5625 - val_mae: 53.3362 - 162ms/epoch - 4ms/step\n",
      "Epoch 122/200\n",
      "38/38 - 0s - loss: 3674.4275 - mae: 23.8862 - val_loss: 296320.1875 - val_mae: 55.9649 - 133ms/epoch - 3ms/step\n",
      "Epoch 123/200\n",
      "38/38 - 0s - loss: 3648.5176 - mae: 26.7862 - val_loss: 295808.5312 - val_mae: 59.6124 - 127ms/epoch - 3ms/step\n",
      "Epoch 124/200\n",
      "38/38 - 0s - loss: 3465.3491 - mae: 23.9438 - val_loss: 295771.2500 - val_mae: 52.9922 - 137ms/epoch - 4ms/step\n",
      "Epoch 125/200\n",
      "38/38 - 0s - loss: 3415.8840 - mae: 22.5339 - val_loss: 295445.8125 - val_mae: 54.2124 - 132ms/epoch - 3ms/step\n",
      "Epoch 126/200\n",
      "38/38 - 0s - loss: 3522.1799 - mae: 23.9690 - val_loss: 295901.7188 - val_mae: 55.0596 - 166ms/epoch - 4ms/step\n",
      "Epoch 127/200\n",
      "38/38 - 0s - loss: 3371.6416 - mae: 23.3368 - val_loss: 296647.0938 - val_mae: 55.1059 - 136ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "38/38 - 0s - loss: 3339.8315 - mae: 23.4191 - val_loss: 296204.2500 - val_mae: 54.8564 - 129ms/epoch - 3ms/step\n",
      "Epoch 129/200\n",
      "38/38 - 0s - loss: 3415.4375 - mae: 23.4619 - val_loss: 296343.1875 - val_mae: 53.6444 - 132ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "38/38 - 0s - loss: 6353.9448 - mae: 38.3250 - val_loss: 296388.9688 - val_mae: 63.0233 - 129ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "38/38 - 0s - loss: 36084.2500 - mae: 85.6823 - val_loss: 600107.9375 - val_mae: 332.0417 - 131ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "38/38 - 0s - loss: 459016.5938 - mae: 219.7191 - val_loss: 297496.9688 - val_mae: 62.9100 - 124ms/epoch - 3ms/step\n",
      "Epoch 133/200\n",
      "38/38 - 0s - loss: 6621.2437 - mae: 40.8266 - val_loss: 296095.3750 - val_mae: 66.0025 - 122ms/epoch - 3ms/step\n",
      "Epoch 134/200\n",
      "38/38 - 0s - loss: 6401.5977 - mae: 33.9011 - val_loss: 298008.9062 - val_mae: 61.1963 - 134ms/epoch - 4ms/step\n",
      "Epoch 135/200\n",
      "38/38 - 0s - loss: 5119.2539 - mae: 31.4570 - val_loss: 295212.6250 - val_mae: 58.6899 - 149ms/epoch - 4ms/step\n",
      "Epoch 136/200\n",
      "38/38 - 0s - loss: 4746.1089 - mae: 29.2712 - val_loss: 295306.7188 - val_mae: 57.9949 - 128ms/epoch - 3ms/step\n",
      "Epoch 137/200\n",
      "38/38 - 0s - loss: 4410.8794 - mae: 28.0425 - val_loss: 296228.2188 - val_mae: 58.5350 - 132ms/epoch - 3ms/step\n",
      "Epoch 138/200\n",
      "38/38 - 0s - loss: 4536.7480 - mae: 28.4703 - val_loss: 296255.8125 - val_mae: 57.7823 - 130ms/epoch - 3ms/step\n",
      "Epoch 139/200\n",
      "38/38 - 0s - loss: 4743.7324 - mae: 28.3951 - val_loss: 297071.0000 - val_mae: 58.1788 - 128ms/epoch - 3ms/step\n",
      "Epoch 140/200\n",
      "38/38 - 0s - loss: 4871.4502 - mae: 28.5461 - val_loss: 296974.8438 - val_mae: 57.6222 - 135ms/epoch - 4ms/step\n",
      "Epoch 141/200\n",
      "38/38 - 0s - loss: 5531.5801 - mae: 28.5018 - val_loss: 296880.0625 - val_mae: 57.9161 - 131ms/epoch - 3ms/step\n",
      "Epoch 142/200\n",
      "38/38 - 0s - loss: 12467.8906 - mae: 34.4361 - val_loss: 299113.0625 - val_mae: 65.4434 - 134ms/epoch - 4ms/step\n",
      "Epoch 143/200\n",
      "38/38 - 0s - loss: 11430.0850 - mae: 35.3409 - val_loss: 297267.7188 - val_mae: 60.2212 - 131ms/epoch - 3ms/step\n",
      "Epoch 144/200\n",
      "38/38 - 0s - loss: 12151.0000 - mae: 32.8940 - val_loss: 290894.5938 - val_mae: 55.7706 - 150ms/epoch - 4ms/step\n",
      "Epoch 145/200\n",
      "38/38 - 0s - loss: 4737.7827 - mae: 27.8456 - val_loss: 292319.1875 - val_mae: 55.7443 - 141ms/epoch - 4ms/step\n",
      "Epoch 146/200\n",
      "38/38 - 0s - loss: 4266.1909 - mae: 26.4103 - val_loss: 292476.3750 - val_mae: 55.9106 - 123ms/epoch - 3ms/step\n",
      "Epoch 147/200\n",
      "38/38 - 0s - loss: 4135.4019 - mae: 25.9372 - val_loss: 293191.2812 - val_mae: 55.6494 - 131ms/epoch - 3ms/step\n",
      "Epoch 148/200\n",
      "38/38 - 0s - loss: 3996.3767 - mae: 25.0749 - val_loss: 293083.9375 - val_mae: 55.9060 - 123ms/epoch - 3ms/step\n",
      "Epoch 149/200\n",
      "38/38 - 0s - loss: 4062.8279 - mae: 25.5263 - val_loss: 292964.3125 - val_mae: 55.8274 - 136ms/epoch - 4ms/step\n",
      "Epoch 150/200\n",
      "38/38 - 0s - loss: 3916.9807 - mae: 25.0391 - val_loss: 293864.4688 - val_mae: 56.6146 - 135ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "38/38 - 0s - loss: 3877.6279 - mae: 24.6704 - val_loss: 293245.5312 - val_mae: 56.3265 - 135ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "38/38 - 0s - loss: 3806.8943 - mae: 24.3156 - val_loss: 293378.9062 - val_mae: 56.2350 - 138ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "38/38 - 0s - loss: 3749.4045 - mae: 24.1741 - val_loss: 293990.8750 - val_mae: 57.0340 - 132ms/epoch - 3ms/step\n",
      "Epoch 154/200\n",
      "38/38 - 0s - loss: 3743.0884 - mae: 24.1463 - val_loss: 293486.0938 - val_mae: 55.8028 - 135ms/epoch - 4ms/step\n",
      "Epoch 155/200\n",
      "38/38 - 0s - loss: 3755.7913 - mae: 24.1042 - val_loss: 293598.2812 - val_mae: 55.6662 - 135ms/epoch - 4ms/step\n",
      "Epoch 156/200\n",
      "38/38 - 0s - loss: 3830.4663 - mae: 24.4551 - val_loss: 293144.8438 - val_mae: 55.5319 - 144ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "38/38 - 0s - loss: 3813.2583 - mae: 24.3077 - val_loss: 292937.5625 - val_mae: 55.2218 - 151ms/epoch - 4ms/step\n",
      "Epoch 158/200\n",
      "38/38 - 0s - loss: 3664.2595 - mae: 23.7584 - val_loss: 293580.2812 - val_mae: 55.6767 - 142ms/epoch - 4ms/step\n",
      "Epoch 159/200\n",
      "38/38 - 0s - loss: 3588.9717 - mae: 23.3873 - val_loss: 293454.6562 - val_mae: 55.3433 - 130ms/epoch - 3ms/step\n",
      "Epoch 160/200\n",
      "38/38 - 0s - loss: 3582.0730 - mae: 23.3461 - val_loss: 293054.6562 - val_mae: 55.3298 - 128ms/epoch - 3ms/step\n",
      "Epoch 161/200\n",
      "38/38 - 0s - loss: 3523.4741 - mae: 23.4598 - val_loss: 294605.5312 - val_mae: 57.6401 - 127ms/epoch - 3ms/step\n",
      "Epoch 162/200\n",
      "38/38 - 0s - loss: 3494.9197 - mae: 23.4147 - val_loss: 293303.1562 - val_mae: 56.4936 - 127ms/epoch - 3ms/step\n",
      "Epoch 163/200\n",
      "38/38 - 0s - loss: 3489.7351 - mae: 23.5380 - val_loss: 294325.9688 - val_mae: 56.0364 - 140ms/epoch - 4ms/step\n",
      "Epoch 164/200\n",
      "38/38 - 0s - loss: 3441.1328 - mae: 23.2182 - val_loss: 293506.0938 - val_mae: 55.2322 - 133ms/epoch - 3ms/step\n",
      "Epoch 165/200\n",
      "38/38 - 0s - loss: 3368.2026 - mae: 23.6146 - val_loss: 293807.7188 - val_mae: 54.2570 - 140ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "38/38 - 0s - loss: 3311.4033 - mae: 23.1196 - val_loss: 294107.1875 - val_mae: 55.3211 - 148ms/epoch - 4ms/step\n",
      "Epoch 167/200\n",
      "38/38 - 0s - loss: 3254.1123 - mae: 22.6864 - val_loss: 295152.9375 - val_mae: 56.9339 - 148ms/epoch - 4ms/step\n",
      "Epoch 168/200\n",
      "38/38 - 0s - loss: 3351.8315 - mae: 23.4477 - val_loss: 295295.6875 - val_mae: 54.5832 - 144ms/epoch - 4ms/step\n",
      "Epoch 169/200\n",
      "38/38 - 0s - loss: 3304.4001 - mae: 22.3989 - val_loss: 294194.4688 - val_mae: 55.2300 - 130ms/epoch - 3ms/step\n",
      "Epoch 170/200\n",
      "38/38 - 0s - loss: 3301.2371 - mae: 23.6520 - val_loss: 294441.5938 - val_mae: 61.5690 - 131ms/epoch - 3ms/step\n",
      "Epoch 171/200\n",
      "38/38 - 0s - loss: 3322.7815 - mae: 23.6563 - val_loss: 294105.6875 - val_mae: 56.3327 - 128ms/epoch - 3ms/step\n",
      "Epoch 172/200\n",
      "38/38 - 0s - loss: 3384.1406 - mae: 23.6925 - val_loss: 295050.6250 - val_mae: 58.4587 - 124ms/epoch - 3ms/step\n",
      "Epoch 173/200\n",
      "38/38 - 0s - loss: 3562.0979 - mae: 24.1016 - val_loss: 295067.7812 - val_mae: 54.4032 - 130ms/epoch - 3ms/step\n",
      "Epoch 174/200\n",
      "38/38 - 0s - loss: 3426.1880 - mae: 22.7606 - val_loss: 294328.6875 - val_mae: 54.6843 - 134ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "38/38 - 0s - loss: 3170.2483 - mae: 22.3256 - val_loss: 295096.5938 - val_mae: 54.4765 - 134ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "38/38 - 0s - loss: 3137.2666 - mae: 21.1060 - val_loss: 294769.8438 - val_mae: 53.8919 - 130ms/epoch - 3ms/step\n",
      "Epoch 177/200\n",
      "38/38 - 0s - loss: 3167.8079 - mae: 21.6031 - val_loss: 295227.4688 - val_mae: 55.4345 - 131ms/epoch - 3ms/step\n",
      "Epoch 178/200\n",
      "38/38 - 0s - loss: 3164.8516 - mae: 21.4875 - val_loss: 296057.9688 - val_mae: 54.2812 - 129ms/epoch - 3ms/step\n",
      "Epoch 179/200\n",
      "38/38 - 0s - loss: 3355.4707 - mae: 22.0741 - val_loss: 295574.2188 - val_mae: 53.2651 - 135ms/epoch - 4ms/step\n",
      "Epoch 180/200\n",
      "38/38 - 0s - loss: 3287.2134 - mae: 22.0673 - val_loss: 295458.5000 - val_mae: 53.8762 - 150ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "38/38 - 0s - loss: 3242.4312 - mae: 22.1416 - val_loss: 295615.7812 - val_mae: 54.2362 - 132ms/epoch - 3ms/step\n",
      "Epoch 182/200\n",
      "38/38 - 0s - loss: 3335.7446 - mae: 21.9828 - val_loss: 295395.2500 - val_mae: 52.9294 - 121ms/epoch - 3ms/step\n",
      "Epoch 183/200\n",
      "38/38 - 0s - loss: 3201.4336 - mae: 21.6598 - val_loss: 296808.8750 - val_mae: 56.2544 - 122ms/epoch - 3ms/step\n",
      "Epoch 184/200\n",
      "38/38 - 0s - loss: 3297.4089 - mae: 22.1097 - val_loss: 296483.2812 - val_mae: 53.6953 - 135ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "38/38 - 0s - loss: 3420.2134 - mae: 22.5530 - val_loss: 296397.7500 - val_mae: 53.4409 - 141ms/epoch - 4ms/step\n",
      "Epoch 186/200\n",
      "38/38 - 0s - loss: 3159.9065 - mae: 21.1142 - val_loss: 296136.4688 - val_mae: 54.5991 - 130ms/epoch - 3ms/step\n",
      "Epoch 187/200\n",
      "38/38 - 0s - loss: 3430.2021 - mae: 21.7038 - val_loss: 298207.9375 - val_mae: 55.2841 - 122ms/epoch - 3ms/step\n",
      "Epoch 188/200\n",
      "38/38 - 0s - loss: 4329.3174 - mae: 25.1413 - val_loss: 294612.5938 - val_mae: 54.0827 - 121ms/epoch - 3ms/step\n",
      "Epoch 189/200\n",
      "38/38 - 0s - loss: 5446.4248 - mae: 25.3638 - val_loss: 294962.7812 - val_mae: 52.0484 - 123ms/epoch - 3ms/step\n",
      "Epoch 190/200\n",
      "38/38 - 0s - loss: 5302.1289 - mae: 24.7861 - val_loss: 293014.4062 - val_mae: 53.4271 - 131ms/epoch - 3ms/step\n",
      "Epoch 191/200\n",
      "38/38 - 0s - loss: 3483.0151 - mae: 23.1667 - val_loss: 293326.2188 - val_mae: 52.2706 - 154ms/epoch - 4ms/step\n",
      "Epoch 192/200\n",
      "38/38 - 0s - loss: 3404.0503 - mae: 22.6141 - val_loss: 293692.6250 - val_mae: 56.3377 - 143ms/epoch - 4ms/step\n",
      "Epoch 193/200\n",
      "38/38 - 0s - loss: 3281.1931 - mae: 22.2334 - val_loss: 296578.2500 - val_mae: 56.0503 - 129ms/epoch - 3ms/step\n",
      "Epoch 194/200\n",
      "38/38 - 0s - loss: 3398.5586 - mae: 21.9521 - val_loss: 293784.8438 - val_mae: 53.0154 - 134ms/epoch - 4ms/step\n",
      "Epoch 195/200\n",
      "38/38 - 0s - loss: 3120.0117 - mae: 21.1285 - val_loss: 293423.1875 - val_mae: 53.7594 - 125ms/epoch - 3ms/step\n",
      "Epoch 196/200\n",
      "38/38 - 0s - loss: 3276.0337 - mae: 21.1679 - val_loss: 295027.7812 - val_mae: 53.8227 - 118ms/epoch - 3ms/step\n",
      "Epoch 197/200\n",
      "38/38 - 0s - loss: 3380.5874 - mae: 21.4707 - val_loss: 293215.7500 - val_mae: 54.2858 - 122ms/epoch - 3ms/step\n",
      "Epoch 198/200\n",
      "38/38 - 0s - loss: 3345.5720 - mae: 22.5964 - val_loss: 294566.9688 - val_mae: 52.7931 - 127ms/epoch - 3ms/step\n",
      "Epoch 199/200\n",
      "38/38 - 0s - loss: 3205.5769 - mae: 21.2922 - val_loss: 295146.7812 - val_mae: 53.2807 - 122ms/epoch - 3ms/step\n",
      "Epoch 200/200\n",
      "38/38 - 0s - loss: 3137.1995 - mae: 21.2741 - val_loss: 293764.1250 - val_mae: 53.4570 - 131ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# MLP\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "def build_model(num_input=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=num_input))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    # activation = 'identity', 'logistic', 'tanh', 'relu'\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(num_input=26)\n",
    "\n",
    "# mini bath\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=2)\n",
    "\n",
    "# evaluate\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "# cross validation\n",
    "model = build_model(num_input=26)\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=200, validation_split=0.25, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a8a29214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.10064560e+02],\n",
       "       [ 1.73234158e+01],\n",
       "       [ 1.20335197e+01],\n",
       "       [ 1.49278564e+01],\n",
       "       [ 1.22598274e+02],\n",
       "       [ 1.16291656e+01],\n",
       "       [ 1.61993317e+02],\n",
       "       [ 4.00593948e+00],\n",
       "       [ 1.33348312e+01],\n",
       "       [ 5.15557480e+00],\n",
       "       [ 2.13261852e+01],\n",
       "       [ 2.60551666e+02],\n",
       "       [ 2.73427765e+02],\n",
       "       [ 5.54477310e+00],\n",
       "       [ 3.71873840e+02],\n",
       "       [ 1.87420311e+01],\n",
       "       [ 1.62942337e+02],\n",
       "       [ 1.07323547e+03],\n",
       "       [ 6.01062813e+01],\n",
       "       [ 6.00191116e+00],\n",
       "       [ 2.44948921e+01],\n",
       "       [ 1.87231827e+00],\n",
       "       [ 6.18508530e+00],\n",
       "       [ 1.57796974e+01],\n",
       "       [ 6.83614731e+00],\n",
       "       [ 5.00187302e+00],\n",
       "       [ 4.03654861e+00],\n",
       "       [ 6.80505753e+00],\n",
       "       [ 5.16615677e+00],\n",
       "       [ 1.35985535e+02],\n",
       "       [ 2.48128014e+01],\n",
       "       [ 2.08653698e+01],\n",
       "       [ 2.24563122e+01],\n",
       "       [ 3.59374580e+01],\n",
       "       [ 3.37666702e+00],\n",
       "       [ 2.49339676e+00],\n",
       "       [ 3.69852257e+01],\n",
       "       [ 1.89922943e+01],\n",
       "       [ 9.18281067e+02],\n",
       "       [ 7.10488510e+00],\n",
       "       [ 2.01370583e+01],\n",
       "       [ 4.24503708e+00],\n",
       "       [ 1.46439552e+01],\n",
       "       [ 1.60347214e+01],\n",
       "       [ 1.81282822e+02],\n",
       "       [ 1.36791954e+01],\n",
       "       [ 6.78556641e+02],\n",
       "       [ 1.24693680e+01],\n",
       "       [ 4.35391617e+00],\n",
       "       [ 1.41560318e+02],\n",
       "       [ 1.91776142e+01],\n",
       "       [ 2.25999584e+01],\n",
       "       [ 2.23286476e+01],\n",
       "       [ 9.29684067e+00],\n",
       "       [ 3.90826797e+00],\n",
       "       [ 1.98171177e+01],\n",
       "       [ 9.62234116e+00],\n",
       "       [ 1.29958649e+01],\n",
       "       [ 7.30066040e+02],\n",
       "       [ 8.32229996e+00],\n",
       "       [ 8.57072830e+00],\n",
       "       [ 8.52975845e+00],\n",
       "       [ 5.05149460e+00],\n",
       "       [-2.71514511e+00],\n",
       "       [ 4.23606537e+02],\n",
       "       [ 2.31991577e+01],\n",
       "       [ 6.28151321e+00],\n",
       "       [ 7.18909073e+00],\n",
       "       [-2.80334854e+00],\n",
       "       [ 2.17327938e+01],\n",
       "       [ 2.95554047e+02],\n",
       "       [ 1.88328648e+01],\n",
       "       [ 1.04836082e+01],\n",
       "       [ 2.41469147e+02],\n",
       "       [ 7.87547684e+00],\n",
       "       [ 1.25225143e+01],\n",
       "       [ 2.32223816e+01],\n",
       "       [ 5.62962723e+00],\n",
       "       [ 1.68593597e+01],\n",
       "       [ 3.39075089e+01],\n",
       "       [ 9.91865158e+01],\n",
       "       [ 6.14424515e+00],\n",
       "       [ 1.68897400e+02],\n",
       "       [ 3.18660706e+02],\n",
       "       [ 6.06440315e+01],\n",
       "       [ 1.50066513e+02],\n",
       "       [ 1.79165802e+01],\n",
       "       [ 5.25151443e+00],\n",
       "       [ 2.56002808e+01],\n",
       "       [ 1.05335960e+01],\n",
       "       [ 2.82169830e+02],\n",
       "       [ 1.39251328e+01],\n",
       "       [ 1.33978928e+02],\n",
       "       [ 9.51263046e+00],\n",
       "       [ 6.16830063e+00],\n",
       "       [ 4.44402695e+00],\n",
       "       [ 3.81845398e+01],\n",
       "       [ 2.65156803e+01],\n",
       "       [ 4.54327774e+00],\n",
       "       [ 7.84967422e+00],\n",
       "       [ 1.02331909e+02],\n",
       "       [ 1.04279533e+02],\n",
       "       [ 1.79898472e+01],\n",
       "       [ 2.38926117e+02],\n",
       "       [ 1.09855133e+02],\n",
       "       [ 3.62343216e+00],\n",
       "       [ 1.26946182e+01],\n",
       "       [ 4.75420761e+00],\n",
       "       [ 1.33302765e+01],\n",
       "       [ 4.43704605e+00],\n",
       "       [ 5.56402969e+00],\n",
       "       [ 2.05743790e+00],\n",
       "       [ 7.50237656e+00],\n",
       "       [ 9.41824722e+00],\n",
       "       [ 6.67641830e+00],\n",
       "       [ 2.61566887e+01],\n",
       "       [ 1.66897774e+01],\n",
       "       [ 4.22639847e+00],\n",
       "       [ 2.57635895e+02],\n",
       "       [ 1.58738594e+01],\n",
       "       [ 8.56358719e+00],\n",
       "       [-2.82921982e+00],\n",
       "       [ 2.28972092e+01],\n",
       "       [ 4.19051170e+01],\n",
       "       [ 6.68942337e+01],\n",
       "       [ 1.47179832e+01],\n",
       "       [ 2.41756744e+01],\n",
       "       [ 2.31912613e+00],\n",
       "       [ 2.20034576e+02],\n",
       "       [ 2.61339226e+01],\n",
       "       [ 1.33006248e+01],\n",
       "       [ 1.51005402e+01],\n",
       "       [ 3.19472122e+00],\n",
       "       [ 1.65644989e+01],\n",
       "       [ 1.25537758e+01],\n",
       "       [ 1.78234138e+01],\n",
       "       [ 3.82626686e+01],\n",
       "       [ 2.16214905e+02],\n",
       "       [ 6.70778275e+00],\n",
       "       [ 1.91924496e+01],\n",
       "       [ 7.07541321e+02],\n",
       "       [ 8.72620010e+00],\n",
       "       [ 2.19907608e+01],\n",
       "       [ 1.88570576e+01],\n",
       "       [-1.72033653e+01],\n",
       "       [ 4.48506531e+02],\n",
       "       [ 2.54898930e+01],\n",
       "       [ 1.18364273e+02],\n",
       "       [ 5.36385727e+00],\n",
       "       [ 4.60290146e+00],\n",
       "       [ 1.51429939e+01],\n",
       "       [ 9.74743271e+00],\n",
       "       [ 1.07828102e+01],\n",
       "       [ 4.39224625e+00],\n",
       "       [ 3.70138931e+00],\n",
       "       [ 1.00764847e+01],\n",
       "       [ 1.45796776e+01],\n",
       "       [ 4.50523758e+00],\n",
       "       [ 4.71626434e+02],\n",
       "       [ 1.92470131e+01],\n",
       "       [ 4.10296249e+00],\n",
       "       [ 1.05465363e+02],\n",
       "       [ 4.89656792e+01],\n",
       "       [ 5.05115128e+00],\n",
       "       [ 2.18058624e+01],\n",
       "       [ 5.14126968e+00],\n",
       "       [ 4.53608322e+00],\n",
       "       [ 1.98647766e+01],\n",
       "       [ 4.04063797e+00],\n",
       "       [ 1.47070923e+01],\n",
       "       [-3.07032433e+01],\n",
       "       [ 1.04043610e+02],\n",
       "       [ 3.60225296e+00],\n",
       "       [ 3.44679642e+00],\n",
       "       [ 1.49843140e+01],\n",
       "       [ 1.17583847e+01],\n",
       "       [ 1.08549271e+01],\n",
       "       [ 4.03828812e+00],\n",
       "       [ 2.04791641e+00],\n",
       "       [ 1.54120712e+01],\n",
       "       [ 1.96252823e+01],\n",
       "       [ 2.91587280e+02],\n",
       "       [ 8.55736923e+00],\n",
       "       [ 1.97125244e+01],\n",
       "       [ 1.74477272e+01],\n",
       "       [ 1.40070847e+02],\n",
       "       [ 1.83705730e+01],\n",
       "       [ 9.74658585e+00],\n",
       "       [ 1.79790955e+01],\n",
       "       [-1.66881981e+01],\n",
       "       [ 8.93747711e+00],\n",
       "       [ 7.43509293e+00],\n",
       "       [ 1.35086098e+01],\n",
       "       [ 3.02684402e+00],\n",
       "       [ 3.85569382e+00],\n",
       "       [ 1.02250099e+01],\n",
       "       [ 1.90864929e+02],\n",
       "       [ 6.07190323e+00],\n",
       "       [ 2.64625282e+01],\n",
       "       [ 2.12372608e+01],\n",
       "       [ 2.86508293e+01],\n",
       "       [ 1.56241989e+01],\n",
       "       [ 2.16293045e+02],\n",
       "       [ 1.13167038e+01],\n",
       "       [ 1.82661438e+00],\n",
       "       [ 5.48096680e+02],\n",
       "       [ 1.44983978e+01],\n",
       "       [ 1.68970108e+00],\n",
       "       [ 1.30754128e+01],\n",
       "       [ 2.24272537e+00],\n",
       "       [ 2.73055237e+02],\n",
       "       [ 1.05786407e+02],\n",
       "       [ 1.08062195e+02],\n",
       "       [ 6.02517319e+00],\n",
       "       [ 1.30476799e+01],\n",
       "       [-8.49670029e+00],\n",
       "       [ 3.52359390e+00],\n",
       "       [ 2.90385437e+02],\n",
       "       [ 2.19573021e+01],\n",
       "       [ 5.21604538e+00],\n",
       "       [ 2.35412155e+02],\n",
       "       [ 4.89387131e+00],\n",
       "       [ 9.61707611e+01],\n",
       "       [ 3.21770096e+00],\n",
       "       [ 1.10942421e+01],\n",
       "       [ 1.84317131e+01],\n",
       "       [ 9.54584885e+00],\n",
       "       [ 4.86894608e+00],\n",
       "       [ 5.48582840e+00],\n",
       "       [ 5.33117294e+00],\n",
       "       [ 1.57363091e+01],\n",
       "       [ 1.66766525e+02],\n",
       "       [ 2.30373001e+00],\n",
       "       [ 2.11854706e+01],\n",
       "       [ 5.14214706e+00],\n",
       "       [ 5.52857590e+00],\n",
       "       [ 1.49374504e+01],\n",
       "       [-3.84511185e+00],\n",
       "       [ 4.24654007e+00],\n",
       "       [ 1.59937454e+02],\n",
       "       [ 5.26449203e+00],\n",
       "       [ 5.42936325e+00],\n",
       "       [ 1.06051521e+01],\n",
       "       [ 9.67431793e+01],\n",
       "       [ 1.95982647e+01],\n",
       "       [ 1.63774605e+01],\n",
       "       [ 2.53260365e+01],\n",
       "       [ 1.85817146e+01],\n",
       "       [ 2.45503693e+01],\n",
       "       [ 1.80322037e+01],\n",
       "       [ 5.34302139e+00],\n",
       "       [ 9.59299698e+01],\n",
       "       [ 5.01195145e+00],\n",
       "       [ 3.26222153e+01],\n",
       "       [-2.51534386e+01],\n",
       "       [ 4.30170822e+00],\n",
       "       [ 2.71567078e+02],\n",
       "       [ 6.21165848e+00],\n",
       "       [ 3.11945305e+01],\n",
       "       [ 1.31556053e+01],\n",
       "       [ 3.63508987e+00],\n",
       "       [ 1.12321854e+02],\n",
       "       [ 2.04022942e+01],\n",
       "       [ 9.84662857e+01],\n",
       "       [ 3.46075058e+00],\n",
       "       [ 9.91810989e+00],\n",
       "       [ 8.42530441e+00],\n",
       "       [ 1.56426525e+01],\n",
       "       [ 3.15496483e+01],\n",
       "       [ 4.36040115e+00],\n",
       "       [ 9.47554169e+01],\n",
       "       [ 1.20426598e+01],\n",
       "       [ 5.66662979e+00],\n",
       "       [ 2.44971275e+01],\n",
       "       [ 2.22881393e+01],\n",
       "       [ 2.43845139e+01],\n",
       "       [ 2.23251152e+01],\n",
       "       [ 8.50922012e+00],\n",
       "       [ 4.64416122e+00],\n",
       "       [-1.83851280e+01],\n",
       "       [ 2.44458199e+01],\n",
       "       [ 6.07707596e+00],\n",
       "       [ 1.05275185e+02],\n",
       "       [ 5.42911470e-01],\n",
       "       [ 2.92831802e+00],\n",
       "       [ 5.43680954e+00],\n",
       "       [ 1.50007381e+01],\n",
       "       [ 1.70964851e+01],\n",
       "       [ 9.51013947e+00],\n",
       "       [ 2.45879730e+02],\n",
       "       [ 6.64003143e+01],\n",
       "       [ 8.59714127e+00],\n",
       "       [ 3.21212387e+00],\n",
       "       [ 1.75587311e+01],\n",
       "       [ 4.07892227e+00],\n",
       "       [ 2.73711014e+00],\n",
       "       [ 2.14732475e+01],\n",
       "       [ 3.79945755e+00],\n",
       "       [ 4.47724533e+00],\n",
       "       [ 1.75612621e+01],\n",
       "       [ 1.30806366e+02],\n",
       "       [ 4.52258682e+00],\n",
       "       [ 5.16096878e+00],\n",
       "       [ 1.31763718e+02],\n",
       "       [ 1.03407898e+01],\n",
       "       [ 1.59348923e+02],\n",
       "       [ 8.13608246e+01],\n",
       "       [ 7.07967758e+00],\n",
       "       [ 1.34376411e+01],\n",
       "       [ 6.54025269e+01],\n",
       "       [ 2.98048782e+00],\n",
       "       [ 3.23066528e+02],\n",
       "       [ 3.86825943e+00],\n",
       "       [ 1.39956703e+01],\n",
       "       [ 9.18395996e+00],\n",
       "       [ 4.51950569e+01],\n",
       "       [ 2.95554352e+02],\n",
       "       [ 9.58498764e+00],\n",
       "       [ 2.04460068e+01],\n",
       "       [ 1.90705929e+01],\n",
       "       [ 9.41283417e+00],\n",
       "       [ 8.82954407e+00],\n",
       "       [ 3.02261734e+00],\n",
       "       [ 1.48666954e+01],\n",
       "       [ 3.93490021e+02],\n",
       "       [ 4.77414795e+02],\n",
       "       [ 7.85565567e+00],\n",
       "       [ 2.37437458e+01],\n",
       "       [-9.03487778e+00],\n",
       "       [ 2.56536224e+02],\n",
       "       [ 5.08016586e+00],\n",
       "       [ 2.15913124e+01],\n",
       "       [ 3.43719864e+00],\n",
       "       [ 2.01594181e+01],\n",
       "       [ 4.78380966e+00],\n",
       "       [ 1.37156868e+01],\n",
       "       [ 6.09075546e+00],\n",
       "       [ 4.78070923e+02],\n",
       "       [ 5.62959671e+00],\n",
       "       [ 1.04635345e+02],\n",
       "       [ 1.80180664e+01],\n",
       "       [ 1.22657356e+01],\n",
       "       [ 1.00845909e+01],\n",
       "       [ 9.99751663e+01],\n",
       "       [ 3.33050270e+01],\n",
       "       [ 5.99779129e+00],\n",
       "       [ 1.90736816e+02],\n",
       "       [ 5.49058914e+00],\n",
       "       [ 2.34877838e+02],\n",
       "       [ 2.28784199e+01],\n",
       "       [ 1.04061279e+01],\n",
       "       [ 3.80832291e+00],\n",
       "       [ 1.15707817e+01],\n",
       "       [ 1.03288651e+02],\n",
       "       [ 1.91812515e+02],\n",
       "       [ 5.24029922e+00],\n",
       "       [ 8.46007919e+00],\n",
       "       [ 2.35716934e+01],\n",
       "       [ 5.40510941e+00],\n",
       "       [ 2.19125271e+01],\n",
       "       [ 3.49103119e+02],\n",
       "       [ 6.11373520e+00],\n",
       "       [ 1.41540565e+01],\n",
       "       [ 5.36103439e+00],\n",
       "       [ 1.57926559e+01],\n",
       "       [ 1.61514481e+02],\n",
       "       [ 7.82221603e+00],\n",
       "       [-6.01558745e-01],\n",
       "       [ 6.33844376e+00],\n",
       "       [ 7.59588379e+02],\n",
       "       [ 8.29407120e+00],\n",
       "       [ 7.52454376e+01],\n",
       "       [ 1.63936043e+01],\n",
       "       [ 1.82416267e+01],\n",
       "       [ 4.36465836e+00],\n",
       "       [ 6.06197929e+01],\n",
       "       [ 1.64753891e+02],\n",
       "       [ 2.67793655e+00],\n",
       "       [ 1.94536781e+01],\n",
       "       [ 5.01555252e+00],\n",
       "       [ 7.94543839e+00],\n",
       "       [ 1.96111755e+01],\n",
       "       [ 1.11453339e+02],\n",
       "       [ 1.03216476e+02],\n",
       "       [ 5.39694595e+00],\n",
       "       [ 1.07650650e+02],\n",
       "       [ 6.86631470e+01],\n",
       "       [ 3.52785583e+02],\n",
       "       [ 2.20183105e+01],\n",
       "       [ 7.24840164e+00],\n",
       "       [ 1.40695992e+01],\n",
       "       [ 2.88658478e+02],\n",
       "       [ 1.33241882e+02],\n",
       "       [ 1.59424347e+02],\n",
       "       [ 2.06499901e+01],\n",
       "       [ 8.82684708e+00],\n",
       "       [ 6.84150314e+00],\n",
       "       [ 2.39348068e+01],\n",
       "       [ 1.92293549e+01],\n",
       "       [ 1.71379642e+01],\n",
       "       [ 1.58221741e+02]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d1e50ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27.824841140214346, 67.21929688122366, 0.799295391701092)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07b7cd",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19134a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce965371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               3456      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,321\n",
      "Trainable params: 168,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e6a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff2f38e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 195.3214 - mean_absolute_error: 195.3214\n",
      "Epoch 1: val_loss improved from inf to 140.08327, saving model to Weights-001--140.08327.hdf5\n",
      "40/40 [==============================] - 2s 15ms/step - loss: 193.9493 - mean_absolute_error: 193.9493 - val_loss: 140.0833 - val_mean_absolute_error: 140.0833\n",
      "Epoch 2/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 89.0736 - mean_absolute_error: 89.0736 \n",
      "Epoch 2: val_loss improved from 140.08327 to 85.76772, saving model to Weights-002--85.76772.hdf5\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 93.6011 - mean_absolute_error: 93.6011 - val_loss: 85.7677 - val_mean_absolute_error: 85.7677\n",
      "Epoch 3/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 63.8005 - mean_absolute_error: 63.8005\n",
      "Epoch 3: val_loss improved from 85.76772 to 72.26411, saving model to Weights-003--72.26411.hdf5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 60.4992 - mean_absolute_error: 60.4992 - val_loss: 72.2641 - val_mean_absolute_error: 72.2641\n",
      "Epoch 4/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 41.7911 - mean_absolute_error: 41.7911\n",
      "Epoch 4: val_loss improved from 72.26411 to 61.46075, saving model to Weights-004--61.46075.hdf5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 42.7123 - mean_absolute_error: 42.7123 - val_loss: 61.4608 - val_mean_absolute_error: 61.4608\n",
      "Epoch 5/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 37.5812 - mean_absolute_error: 37.5812\n",
      "Epoch 5: val_loss did not improve from 61.46075\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 35.7191 - mean_absolute_error: 35.7191 - val_loss: 63.2092 - val_mean_absolute_error: 63.2092\n",
      "Epoch 6/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 34.6458 - mean_absolute_error: 34.6458\n",
      "Epoch 6: val_loss improved from 61.46075 to 58.44569, saving model to Weights-006--58.44569.hdf5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 33.6356 - mean_absolute_error: 33.6356 - val_loss: 58.4457 - val_mean_absolute_error: 58.4457\n",
      "Epoch 7/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 33.0115 - mean_absolute_error: 33.0115\n",
      "Epoch 7: val_loss did not improve from 58.44569\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 32.9707 - mean_absolute_error: 32.9707 - val_loss: 60.5246 - val_mean_absolute_error: 60.5246\n",
      "Epoch 8/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 31.3442 - mean_absolute_error: 31.3442\n",
      "Epoch 8: val_loss improved from 58.44569 to 53.76830, saving model to Weights-008--53.76830.hdf5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 31.3442 - mean_absolute_error: 31.3442 - val_loss: 53.7683 - val_mean_absolute_error: 53.7683\n",
      "Epoch 9/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 27.3115 - mean_absolute_error: 27.3115\n",
      "Epoch 9: val_loss improved from 53.76830 to 52.78047, saving model to Weights-009--52.78047.hdf5\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 29.8297 - mean_absolute_error: 29.8297 - val_loss: 52.7805 - val_mean_absolute_error: 52.7805\n",
      "Epoch 10/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 31.2244 - mean_absolute_error: 31.2244\n",
      "Epoch 10: val_loss improved from 52.78047 to 52.47847, saving model to Weights-010--52.47847.hdf5\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 29.2672 - mean_absolute_error: 29.2672 - val_loss: 52.4785 - val_mean_absolute_error: 52.4785\n",
      "Epoch 11/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 29.7084 - mean_absolute_error: 29.7084\n",
      "Epoch 11: val_loss did not improve from 52.47847\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 28.4329 - mean_absolute_error: 28.4329 - val_loss: 54.4163 - val_mean_absolute_error: 54.4163\n",
      "Epoch 12/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 29.9417 - mean_absolute_error: 29.9417\n",
      "Epoch 12: val_loss improved from 52.47847 to 50.37542, saving model to Weights-012--50.37542.hdf5\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 31.0662 - mean_absolute_error: 31.0662 - val_loss: 50.3754 - val_mean_absolute_error: 50.3754\n",
      "Epoch 13/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 25.1063 - mean_absolute_error: 25.1063\n",
      "Epoch 13: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 28.2825 - mean_absolute_error: 28.2825 - val_loss: 53.2021 - val_mean_absolute_error: 53.2021\n",
      "Epoch 14/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 28.6426 - mean_absolute_error: 28.6426\n",
      "Epoch 14: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 28.5740 - mean_absolute_error: 28.5740 - val_loss: 53.6039 - val_mean_absolute_error: 53.6039\n",
      "Epoch 15/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 27.3637 - mean_absolute_error: 27.3637\n",
      "Epoch 15: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 27.6212 - mean_absolute_error: 27.6212 - val_loss: 52.0527 - val_mean_absolute_error: 52.0527\n",
      "Epoch 16/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 29.0260 - mean_absolute_error: 29.0260\n",
      "Epoch 16: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 29.2959 - mean_absolute_error: 29.2959 - val_loss: 50.4447 - val_mean_absolute_error: 50.4447\n",
      "Epoch 17/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 28.7240 - mean_absolute_error: 28.7240\n",
      "Epoch 17: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 28.7240 - mean_absolute_error: 28.7240 - val_loss: 54.1659 - val_mean_absolute_error: 54.1659\n",
      "Epoch 18/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 27.3133 - mean_absolute_error: 27.3133\n",
      "Epoch 18: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 26.8842 - mean_absolute_error: 26.8842 - val_loss: 54.6902 - val_mean_absolute_error: 54.6902\n",
      "Epoch 19/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 28.3296 - mean_absolute_error: 28.3296\n",
      "Epoch 19: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 26.9059 - mean_absolute_error: 26.9059 - val_loss: 51.8675 - val_mean_absolute_error: 51.8675\n",
      "Epoch 20/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 27.1835 - mean_absolute_error: 27.1835\n",
      "Epoch 20: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 26.7080 - mean_absolute_error: 26.7080 - val_loss: 51.2475 - val_mean_absolute_error: 51.2475\n",
      "Epoch 21/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 28.1228 - mean_absolute_error: 28.1228\n",
      "Epoch 21: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 28.1228 - mean_absolute_error: 28.1228 - val_loss: 52.3823 - val_mean_absolute_error: 52.3823\n",
      "Epoch 22/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 26.8572 - mean_absolute_error: 26.8572\n",
      "Epoch 22: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 26.4991 - mean_absolute_error: 26.4991 - val_loss: 55.7048 - val_mean_absolute_error: 55.7048\n",
      "Epoch 23/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 27.5573 - mean_absolute_error: 27.5573\n",
      "Epoch 23: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 27.7140 - mean_absolute_error: 27.7140 - val_loss: 52.3493 - val_mean_absolute_error: 52.3493\n",
      "Epoch 24/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 28.4315 - mean_absolute_error: 28.4315\n",
      "Epoch 24: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 29.1461 - mean_absolute_error: 29.1461 - val_loss: 52.8913 - val_mean_absolute_error: 52.8913\n",
      "Epoch 25/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 25.4015 - mean_absolute_error: 25.4015\n",
      "Epoch 25: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 27.1680 - mean_absolute_error: 27.1680 - val_loss: 52.9552 - val_mean_absolute_error: 52.9552\n",
      "Epoch 26/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 26.1785 - mean_absolute_error: 26.1785\n",
      "Epoch 26: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 27.2030 - mean_absolute_error: 27.2030 - val_loss: 52.1040 - val_mean_absolute_error: 52.1040\n",
      "Epoch 27/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 27.8663 - mean_absolute_error: 27.8663\n",
      "Epoch 27: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 28.4594 - mean_absolute_error: 28.4594 - val_loss: 55.0520 - val_mean_absolute_error: 55.0520\n",
      "Epoch 28/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 26.9857 - mean_absolute_error: 26.9857\n",
      "Epoch 28: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.6049 - mean_absolute_error: 26.6049 - val_loss: 51.9508 - val_mean_absolute_error: 51.9508\n",
      "Epoch 29/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 26.7005 - mean_absolute_error: 26.7005\n",
      "Epoch 29: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.6004 - mean_absolute_error: 26.6004 - val_loss: 51.3310 - val_mean_absolute_error: 51.3310\n",
      "Epoch 30/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 27.0914 - mean_absolute_error: 27.0914\n",
      "Epoch 30: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 26.8988 - mean_absolute_error: 26.8988 - val_loss: 51.8967 - val_mean_absolute_error: 51.8967\n",
      "Epoch 31/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 24.9996 - mean_absolute_error: 24.9996\n",
      "Epoch 31: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 25.0913 - mean_absolute_error: 25.0913 - val_loss: 55.7613 - val_mean_absolute_error: 55.7613\n",
      "Epoch 32/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 27.2993 - mean_absolute_error: 27.2993\n",
      "Epoch 32: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.3838 - mean_absolute_error: 26.3838 - val_loss: 52.3207 - val_mean_absolute_error: 52.3207\n",
      "Epoch 33/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 26.3375 - mean_absolute_error: 26.3375\n",
      "Epoch 33: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 26.0791 - mean_absolute_error: 26.0791 - val_loss: 52.1866 - val_mean_absolute_error: 52.1866\n",
      "Epoch 34/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 24.6527 - mean_absolute_error: 24.6527\n",
      "Epoch 34: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 27.0015 - mean_absolute_error: 27.0015 - val_loss: 52.5167 - val_mean_absolute_error: 52.5167\n",
      "Epoch 35/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 26.5102 - mean_absolute_error: 26.5102\n",
      "Epoch 35: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.8410 - mean_absolute_error: 25.8410 - val_loss: 51.3323 - val_mean_absolute_error: 51.3323\n",
      "Epoch 36/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 25.6560 - mean_absolute_error: 25.6560\n",
      "Epoch 36: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.0545 - mean_absolute_error: 25.0545 - val_loss: 52.4809 - val_mean_absolute_error: 52.4809\n",
      "Epoch 37/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 25.9655 - mean_absolute_error: 25.9655\n",
      "Epoch 37: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.7812 - mean_absolute_error: 25.7812 - val_loss: 53.9189 - val_mean_absolute_error: 53.9189\n",
      "Epoch 38/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 26.3738 - mean_absolute_error: 26.3738\n",
      "Epoch 38: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.2751 - mean_absolute_error: 26.2751 - val_loss: 56.8985 - val_mean_absolute_error: 56.8985\n",
      "Epoch 39/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 27.0123 - mean_absolute_error: 27.0123\n",
      "Epoch 39: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.1918 - mean_absolute_error: 26.1918 - val_loss: 53.8630 - val_mean_absolute_error: 53.8630\n",
      "Epoch 40/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 25.2090 - mean_absolute_error: 25.2090\n",
      "Epoch 40: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.9431 - mean_absolute_error: 25.9431 - val_loss: 52.6418 - val_mean_absolute_error: 52.6418\n",
      "Epoch 41/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 25.2799 - mean_absolute_error: 25.2799\n",
      "Epoch 41: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.3975 - mean_absolute_error: 26.3975 - val_loss: 57.1182 - val_mean_absolute_error: 57.1182\n",
      "Epoch 42/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 26.7393 - mean_absolute_error: 26.7393\n",
      "Epoch 42: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 26.7393 - mean_absolute_error: 26.7393 - val_loss: 55.4294 - val_mean_absolute_error: 55.4294\n",
      "Epoch 43/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 28.2955 - mean_absolute_error: 28.2955\n",
      "Epoch 43: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 27.2449 - mean_absolute_error: 27.2449 - val_loss: 54.0688 - val_mean_absolute_error: 54.0688\n",
      "Epoch 44/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 26.0704 - mean_absolute_error: 26.0704\n",
      "Epoch 44: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.6290 - mean_absolute_error: 25.6290 - val_loss: 53.6973 - val_mean_absolute_error: 53.6973\n",
      "Epoch 45/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 25.3592 - mean_absolute_error: 25.3592\n",
      "Epoch 45: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.1990 - mean_absolute_error: 26.1990 - val_loss: 53.5295 - val_mean_absolute_error: 53.5295\n",
      "Epoch 46/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 23.7742 - mean_absolute_error: 23.7742\n",
      "Epoch 46: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 26.3452 - mean_absolute_error: 26.3452 - val_loss: 52.0719 - val_mean_absolute_error: 52.0719\n",
      "Epoch 47/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 23.4184 - mean_absolute_error: 23.4184\n",
      "Epoch 47: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.8681 - mean_absolute_error: 23.8681 - val_loss: 52.4812 - val_mean_absolute_error: 52.4812\n",
      "Epoch 48/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 28.0461 - mean_absolute_error: 28.0461\n",
      "Epoch 48: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 27.2219 - mean_absolute_error: 27.2219 - val_loss: 54.0487 - val_mean_absolute_error: 54.0487\n",
      "Epoch 49/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 25.9829 - mean_absolute_error: 25.9829\n",
      "Epoch 49: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 26.1191 - mean_absolute_error: 26.1191 - val_loss: 53.1461 - val_mean_absolute_error: 53.1461\n",
      "Epoch 50/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 25.0604 - mean_absolute_error: 25.0604\n",
      "Epoch 50: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 25.1912 - mean_absolute_error: 25.1912 - val_loss: 53.2123 - val_mean_absolute_error: 53.2123\n",
      "Epoch 51/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 26.4500 - mean_absolute_error: 26.4500\n",
      "Epoch 51: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 25.4422 - mean_absolute_error: 25.4422 - val_loss: 50.8586 - val_mean_absolute_error: 50.8586\n",
      "Epoch 52/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 25.3459 - mean_absolute_error: 25.3459\n",
      "Epoch 52: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.7504 - mean_absolute_error: 24.7504 - val_loss: 52.5369 - val_mean_absolute_error: 52.5369\n",
      "Epoch 53/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 26.4169 - mean_absolute_error: 26.4169\n",
      "Epoch 53: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 25.2506 - mean_absolute_error: 25.2506 - val_loss: 52.3422 - val_mean_absolute_error: 52.3422\n",
      "Epoch 54/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 25.8519 - mean_absolute_error: 25.8519\n",
      "Epoch 54: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 26.0243 - mean_absolute_error: 26.0243 - val_loss: 53.7346 - val_mean_absolute_error: 53.7346\n",
      "Epoch 55/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 24.8794 - mean_absolute_error: 24.8794\n",
      "Epoch 55: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 25.2171 - mean_absolute_error: 25.2171 - val_loss: 55.3175 - val_mean_absolute_error: 55.3175\n",
      "Epoch 56/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.6390 - mean_absolute_error: 22.6390\n",
      "Epoch 56: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.8469 - mean_absolute_error: 25.8469 - val_loss: 53.3911 - val_mean_absolute_error: 53.3911\n",
      "Epoch 57/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 25.2512 - mean_absolute_error: 25.2512\n",
      "Epoch 57: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 24.4633 - mean_absolute_error: 24.4633 - val_loss: 54.7350 - val_mean_absolute_error: 54.7350\n",
      "Epoch 58/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 24.0192 - mean_absolute_error: 24.0192\n",
      "Epoch 58: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 23.9112 - mean_absolute_error: 23.9112 - val_loss: 51.4358 - val_mean_absolute_error: 51.4358\n",
      "Epoch 59/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 24.2065 - mean_absolute_error: 24.2065\n",
      "Epoch 59: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 24.0408 - mean_absolute_error: 24.0408 - val_loss: 52.2052 - val_mean_absolute_error: 52.2052\n",
      "Epoch 60/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 24.9830 - mean_absolute_error: 24.9830\n",
      "Epoch 60: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 24.5700 - mean_absolute_error: 24.5700 - val_loss: 52.6680 - val_mean_absolute_error: 52.6680\n",
      "Epoch 61/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 26.0327 - mean_absolute_error: 26.0327\n",
      "Epoch 61: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.3566 - mean_absolute_error: 25.3566 - val_loss: 52.2426 - val_mean_absolute_error: 52.2426\n",
      "Epoch 62/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 20.6196 - mean_absolute_error: 20.6196\n",
      "Epoch 62: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 24.1462 - mean_absolute_error: 24.1462 - val_loss: 52.9076 - val_mean_absolute_error: 52.9076\n",
      "Epoch 63/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 25.0932 - mean_absolute_error: 25.0932\n",
      "Epoch 63: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.8779 - mean_absolute_error: 24.8779 - val_loss: 56.1770 - val_mean_absolute_error: 56.1770\n",
      "Epoch 64/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 22.8443 - mean_absolute_error: 22.8443\n",
      "Epoch 64: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 25.1406 - mean_absolute_error: 25.1406 - val_loss: 56.0989 - val_mean_absolute_error: 56.0989\n",
      "Epoch 65/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 24.6645 - mean_absolute_error: 24.6645\n",
      "Epoch 65: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 23.9425 - mean_absolute_error: 23.9425 - val_loss: 55.6873 - val_mean_absolute_error: 55.6873\n",
      "Epoch 66/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 26.6137 - mean_absolute_error: 26.6137\n",
      "Epoch 66: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.4567 - mean_absolute_error: 25.4567 - val_loss: 53.3602 - val_mean_absolute_error: 53.3602\n",
      "Epoch 67/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 23.2688 - mean_absolute_error: 23.2688\n",
      "Epoch 67: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.1554 - mean_absolute_error: 23.1554 - val_loss: 54.6476 - val_mean_absolute_error: 54.6476\n",
      "Epoch 68/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 25.2884 - mean_absolute_error: 25.2884\n",
      "Epoch 68: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 24.2108 - mean_absolute_error: 24.2108 - val_loss: 56.8258 - val_mean_absolute_error: 56.8258\n",
      "Epoch 69/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 26.2192 - mean_absolute_error: 26.2192\n",
      "Epoch 69: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.5202 - mean_absolute_error: 24.5202 - val_loss: 52.7070 - val_mean_absolute_error: 52.7070\n",
      "Epoch 70/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 24.8034 - mean_absolute_error: 24.8034\n",
      "Epoch 70: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 24.8450 - mean_absolute_error: 24.8450 - val_loss: 52.1764 - val_mean_absolute_error: 52.1764\n",
      "Epoch 71/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 24.8038 - mean_absolute_error: 24.8038\n",
      "Epoch 71: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 23.5820 - mean_absolute_error: 23.5820 - val_loss: 53.8057 - val_mean_absolute_error: 53.8057\n",
      "Epoch 72/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 24.2621 - mean_absolute_error: 24.2621\n",
      "Epoch 72: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.6554 - mean_absolute_error: 23.6554 - val_loss: 53.0139 - val_mean_absolute_error: 53.0139\n",
      "Epoch 73/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 24.2879 - mean_absolute_error: 24.2879\n",
      "Epoch 73: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 24.2580 - mean_absolute_error: 24.2580 - val_loss: 51.4163 - val_mean_absolute_error: 51.4163\n",
      "Epoch 74/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 24.2245 - mean_absolute_error: 24.2245\n",
      "Epoch 74: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.1500 - mean_absolute_error: 24.1500 - val_loss: 52.1734 - val_mean_absolute_error: 52.1734\n",
      "Epoch 75/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 23.9535 - mean_absolute_error: 23.9535\n",
      "Epoch 75: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.7842 - mean_absolute_error: 24.7842 - val_loss: 54.1782 - val_mean_absolute_error: 54.1782\n",
      "Epoch 76/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 25.3584 - mean_absolute_error: 25.3584\n",
      "Epoch 76: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 24.9036 - mean_absolute_error: 24.9036 - val_loss: 54.5843 - val_mean_absolute_error: 54.5843\n",
      "Epoch 77/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 25.1688 - mean_absolute_error: 25.1688\n",
      "Epoch 77: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.7744 - mean_absolute_error: 23.7744 - val_loss: 53.4212 - val_mean_absolute_error: 53.4212\n",
      "Epoch 78/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 23.2647 - mean_absolute_error: 23.2647\n",
      "Epoch 78: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.7040 - mean_absolute_error: 23.7040 - val_loss: 54.5489 - val_mean_absolute_error: 54.5489\n",
      "Epoch 79/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 24.8290 - mean_absolute_error: 24.8290\n",
      "Epoch 79: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.6640 - mean_absolute_error: 23.6640 - val_loss: 54.3459 - val_mean_absolute_error: 54.3459\n",
      "Epoch 80/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 25.3349 - mean_absolute_error: 25.3349\n",
      "Epoch 80: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 24.9015 - mean_absolute_error: 24.9015 - val_loss: 54.3321 - val_mean_absolute_error: 54.3321\n",
      "Epoch 81/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 23.1464 - mean_absolute_error: 23.1464\n",
      "Epoch 81: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 25.2043 - mean_absolute_error: 25.2043 - val_loss: 53.6186 - val_mean_absolute_error: 53.6186\n",
      "Epoch 82/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 24.7537 - mean_absolute_error: 24.7537\n",
      "Epoch 82: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 24.6118 - mean_absolute_error: 24.6118 - val_loss: 57.4491 - val_mean_absolute_error: 57.4491\n",
      "Epoch 83/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 23.7177 - mean_absolute_error: 23.7177\n",
      "Epoch 83: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.9993 - mean_absolute_error: 22.9993 - val_loss: 55.6165 - val_mean_absolute_error: 55.6165\n",
      "Epoch 84/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 23.8512 - mean_absolute_error: 23.8512\n",
      "Epoch 84: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 23.6899 - mean_absolute_error: 23.6899 - val_loss: 53.9515 - val_mean_absolute_error: 53.9515\n",
      "Epoch 85/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 25.0283 - mean_absolute_error: 25.0283\n",
      "Epoch 85: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.0825 - mean_absolute_error: 24.0825 - val_loss: 53.6306 - val_mean_absolute_error: 53.6306\n",
      "Epoch 86/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 22.7097 - mean_absolute_error: 22.7097\n",
      "Epoch 86: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.4476 - mean_absolute_error: 22.4476 - val_loss: 55.3068 - val_mean_absolute_error: 55.3068\n",
      "Epoch 87/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 22.2571 - mean_absolute_error: 22.2571\n",
      "Epoch 87: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 23.2890 - mean_absolute_error: 23.2890 - val_loss: 58.1316 - val_mean_absolute_error: 58.1316\n",
      "Epoch 88/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.5243 - mean_absolute_error: 22.5243\n",
      "Epoch 88: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 22.5191 - mean_absolute_error: 22.5191 - val_loss: 55.1515 - val_mean_absolute_error: 55.1515\n",
      "Epoch 89/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 21.8073 - mean_absolute_error: 21.8073\n",
      "Epoch 89: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.1943 - mean_absolute_error: 23.1943 - val_loss: 61.6282 - val_mean_absolute_error: 61.6282\n",
      "Epoch 90/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 25.2284 - mean_absolute_error: 25.2284\n",
      "Epoch 90: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.8310 - mean_absolute_error: 23.8310 - val_loss: 54.7517 - val_mean_absolute_error: 54.7517\n",
      "Epoch 91/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 21.4314 - mean_absolute_error: 21.4314\n",
      "Epoch 91: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.8801 - mean_absolute_error: 22.8801 - val_loss: 54.1807 - val_mean_absolute_error: 54.1807\n",
      "Epoch 92/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 23.9000 - mean_absolute_error: 23.9000\n",
      "Epoch 92: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 22.9369 - mean_absolute_error: 22.9369 - val_loss: 54.9827 - val_mean_absolute_error: 54.9827\n",
      "Epoch 93/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 24.0447 - mean_absolute_error: 24.0447\n",
      "Epoch 93: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 23.4172 - mean_absolute_error: 23.4172 - val_loss: 54.7389 - val_mean_absolute_error: 54.7389\n",
      "Epoch 94/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 21.9414 - mean_absolute_error: 21.9414\n",
      "Epoch 94: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 22.4765 - mean_absolute_error: 22.4765 - val_loss: 53.2236 - val_mean_absolute_error: 53.2236\n",
      "Epoch 95/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 23.2476 - mean_absolute_error: 23.2476\n",
      "Epoch 95: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 22.9164 - mean_absolute_error: 22.9164 - val_loss: 57.9156 - val_mean_absolute_error: 57.9156\n",
      "Epoch 96/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 22.3235 - mean_absolute_error: 22.3235\n",
      "Epoch 96: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.3422 - mean_absolute_error: 22.3422 - val_loss: 54.6913 - val_mean_absolute_error: 54.6913\n",
      "Epoch 97/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 22.2184 - mean_absolute_error: 22.2184\n",
      "Epoch 97: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 22.1161 - mean_absolute_error: 22.1161 - val_loss: 57.9346 - val_mean_absolute_error: 57.9346\n",
      "Epoch 98/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 23.9103 - mean_absolute_error: 23.9103\n",
      "Epoch 98: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.9945 - mean_absolute_error: 23.9945 - val_loss: 60.2508 - val_mean_absolute_error: 60.2508\n",
      "Epoch 99/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 22.7433 - mean_absolute_error: 22.7433\n",
      "Epoch 99: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 23.0912 - mean_absolute_error: 23.0912 - val_loss: 55.5325 - val_mean_absolute_error: 55.5325\n",
      "Epoch 100/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 23.4615 - mean_absolute_error: 23.4615\n",
      "Epoch 100: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 23.2365 - mean_absolute_error: 23.2365 - val_loss: 57.1058 - val_mean_absolute_error: 57.1058\n",
      "Epoch 101/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 22.2223 - mean_absolute_error: 22.2223\n",
      "Epoch 101: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.9969 - mean_absolute_error: 21.9969 - val_loss: 55.5448 - val_mean_absolute_error: 55.5448\n",
      "Epoch 102/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 21.6803 - mean_absolute_error: 21.6803\n",
      "Epoch 102: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.9555 - mean_absolute_error: 21.9555 - val_loss: 58.4585 - val_mean_absolute_error: 58.4585\n",
      "Epoch 103/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 21.3595 - mean_absolute_error: 21.3595\n",
      "Epoch 103: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.7540 - mean_absolute_error: 21.7540 - val_loss: 55.3464 - val_mean_absolute_error: 55.3464\n",
      "Epoch 104/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 23.5884 - mean_absolute_error: 23.5884\n",
      "Epoch 104: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.0617 - mean_absolute_error: 23.0617 - val_loss: 54.6748 - val_mean_absolute_error: 54.6748\n",
      "Epoch 105/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 21.4494 - mean_absolute_error: 21.4494\n",
      "Epoch 105: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 21.4494 - mean_absolute_error: 21.4494 - val_loss: 58.4527 - val_mean_absolute_error: 58.4527\n",
      "Epoch 106/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 21.2200 - mean_absolute_error: 21.2200\n",
      "Epoch 106: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.4148 - mean_absolute_error: 21.4148 - val_loss: 54.8467 - val_mean_absolute_error: 54.8467\n",
      "Epoch 107/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 24.5598 - mean_absolute_error: 24.5598\n",
      "Epoch 107: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.2499 - mean_absolute_error: 23.2499 - val_loss: 55.8006 - val_mean_absolute_error: 55.8006\n",
      "Epoch 108/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 21.4087 - mean_absolute_error: 21.4087\n",
      "Epoch 108: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.4620 - mean_absolute_error: 21.4620 - val_loss: 58.3711 - val_mean_absolute_error: 58.3711\n",
      "Epoch 109/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 20.2870 - mean_absolute_error: 20.2870\n",
      "Epoch 109: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.9298 - mean_absolute_error: 20.9298 - val_loss: 57.0397 - val_mean_absolute_error: 57.0397\n",
      "Epoch 110/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 21.0461 - mean_absolute_error: 21.0461\n",
      "Epoch 110: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.0461 - mean_absolute_error: 21.0461 - val_loss: 57.6972 - val_mean_absolute_error: 57.6972\n",
      "Epoch 111/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 20.3075 - mean_absolute_error: 20.3075\n",
      "Epoch 111: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.1574 - mean_absolute_error: 21.1574 - val_loss: 58.0805 - val_mean_absolute_error: 58.0805\n",
      "Epoch 112/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 22.5280 - mean_absolute_error: 22.5280\n",
      "Epoch 112: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 23.5367 - mean_absolute_error: 23.5367 - val_loss: 61.3745 - val_mean_absolute_error: 61.3745\n",
      "Epoch 113/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.3419 - mean_absolute_error: 22.3419\n",
      "Epoch 113: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.9776 - mean_absolute_error: 21.9776 - val_loss: 56.5328 - val_mean_absolute_error: 56.5328\n",
      "Epoch 114/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 22.2227 - mean_absolute_error: 22.2227\n",
      "Epoch 114: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.2227 - mean_absolute_error: 22.2227 - val_loss: 59.9627 - val_mean_absolute_error: 59.9627\n",
      "Epoch 115/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.4718 - mean_absolute_error: 22.4718\n",
      "Epoch 115: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 22.0903 - mean_absolute_error: 22.0903 - val_loss: 58.2049 - val_mean_absolute_error: 58.2049\n",
      "Epoch 116/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 20.7797 - mean_absolute_error: 20.7797\n",
      "Epoch 116: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.6993 - mean_absolute_error: 21.6993 - val_loss: 57.2289 - val_mean_absolute_error: 57.2289\n",
      "Epoch 117/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 21.3838 - mean_absolute_error: 21.3838\n",
      "Epoch 117: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.0043 - mean_absolute_error: 21.0043 - val_loss: 64.2948 - val_mean_absolute_error: 64.2948\n",
      "Epoch 118/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.9621 - mean_absolute_error: 22.9621\n",
      "Epoch 118: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 23.8777 - mean_absolute_error: 23.8777 - val_loss: 57.7989 - val_mean_absolute_error: 57.7989\n",
      "Epoch 119/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 24.3897 - mean_absolute_error: 24.3897\n",
      "Epoch 119: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 24.0394 - mean_absolute_error: 24.0394 - val_loss: 55.2164 - val_mean_absolute_error: 55.2164\n",
      "Epoch 120/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 22.0421 - mean_absolute_error: 22.0421\n",
      "Epoch 120: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 22.5192 - mean_absolute_error: 22.5192 - val_loss: 58.3986 - val_mean_absolute_error: 58.3986\n",
      "Epoch 121/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 20.2517 - mean_absolute_error: 20.2517\n",
      "Epoch 121: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.8117 - mean_absolute_error: 19.8117 - val_loss: 55.9490 - val_mean_absolute_error: 55.9490\n",
      "Epoch 122/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 22.5634 - mean_absolute_error: 22.5634\n",
      "Epoch 122: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 21.8860 - mean_absolute_error: 21.8860 - val_loss: 57.7677 - val_mean_absolute_error: 57.7677\n",
      "Epoch 123/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 21.4461 - mean_absolute_error: 21.4461\n",
      "Epoch 123: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 21.6085 - mean_absolute_error: 21.6085 - val_loss: 57.4423 - val_mean_absolute_error: 57.4423\n",
      "Epoch 124/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 20.2316 - mean_absolute_error: 20.2316\n",
      "Epoch 124: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.2627 - mean_absolute_error: 20.2627 - val_loss: 57.2857 - val_mean_absolute_error: 57.2857\n",
      "Epoch 125/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 20.3655 - mean_absolute_error: 20.3655\n",
      "Epoch 125: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.4260 - mean_absolute_error: 21.4260 - val_loss: 58.0121 - val_mean_absolute_error: 58.0121\n",
      "Epoch 126/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.4761 - mean_absolute_error: 18.4761\n",
      "Epoch 126: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.6372 - mean_absolute_error: 19.6372 - val_loss: 54.8891 - val_mean_absolute_error: 54.8891\n",
      "Epoch 127/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 20.0697 - mean_absolute_error: 20.0697\n",
      "Epoch 127: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.0697 - mean_absolute_error: 20.0697 - val_loss: 60.9714 - val_mean_absolute_error: 60.9714\n",
      "Epoch 128/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 21.0023 - mean_absolute_error: 21.0023\n",
      "Epoch 128: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.7751 - mean_absolute_error: 20.7751 - val_loss: 61.2195 - val_mean_absolute_error: 61.2195\n",
      "Epoch 129/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 20.8298 - mean_absolute_error: 20.8298\n",
      "Epoch 129: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 20.8298 - mean_absolute_error: 20.8298 - val_loss: 55.9989 - val_mean_absolute_error: 55.9989\n",
      "Epoch 130/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.8084 - mean_absolute_error: 19.8084\n",
      "Epoch 130: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.8084 - mean_absolute_error: 19.8084 - val_loss: 55.0632 - val_mean_absolute_error: 55.0632\n",
      "Epoch 131/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.2170 - mean_absolute_error: 18.2170\n",
      "Epoch 131: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.9668 - mean_absolute_error: 18.9668 - val_loss: 57.4390 - val_mean_absolute_error: 57.4390\n",
      "Epoch 132/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 22.3768 - mean_absolute_error: 22.3768\n",
      "Epoch 132: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.3914 - mean_absolute_error: 21.3914 - val_loss: 55.1855 - val_mean_absolute_error: 55.1855\n",
      "Epoch 133/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 19.2007 - mean_absolute_error: 19.2007\n",
      "Epoch 133: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 19.4517 - mean_absolute_error: 19.4517 - val_loss: 56.9437 - val_mean_absolute_error: 56.9437\n",
      "Epoch 134/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 19.3688 - mean_absolute_error: 19.3688\n",
      "Epoch 134: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 20.9245 - mean_absolute_error: 20.9245 - val_loss: 57.9518 - val_mean_absolute_error: 57.9518\n",
      "Epoch 135/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 20.4818 - mean_absolute_error: 20.4818\n",
      "Epoch 135: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 20.7496 - mean_absolute_error: 20.7496 - val_loss: 57.9760 - val_mean_absolute_error: 57.9760\n",
      "Epoch 136/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 20.0088 - mean_absolute_error: 20.0088\n",
      "Epoch 136: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.3582 - mean_absolute_error: 19.3582 - val_loss: 56.1846 - val_mean_absolute_error: 56.1846\n",
      "Epoch 137/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.5838 - mean_absolute_error: 18.5838\n",
      "Epoch 137: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.2499 - mean_absolute_error: 19.2499 - val_loss: 56.2957 - val_mean_absolute_error: 56.2957\n",
      "Epoch 138/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 19.8930 - mean_absolute_error: 19.8930\n",
      "Epoch 138: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.8248 - mean_absolute_error: 19.8248 - val_loss: 55.7648 - val_mean_absolute_error: 55.7648\n",
      "Epoch 139/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 20.8121 - mean_absolute_error: 20.8121\n",
      "Epoch 139: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 20.5347 - mean_absolute_error: 20.5347 - val_loss: 55.1705 - val_mean_absolute_error: 55.1705\n",
      "Epoch 140/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 19.8902 - mean_absolute_error: 19.8902\n",
      "Epoch 140: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.5096 - mean_absolute_error: 19.5096 - val_loss: 59.2052 - val_mean_absolute_error: 59.2052\n",
      "Epoch 141/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 17.6487 - mean_absolute_error: 17.6487\n",
      "Epoch 141: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.5803 - mean_absolute_error: 18.5803 - val_loss: 58.8705 - val_mean_absolute_error: 58.8705\n",
      "Epoch 142/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 20.0770 - mean_absolute_error: 20.0770\n",
      "Epoch 142: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.9908 - mean_absolute_error: 19.9908 - val_loss: 55.2453 - val_mean_absolute_error: 55.2453\n",
      "Epoch 143/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 20.0110 - mean_absolute_error: 20.0110\n",
      "Epoch 143: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 21.0261 - mean_absolute_error: 21.0261 - val_loss: 56.6273 - val_mean_absolute_error: 56.6273\n",
      "Epoch 144/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 20.0914 - mean_absolute_error: 20.0914\n",
      "Epoch 144: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 20.4697 - mean_absolute_error: 20.4697 - val_loss: 57.4453 - val_mean_absolute_error: 57.4453\n",
      "Epoch 145/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.7494 - mean_absolute_error: 17.7494\n",
      "Epoch 145: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.5117 - mean_absolute_error: 19.5117 - val_loss: 56.5724 - val_mean_absolute_error: 56.5724\n",
      "Epoch 146/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.2324 - mean_absolute_error: 19.2324\n",
      "Epoch 146: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.2324 - mean_absolute_error: 19.2324 - val_loss: 56.7615 - val_mean_absolute_error: 56.7615\n",
      "Epoch 147/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 18.9346 - mean_absolute_error: 18.9346\n",
      "Epoch 147: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.1158 - mean_absolute_error: 19.1158 - val_loss: 59.6179 - val_mean_absolute_error: 59.6179\n",
      "Epoch 148/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 22.9819 - mean_absolute_error: 22.9819\n",
      "Epoch 148: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 22.8175 - mean_absolute_error: 22.8175 - val_loss: 58.9264 - val_mean_absolute_error: 58.9264\n",
      "Epoch 149/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 22.4205 - mean_absolute_error: 22.4205\n",
      "Epoch 149: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 23.6869 - mean_absolute_error: 23.6869 - val_loss: 57.3575 - val_mean_absolute_error: 57.3575\n",
      "Epoch 150/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.2149 - mean_absolute_error: 18.2149\n",
      "Epoch 150: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.4770 - mean_absolute_error: 19.4770 - val_loss: 57.4733 - val_mean_absolute_error: 57.4733\n",
      "Epoch 151/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 19.6448 - mean_absolute_error: 19.6448\n",
      "Epoch 151: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.0119 - mean_absolute_error: 20.0119 - val_loss: 58.3070 - val_mean_absolute_error: 58.3070\n",
      "Epoch 152/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.7877 - mean_absolute_error: 19.7877\n",
      "Epoch 152: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.7877 - mean_absolute_error: 19.7877 - val_loss: 55.6057 - val_mean_absolute_error: 55.6057\n",
      "Epoch 153/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 22.0061 - mean_absolute_error: 22.0061\n",
      "Epoch 153: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 21.0990 - mean_absolute_error: 21.0990 - val_loss: 57.3738 - val_mean_absolute_error: 57.3738\n",
      "Epoch 154/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 20.3171 - mean_absolute_error: 20.3171\n",
      "Epoch 154: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.7176 - mean_absolute_error: 19.7176 - val_loss: 57.9497 - val_mean_absolute_error: 57.9497\n",
      "Epoch 155/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 19.3497 - mean_absolute_error: 19.3497\n",
      "Epoch 155: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.1040 - mean_absolute_error: 19.1040 - val_loss: 57.3185 - val_mean_absolute_error: 57.3185\n",
      "Epoch 156/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 19.0354 - mean_absolute_error: 19.0354\n",
      "Epoch 156: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.9519 - mean_absolute_error: 19.9519 - val_loss: 56.0196 - val_mean_absolute_error: 56.0196\n",
      "Epoch 157/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 18.6855 - mean_absolute_error: 18.6855\n",
      "Epoch 157: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 19.0903 - mean_absolute_error: 19.0903 - val_loss: 55.7705 - val_mean_absolute_error: 55.7705\n",
      "Epoch 158/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.5715 - mean_absolute_error: 19.5715\n",
      "Epoch 158: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.5715 - mean_absolute_error: 19.5715 - val_loss: 55.8441 - val_mean_absolute_error: 55.8441\n",
      "Epoch 159/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.9568 - mean_absolute_error: 18.9568\n",
      "Epoch 159: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 18.8500 - mean_absolute_error: 18.8500 - val_loss: 58.1354 - val_mean_absolute_error: 58.1354\n",
      "Epoch 160/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 17.4605 - mean_absolute_error: 17.4605\n",
      "Epoch 160: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.6047 - mean_absolute_error: 17.6047 - val_loss: 60.0330 - val_mean_absolute_error: 60.0330\n",
      "Epoch 161/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 19.5296 - mean_absolute_error: 19.5296\n",
      "Epoch 161: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.6497 - mean_absolute_error: 19.6497 - val_loss: 56.5690 - val_mean_absolute_error: 56.5690\n",
      "Epoch 162/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 21.7794 - mean_absolute_error: 21.7794\n",
      "Epoch 162: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.1684 - mean_absolute_error: 21.1684 - val_loss: 57.8093 - val_mean_absolute_error: 57.8093\n",
      "Epoch 163/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.0052 - mean_absolute_error: 19.0052\n",
      "Epoch 163: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.0052 - mean_absolute_error: 19.0052 - val_loss: 58.5959 - val_mean_absolute_error: 58.5959\n",
      "Epoch 164/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 21.0255 - mean_absolute_error: 21.0255\n",
      "Epoch 164: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 21.0255 - mean_absolute_error: 21.0255 - val_loss: 56.5225 - val_mean_absolute_error: 56.5225\n",
      "Epoch 165/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 21.3235 - mean_absolute_error: 21.3235\n",
      "Epoch 165: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.1913 - mean_absolute_error: 21.1913 - val_loss: 55.9380 - val_mean_absolute_error: 55.9380\n",
      "Epoch 166/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 19.4872 - mean_absolute_error: 19.4872\n",
      "Epoch 166: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.4483 - mean_absolute_error: 19.4483 - val_loss: 55.2745 - val_mean_absolute_error: 55.2745\n",
      "Epoch 167/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 19.5669 - mean_absolute_error: 19.5669\n",
      "Epoch 167: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.4727 - mean_absolute_error: 19.4727 - val_loss: 55.7517 - val_mean_absolute_error: 55.7517\n",
      "Epoch 168/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 19.7664 - mean_absolute_error: 19.7664\n",
      "Epoch 168: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.4133 - mean_absolute_error: 18.4133 - val_loss: 55.6986 - val_mean_absolute_error: 55.6986\n",
      "Epoch 169/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.7118 - mean_absolute_error: 17.7118\n",
      "Epoch 169: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.8912 - mean_absolute_error: 17.8912 - val_loss: 57.2239 - val_mean_absolute_error: 57.2239\n",
      "Epoch 170/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 19.1578 - mean_absolute_error: 19.1578\n",
      "Epoch 170: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.3618 - mean_absolute_error: 19.3618 - val_loss: 55.9810 - val_mean_absolute_error: 55.9810\n",
      "Epoch 171/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 18.0449 - mean_absolute_error: 18.0449\n",
      "Epoch 171: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.9562 - mean_absolute_error: 17.9562 - val_loss: 55.2080 - val_mean_absolute_error: 55.2080\n",
      "Epoch 172/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.5457 - mean_absolute_error: 18.5457\n",
      "Epoch 172: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.1644 - mean_absolute_error: 19.1644 - val_loss: 54.6881 - val_mean_absolute_error: 54.6881\n",
      "Epoch 173/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.1321 - mean_absolute_error: 18.1321\n",
      "Epoch 173: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.1210 - mean_absolute_error: 18.1210 - val_loss: 54.9276 - val_mean_absolute_error: 54.9276\n",
      "Epoch 174/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 19.1168 - mean_absolute_error: 19.1168\n",
      "Epoch 174: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.2080 - mean_absolute_error: 19.2080 - val_loss: 55.6466 - val_mean_absolute_error: 55.6466\n",
      "Epoch 175/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 18.3412 - mean_absolute_error: 18.3412\n",
      "Epoch 175: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.9269 - mean_absolute_error: 18.9269 - val_loss: 58.0922 - val_mean_absolute_error: 58.0922\n",
      "Epoch 176/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.4151 - mean_absolute_error: 19.4151\n",
      "Epoch 176: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.4151 - mean_absolute_error: 19.4151 - val_loss: 56.2671 - val_mean_absolute_error: 56.2671\n",
      "Epoch 177/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.2527 - mean_absolute_error: 17.2527\n",
      "Epoch 177: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.9824 - mean_absolute_error: 18.9824 - val_loss: 57.9685 - val_mean_absolute_error: 57.9685\n",
      "Epoch 178/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 19.2141 - mean_absolute_error: 19.2141\n",
      "Epoch 178: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.8989 - mean_absolute_error: 18.8989 - val_loss: 57.0890 - val_mean_absolute_error: 57.0890\n",
      "Epoch 179/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 21.4629 - mean_absolute_error: 21.4629\n",
      "Epoch 179: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 21.1891 - mean_absolute_error: 21.1891 - val_loss: 55.4414 - val_mean_absolute_error: 55.4414\n",
      "Epoch 180/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.7608 - mean_absolute_error: 18.7608\n",
      "Epoch 180: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.6589 - mean_absolute_error: 18.6589 - val_loss: 58.0401 - val_mean_absolute_error: 58.0401\n",
      "Epoch 181/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.7902 - mean_absolute_error: 18.7902\n",
      "Epoch 181: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.8621 - mean_absolute_error: 17.8621 - val_loss: 55.7757 - val_mean_absolute_error: 55.7757\n",
      "Epoch 182/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 19.1789 - mean_absolute_error: 19.1789\n",
      "Epoch 182: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.6295 - mean_absolute_error: 19.6295 - val_loss: 57.2272 - val_mean_absolute_error: 57.2272\n",
      "Epoch 183/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 19.0340 - mean_absolute_error: 19.0340\n",
      "Epoch 183: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.8584 - mean_absolute_error: 18.8584 - val_loss: 56.0745 - val_mean_absolute_error: 56.0745\n",
      "Epoch 184/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 19.2633 - mean_absolute_error: 19.2633\n",
      "Epoch 184: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.4157 - mean_absolute_error: 19.4157 - val_loss: 56.8071 - val_mean_absolute_error: 56.8071\n",
      "Epoch 185/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.5203 - mean_absolute_error: 18.5203\n",
      "Epoch 185: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.0662 - mean_absolute_error: 18.0662 - val_loss: 57.1030 - val_mean_absolute_error: 57.1030\n",
      "Epoch 186/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 19.4423 - mean_absolute_error: 19.4423\n",
      "Epoch 186: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.4578 - mean_absolute_error: 19.4578 - val_loss: 63.2242 - val_mean_absolute_error: 63.2242\n",
      "Epoch 187/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 19.0256 - mean_absolute_error: 19.0256\n",
      "Epoch 187: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.7320 - mean_absolute_error: 18.7320 - val_loss: 57.2466 - val_mean_absolute_error: 57.2466\n",
      "Epoch 188/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 17.7023 - mean_absolute_error: 17.7023\n",
      "Epoch 188: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.0133 - mean_absolute_error: 18.0133 - val_loss: 57.2717 - val_mean_absolute_error: 57.2717\n",
      "Epoch 189/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 20.8291 - mean_absolute_error: 20.8291\n",
      "Epoch 189: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 19.8701 - mean_absolute_error: 19.8701 - val_loss: 57.0461 - val_mean_absolute_error: 57.0461\n",
      "Epoch 190/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 19.1851 - mean_absolute_error: 19.1851\n",
      "Epoch 190: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.5859 - mean_absolute_error: 18.5859 - val_loss: 58.0764 - val_mean_absolute_error: 58.0764\n",
      "Epoch 191/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.0928 - mean_absolute_error: 18.0928\n",
      "Epoch 191: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.0150 - mean_absolute_error: 18.0150 - val_loss: 56.5712 - val_mean_absolute_error: 56.5712\n",
      "Epoch 192/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.3961 - mean_absolute_error: 18.3961\n",
      "Epoch 192: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 18.0224 - mean_absolute_error: 18.0224 - val_loss: 55.2277 - val_mean_absolute_error: 55.2277\n",
      "Epoch 193/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 18.1381 - mean_absolute_error: 18.1381\n",
      "Epoch 193: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 18.4866 - mean_absolute_error: 18.4866 - val_loss: 54.8988 - val_mean_absolute_error: 54.8988\n",
      "Epoch 194/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 19.2608 - mean_absolute_error: 19.2608\n",
      "Epoch 194: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.6822 - mean_absolute_error: 18.6822 - val_loss: 55.2703 - val_mean_absolute_error: 55.2703\n",
      "Epoch 195/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 18.4869 - mean_absolute_error: 18.4869\n",
      "Epoch 195: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.3866 - mean_absolute_error: 18.3866 - val_loss: 55.0007 - val_mean_absolute_error: 55.0007\n",
      "Epoch 196/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 18.3846 - mean_absolute_error: 18.3846\n",
      "Epoch 196: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.8038 - mean_absolute_error: 17.8038 - val_loss: 57.1977 - val_mean_absolute_error: 57.1977\n",
      "Epoch 197/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.6575 - mean_absolute_error: 18.6575\n",
      "Epoch 197: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.6556 - mean_absolute_error: 18.6556 - val_loss: 56.4070 - val_mean_absolute_error: 56.4070\n",
      "Epoch 198/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.1138 - mean_absolute_error: 17.1138\n",
      "Epoch 198: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.0885 - mean_absolute_error: 17.0885 - val_loss: 56.3841 - val_mean_absolute_error: 56.3841\n",
      "Epoch 199/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 18.1412 - mean_absolute_error: 18.1412\n",
      "Epoch 199: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.8161 - mean_absolute_error: 18.8161 - val_loss: 57.7750 - val_mean_absolute_error: 57.7750\n",
      "Epoch 200/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 20.5782 - mean_absolute_error: 20.5782\n",
      "Epoch 200: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.7274 - mean_absolute_error: 19.7274 - val_loss: 56.5180 - val_mean_absolute_error: 56.5180\n",
      "Epoch 201/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 18.4207 - mean_absolute_error: 18.4207\n",
      "Epoch 201: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.4971 - mean_absolute_error: 18.4971 - val_loss: 55.5836 - val_mean_absolute_error: 55.5836\n",
      "Epoch 202/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 19.5695 - mean_absolute_error: 19.5695\n",
      "Epoch 202: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.5543 - mean_absolute_error: 20.5543 - val_loss: 56.8383 - val_mean_absolute_error: 56.8383\n",
      "Epoch 203/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 18.1061 - mean_absolute_error: 18.1061\n",
      "Epoch 203: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.0785 - mean_absolute_error: 19.0785 - val_loss: 58.8670 - val_mean_absolute_error: 58.8670\n",
      "Epoch 204/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.6454 - mean_absolute_error: 19.6454\n",
      "Epoch 204: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.6454 - mean_absolute_error: 19.6454 - val_loss: 57.5527 - val_mean_absolute_error: 57.5527\n",
      "Epoch 205/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 19.2143 - mean_absolute_error: 19.2143\n",
      "Epoch 205: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.8741 - mean_absolute_error: 18.8741 - val_loss: 57.1117 - val_mean_absolute_error: 57.1117\n",
      "Epoch 206/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 17.7594 - mean_absolute_error: 17.7594\n",
      "Epoch 206: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.7594 - mean_absolute_error: 17.7594 - val_loss: 56.2699 - val_mean_absolute_error: 56.2699\n",
      "Epoch 207/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 19.8779 - mean_absolute_error: 19.8779\n",
      "Epoch 207: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.6766 - mean_absolute_error: 19.6766 - val_loss: 57.3920 - val_mean_absolute_error: 57.3920\n",
      "Epoch 208/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 18.2501 - mean_absolute_error: 18.2501\n",
      "Epoch 208: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.9337 - mean_absolute_error: 17.9337 - val_loss: 58.0098 - val_mean_absolute_error: 58.0098\n",
      "Epoch 209/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 18.5077 - mean_absolute_error: 18.5077\n",
      "Epoch 209: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.2524 - mean_absolute_error: 18.2524 - val_loss: 57.4971 - val_mean_absolute_error: 57.4971\n",
      "Epoch 210/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 18.0903 - mean_absolute_error: 18.0903\n",
      "Epoch 210: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.6867 - mean_absolute_error: 18.6867 - val_loss: 57.9431 - val_mean_absolute_error: 57.9431\n",
      "Epoch 211/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 18.2970 - mean_absolute_error: 18.2970\n",
      "Epoch 211: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.0952 - mean_absolute_error: 18.0952 - val_loss: 56.9045 - val_mean_absolute_error: 56.9045\n",
      "Epoch 212/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 18.8832 - mean_absolute_error: 18.8832\n",
      "Epoch 212: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.0572 - mean_absolute_error: 19.0572 - val_loss: 55.4454 - val_mean_absolute_error: 55.4454\n",
      "Epoch 213/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 18.0040 - mean_absolute_error: 18.0040\n",
      "Epoch 213: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.6248 - mean_absolute_error: 17.6248 - val_loss: 57.5084 - val_mean_absolute_error: 57.5084\n",
      "Epoch 214/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 16.2712 - mean_absolute_error: 16.2712\n",
      "Epoch 214: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.1082 - mean_absolute_error: 17.1082 - val_loss: 55.7709 - val_mean_absolute_error: 55.7709\n",
      "Epoch 215/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 18.1809 - mean_absolute_error: 18.1809\n",
      "Epoch 215: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.1323 - mean_absolute_error: 18.1323 - val_loss: 57.1101 - val_mean_absolute_error: 57.1101\n",
      "Epoch 216/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 18.2595 - mean_absolute_error: 18.2595\n",
      "Epoch 216: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.2595 - mean_absolute_error: 18.2595 - val_loss: 56.8424 - val_mean_absolute_error: 56.8424\n",
      "Epoch 217/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 18.5332 - mean_absolute_error: 18.5332\n",
      "Epoch 217: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.0899 - mean_absolute_error: 18.0899 - val_loss: 58.7640 - val_mean_absolute_error: 58.7640\n",
      "Epoch 218/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.4740 - mean_absolute_error: 17.4740\n",
      "Epoch 218: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.1728 - mean_absolute_error: 18.1728 - val_loss: 57.6173 - val_mean_absolute_error: 57.6173\n",
      "Epoch 219/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 15.7380 - mean_absolute_error: 15.7380\n",
      "Epoch 219: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.9020 - mean_absolute_error: 18.9020 - val_loss: 56.8069 - val_mean_absolute_error: 56.8069\n",
      "Epoch 220/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 19.4068 - mean_absolute_error: 19.4068\n",
      "Epoch 220: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.4068 - mean_absolute_error: 19.4068 - val_loss: 60.9584 - val_mean_absolute_error: 60.9584\n",
      "Epoch 221/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 19.3483 - mean_absolute_error: 19.3483\n",
      "Epoch 221: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.3566 - mean_absolute_error: 19.3566 - val_loss: 55.9892 - val_mean_absolute_error: 55.9892\n",
      "Epoch 222/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 19.2021 - mean_absolute_error: 19.2021\n",
      "Epoch 222: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.8594 - mean_absolute_error: 18.8594 - val_loss: 56.2873 - val_mean_absolute_error: 56.2873\n",
      "Epoch 223/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 17.6400 - mean_absolute_error: 17.6400\n",
      "Epoch 223: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.1446 - mean_absolute_error: 18.1446 - val_loss: 57.5195 - val_mean_absolute_error: 57.5195\n",
      "Epoch 224/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.8322 - mean_absolute_error: 17.8322\n",
      "Epoch 224: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.2261 - mean_absolute_error: 18.2261 - val_loss: 58.5663 - val_mean_absolute_error: 58.5663\n",
      "Epoch 225/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 20.8402 - mean_absolute_error: 20.8402\n",
      "Epoch 225: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 20.7731 - mean_absolute_error: 20.7731 - val_loss: 55.3122 - val_mean_absolute_error: 55.3122\n",
      "Epoch 226/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 19.2101 - mean_absolute_error: 19.2101\n",
      "Epoch 226: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 19.3829 - mean_absolute_error: 19.3829 - val_loss: 58.7986 - val_mean_absolute_error: 58.7986\n",
      "Epoch 227/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 18.1590 - mean_absolute_error: 18.1590\n",
      "Epoch 227: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.8964 - mean_absolute_error: 17.8964 - val_loss: 56.0482 - val_mean_absolute_error: 56.0482\n",
      "Epoch 228/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 18.5242 - mean_absolute_error: 18.5242\n",
      "Epoch 228: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.1179 - mean_absolute_error: 18.1179 - val_loss: 56.1537 - val_mean_absolute_error: 56.1537\n",
      "Epoch 229/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 15.7649 - mean_absolute_error: 15.7649\n",
      "Epoch 229: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.6910 - mean_absolute_error: 17.6910 - val_loss: 59.9544 - val_mean_absolute_error: 59.9544\n",
      "Epoch 230/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 18.9236 - mean_absolute_error: 18.9236\n",
      "Epoch 230: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 19.0184 - mean_absolute_error: 19.0184 - val_loss: 56.5344 - val_mean_absolute_error: 56.5344\n",
      "Epoch 231/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 17.1168 - mean_absolute_error: 17.1168\n",
      "Epoch 231: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.4253 - mean_absolute_error: 18.4253 - val_loss: 57.3742 - val_mean_absolute_error: 57.3742\n",
      "Epoch 232/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.8743 - mean_absolute_error: 17.8743\n",
      "Epoch 232: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.4246 - mean_absolute_error: 17.4246 - val_loss: 58.0658 - val_mean_absolute_error: 58.0658\n",
      "Epoch 233/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 18.1996 - mean_absolute_error: 18.1996\n",
      "Epoch 233: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.8607 - mean_absolute_error: 17.8607 - val_loss: 55.9230 - val_mean_absolute_error: 55.9230\n",
      "Epoch 234/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.8435 - mean_absolute_error: 17.8435\n",
      "Epoch 234: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.6336 - mean_absolute_error: 17.6336 - val_loss: 58.1364 - val_mean_absolute_error: 58.1364\n",
      "Epoch 235/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 16.3942 - mean_absolute_error: 16.3942\n",
      "Epoch 235: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.6700 - mean_absolute_error: 18.6700 - val_loss: 57.2357 - val_mean_absolute_error: 57.2357\n",
      "Epoch 236/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.5593 - mean_absolute_error: 16.5593\n",
      "Epoch 236: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.6577 - mean_absolute_error: 17.6577 - val_loss: 58.8765 - val_mean_absolute_error: 58.8765\n",
      "Epoch 237/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 17.6469 - mean_absolute_error: 17.6469\n",
      "Epoch 237: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.4598 - mean_absolute_error: 17.4598 - val_loss: 55.8082 - val_mean_absolute_error: 55.8082\n",
      "Epoch 238/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 17.1504 - mean_absolute_error: 17.1504\n",
      "Epoch 238: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.0155 - mean_absolute_error: 17.0155 - val_loss: 56.0637 - val_mean_absolute_error: 56.0637\n",
      "Epoch 239/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 16.8331 - mean_absolute_error: 16.8331\n",
      "Epoch 239: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.6026 - mean_absolute_error: 17.6026 - val_loss: 57.2957 - val_mean_absolute_error: 57.2957\n",
      "Epoch 240/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 20.5475 - mean_absolute_error: 20.5475\n",
      "Epoch 240: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 20.1421 - mean_absolute_error: 20.1421 - val_loss: 56.3119 - val_mean_absolute_error: 56.3119\n",
      "Epoch 241/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 17.8538 - mean_absolute_error: 17.8538\n",
      "Epoch 241: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.7555 - mean_absolute_error: 17.7555 - val_loss: 56.9126 - val_mean_absolute_error: 56.9126\n",
      "Epoch 242/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.0359 - mean_absolute_error: 17.0359\n",
      "Epoch 242: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.3242 - mean_absolute_error: 17.3242 - val_loss: 57.5056 - val_mean_absolute_error: 57.5056\n",
      "Epoch 243/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 19.6258 - mean_absolute_error: 19.6258\n",
      "Epoch 243: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.6925 - mean_absolute_error: 18.6925 - val_loss: 58.5564 - val_mean_absolute_error: 58.5564\n",
      "Epoch 244/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 16.9542 - mean_absolute_error: 16.9542\n",
      "Epoch 244: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.7648 - mean_absolute_error: 16.7648 - val_loss: 59.3972 - val_mean_absolute_error: 59.3972\n",
      "Epoch 245/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 18.0127 - mean_absolute_error: 18.0127\n",
      "Epoch 245: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.8197 - mean_absolute_error: 17.8197 - val_loss: 56.5476 - val_mean_absolute_error: 56.5476\n",
      "Epoch 246/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.1012 - mean_absolute_error: 18.1012\n",
      "Epoch 246: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.2310 - mean_absolute_error: 17.2310 - val_loss: 57.7209 - val_mean_absolute_error: 57.7209\n",
      "Epoch 247/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 16.4948 - mean_absolute_error: 16.4948\n",
      "Epoch 247: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.3076 - mean_absolute_error: 16.3076 - val_loss: 56.9807 - val_mean_absolute_error: 56.9807\n",
      "Epoch 248/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.6912 - mean_absolute_error: 17.6912\n",
      "Epoch 248: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 18.0043 - mean_absolute_error: 18.0043 - val_loss: 57.1618 - val_mean_absolute_error: 57.1618\n",
      "Epoch 249/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 17.2117 - mean_absolute_error: 17.2117\n",
      "Epoch 249: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.2117 - mean_absolute_error: 17.2117 - val_loss: 56.6198 - val_mean_absolute_error: 56.6198\n",
      "Epoch 250/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.0411 - mean_absolute_error: 18.0411\n",
      "Epoch 250: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.9020 - mean_absolute_error: 17.9020 - val_loss: 56.4079 - val_mean_absolute_error: 56.4079\n",
      "Epoch 251/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 17.4618 - mean_absolute_error: 17.4618\n",
      "Epoch 251: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.0825 - mean_absolute_error: 17.0825 - val_loss: 57.2794 - val_mean_absolute_error: 57.2794\n",
      "Epoch 252/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 16.7163 - mean_absolute_error: 16.7163\n",
      "Epoch 252: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.5490 - mean_absolute_error: 17.5490 - val_loss: 57.6302 - val_mean_absolute_error: 57.6302\n",
      "Epoch 253/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 17.3359 - mean_absolute_error: 17.3359\n",
      "Epoch 253: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.4932 - mean_absolute_error: 17.4932 - val_loss: 59.4384 - val_mean_absolute_error: 59.4384\n",
      "Epoch 254/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.0134 - mean_absolute_error: 18.0134\n",
      "Epoch 254: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.5844 - mean_absolute_error: 18.5844 - val_loss: 57.0742 - val_mean_absolute_error: 57.0742\n",
      "Epoch 255/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 17.7592 - mean_absolute_error: 17.7592\n",
      "Epoch 255: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.5737 - mean_absolute_error: 17.5737 - val_loss: 55.5959 - val_mean_absolute_error: 55.5959\n",
      "Epoch 256/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.0726 - mean_absolute_error: 16.0726\n",
      "Epoch 256: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.0274 - mean_absolute_error: 17.0274 - val_loss: 55.8212 - val_mean_absolute_error: 55.8212\n",
      "Epoch 257/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 16.0194 - mean_absolute_error: 16.0194\n",
      "Epoch 257: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.9251 - mean_absolute_error: 16.9251 - val_loss: 57.3256 - val_mean_absolute_error: 57.3256\n",
      "Epoch 258/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 15.5757 - mean_absolute_error: 15.5757\n",
      "Epoch 258: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.1322 - mean_absolute_error: 16.1322 - val_loss: 56.7450 - val_mean_absolute_error: 56.7450\n",
      "Epoch 259/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 19.3891 - mean_absolute_error: 19.3891\n",
      "Epoch 259: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.5843 - mean_absolute_error: 18.5843 - val_loss: 57.4678 - val_mean_absolute_error: 57.4678\n",
      "Epoch 260/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 16.3970 - mean_absolute_error: 16.3970\n",
      "Epoch 260: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.6300 - mean_absolute_error: 16.6300 - val_loss: 58.5369 - val_mean_absolute_error: 58.5369\n",
      "Epoch 261/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 16.4624 - mean_absolute_error: 16.4624\n",
      "Epoch 261: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.7432 - mean_absolute_error: 17.7432 - val_loss: 56.2696 - val_mean_absolute_error: 56.2696\n",
      "Epoch 262/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 16.3938 - mean_absolute_error: 16.3938\n",
      "Epoch 262: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.5418 - mean_absolute_error: 17.5418 - val_loss: 56.7038 - val_mean_absolute_error: 56.7038\n",
      "Epoch 263/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 15.1222 - mean_absolute_error: 15.1222\n",
      "Epoch 263: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.0289 - mean_absolute_error: 17.0289 - val_loss: 58.3717 - val_mean_absolute_error: 58.3717\n",
      "Epoch 264/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 16.6900 - mean_absolute_error: 16.6900\n",
      "Epoch 264: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.0257 - mean_absolute_error: 17.0257 - val_loss: 56.7473 - val_mean_absolute_error: 56.7473\n",
      "Epoch 265/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 17.3812 - mean_absolute_error: 17.3812\n",
      "Epoch 265: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.3812 - mean_absolute_error: 17.3812 - val_loss: 57.5369 - val_mean_absolute_error: 57.5369\n",
      "Epoch 266/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 16.6467 - mean_absolute_error: 16.6467\n",
      "Epoch 266: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.9450 - mean_absolute_error: 16.9450 - val_loss: 56.0396 - val_mean_absolute_error: 56.0396\n",
      "Epoch 267/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 16.0140 - mean_absolute_error: 16.0140\n",
      "Epoch 267: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 17.6803 - mean_absolute_error: 17.6803 - val_loss: 56.6471 - val_mean_absolute_error: 56.6471\n",
      "Epoch 268/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 15.7685 - mean_absolute_error: 15.7685\n",
      "Epoch 268: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.2811 - mean_absolute_error: 16.2811 - val_loss: 56.8366 - val_mean_absolute_error: 56.8366\n",
      "Epoch 269/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 17.0198 - mean_absolute_error: 17.0198\n",
      "Epoch 269: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.3912 - mean_absolute_error: 17.3912 - val_loss: 57.2176 - val_mean_absolute_error: 57.2176\n",
      "Epoch 270/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.2278 - mean_absolute_error: 17.2278\n",
      "Epoch 270: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.6986 - mean_absolute_error: 16.6986 - val_loss: 59.1406 - val_mean_absolute_error: 59.1406\n",
      "Epoch 271/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 17.6257 - mean_absolute_error: 17.6257\n",
      "Epoch 271: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.8311 - mean_absolute_error: 16.8311 - val_loss: 56.5869 - val_mean_absolute_error: 56.5869\n",
      "Epoch 272/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.1633 - mean_absolute_error: 15.1633\n",
      "Epoch 272: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.2334 - mean_absolute_error: 16.2334 - val_loss: 57.5095 - val_mean_absolute_error: 57.5095\n",
      "Epoch 273/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 18.0403 - mean_absolute_error: 18.0403\n",
      "Epoch 273: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 18.0403 - mean_absolute_error: 18.0403 - val_loss: 57.6945 - val_mean_absolute_error: 57.6945\n",
      "Epoch 274/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.5584 - mean_absolute_error: 18.5584\n",
      "Epoch 274: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 18.9886 - mean_absolute_error: 18.9886 - val_loss: 58.7352 - val_mean_absolute_error: 58.7352\n",
      "Epoch 275/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 18.7808 - mean_absolute_error: 18.7808\n",
      "Epoch 275: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 18.0565 - mean_absolute_error: 18.0565 - val_loss: 56.1354 - val_mean_absolute_error: 56.1354\n",
      "Epoch 276/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 16.2397 - mean_absolute_error: 16.2397\n",
      "Epoch 276: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.2417 - mean_absolute_error: 16.2417 - val_loss: 56.5409 - val_mean_absolute_error: 56.5409\n",
      "Epoch 277/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 16.5893 - mean_absolute_error: 16.5893\n",
      "Epoch 277: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.8827 - mean_absolute_error: 15.8827 - val_loss: 59.0473 - val_mean_absolute_error: 59.0473\n",
      "Epoch 278/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 17.1694 - mean_absolute_error: 17.1694\n",
      "Epoch 278: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.1694 - mean_absolute_error: 17.1694 - val_loss: 57.3751 - val_mean_absolute_error: 57.3751\n",
      "Epoch 279/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.7192 - mean_absolute_error: 15.7192\n",
      "Epoch 279: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.8283 - mean_absolute_error: 15.8283 - val_loss: 58.1562 - val_mean_absolute_error: 58.1562\n",
      "Epoch 280/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 14.2713 - mean_absolute_error: 14.2713\n",
      "Epoch 280: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.9830 - mean_absolute_error: 16.9830 - val_loss: 58.9348 - val_mean_absolute_error: 58.9348\n",
      "Epoch 281/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 18.8396 - mean_absolute_error: 18.8396\n",
      "Epoch 281: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 17.4745 - mean_absolute_error: 17.4745 - val_loss: 57.0593 - val_mean_absolute_error: 57.0593\n",
      "Epoch 282/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 16.4342 - mean_absolute_error: 16.4342\n",
      "Epoch 282: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.4342 - mean_absolute_error: 16.4342 - val_loss: 58.6581 - val_mean_absolute_error: 58.6581\n",
      "Epoch 283/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 16.5951 - mean_absolute_error: 16.5951\n",
      "Epoch 283: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 16.5951 - mean_absolute_error: 16.5951 - val_loss: 57.0068 - val_mean_absolute_error: 57.0068\n",
      "Epoch 284/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.6027 - mean_absolute_error: 15.6027\n",
      "Epoch 284: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 16.5022 - mean_absolute_error: 16.5022 - val_loss: 57.9861 - val_mean_absolute_error: 57.9861\n",
      "Epoch 285/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.5134 - mean_absolute_error: 14.5134\n",
      "Epoch 285: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.8619 - mean_absolute_error: 15.8619 - val_loss: 57.1785 - val_mean_absolute_error: 57.1785\n",
      "Epoch 286/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 16.6997 - mean_absolute_error: 16.6997\n",
      "Epoch 286: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.4943 - mean_absolute_error: 16.4943 - val_loss: 56.7507 - val_mean_absolute_error: 56.7507\n",
      "Epoch 287/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 15.5196 - mean_absolute_error: 15.5196\n",
      "Epoch 287: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.5196 - mean_absolute_error: 15.5196 - val_loss: 57.5449 - val_mean_absolute_error: 57.5449\n",
      "Epoch 288/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 16.8142 - mean_absolute_error: 16.8142\n",
      "Epoch 288: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.5940 - mean_absolute_error: 16.5940 - val_loss: 56.9986 - val_mean_absolute_error: 56.9986\n",
      "Epoch 289/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.1202 - mean_absolute_error: 17.1202\n",
      "Epoch 289: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.9827 - mean_absolute_error: 16.9827 - val_loss: 60.4061 - val_mean_absolute_error: 60.4061\n",
      "Epoch 290/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 17.2651 - mean_absolute_error: 17.2651\n",
      "Epoch 290: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 17ms/step - loss: 17.7264 - mean_absolute_error: 17.7264 - val_loss: 57.9910 - val_mean_absolute_error: 57.9910\n",
      "Epoch 291/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 16.2981 - mean_absolute_error: 16.2981\n",
      "Epoch 291: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 16.2981 - mean_absolute_error: 16.2981 - val_loss: 56.8803 - val_mean_absolute_error: 56.8803\n",
      "Epoch 292/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.6375 - mean_absolute_error: 15.6375\n",
      "Epoch 292: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 16.0476 - mean_absolute_error: 16.0476 - val_loss: 59.2081 - val_mean_absolute_error: 59.2081\n",
      "Epoch 293/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 17.8037 - mean_absolute_error: 17.8037\n",
      "Epoch 293: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 17.3228 - mean_absolute_error: 17.3228 - val_loss: 56.3690 - val_mean_absolute_error: 56.3690\n",
      "Epoch 294/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 16.3278 - mean_absolute_error: 16.3278\n",
      "Epoch 294: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.9382 - mean_absolute_error: 15.9382 - val_loss: 58.2157 - val_mean_absolute_error: 58.2157\n",
      "Epoch 295/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 16.7061 - mean_absolute_error: 16.7061\n",
      "Epoch 295: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.7061 - mean_absolute_error: 16.7061 - val_loss: 56.6837 - val_mean_absolute_error: 56.6837\n",
      "Epoch 296/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.3786 - mean_absolute_error: 15.3786\n",
      "Epoch 296: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.6805 - mean_absolute_error: 15.6805 - val_loss: 57.2010 - val_mean_absolute_error: 57.2010\n",
      "Epoch 297/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 14.5153 - mean_absolute_error: 14.5153\n",
      "Epoch 297: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.3640 - mean_absolute_error: 15.3640 - val_loss: 57.8408 - val_mean_absolute_error: 57.8408\n",
      "Epoch 298/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 14.5331 - mean_absolute_error: 14.5331\n",
      "Epoch 298: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.2018 - mean_absolute_error: 15.2018 - val_loss: 57.5643 - val_mean_absolute_error: 57.5643\n",
      "Epoch 299/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 16.8454 - mean_absolute_error: 16.8454\n",
      "Epoch 299: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 16.6200 - mean_absolute_error: 16.6200 - val_loss: 55.6741 - val_mean_absolute_error: 55.6741\n",
      "Epoch 300/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 16.2989 - mean_absolute_error: 16.2989\n",
      "Epoch 300: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 16.0743 - mean_absolute_error: 16.0743 - val_loss: 57.4967 - val_mean_absolute_error: 57.4967\n",
      "Epoch 301/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.7455 - mean_absolute_error: 15.7455\n",
      "Epoch 301: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.7773 - mean_absolute_error: 15.7773 - val_loss: 57.8719 - val_mean_absolute_error: 57.8719\n",
      "Epoch 302/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.0965 - mean_absolute_error: 17.0965\n",
      "Epoch 302: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.3163 - mean_absolute_error: 16.3163 - val_loss: 59.1004 - val_mean_absolute_error: 59.1004\n",
      "Epoch 303/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.2705 - mean_absolute_error: 17.2705\n",
      "Epoch 303: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 16.7158 - mean_absolute_error: 16.7158 - val_loss: 56.7547 - val_mean_absolute_error: 56.7547\n",
      "Epoch 304/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 17.7939 - mean_absolute_error: 17.7939\n",
      "Epoch 304: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 16.8308 - mean_absolute_error: 16.8308 - val_loss: 58.6794 - val_mean_absolute_error: 58.6794\n",
      "Epoch 305/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 15.6825 - mean_absolute_error: 15.6825\n",
      "Epoch 305: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 16.3242 - mean_absolute_error: 16.3242 - val_loss: 56.4948 - val_mean_absolute_error: 56.4948\n",
      "Epoch 306/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 17.5188 - mean_absolute_error: 17.5188\n",
      "Epoch 306: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 17.5188 - mean_absolute_error: 17.5188 - val_loss: 56.9456 - val_mean_absolute_error: 56.9456\n",
      "Epoch 307/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 15.5850 - mean_absolute_error: 15.5850\n",
      "Epoch 307: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.7722 - mean_absolute_error: 15.7722 - val_loss: 57.1639 - val_mean_absolute_error: 57.1639\n",
      "Epoch 308/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.4305 - mean_absolute_error: 17.4305\n",
      "Epoch 308: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 17.1587 - mean_absolute_error: 17.1587 - val_loss: 56.6862 - val_mean_absolute_error: 56.6862\n",
      "Epoch 309/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.4387 - mean_absolute_error: 16.4387\n",
      "Epoch 309: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.3592 - mean_absolute_error: 16.3592 - val_loss: 56.2007 - val_mean_absolute_error: 56.2007\n",
      "Epoch 310/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 16.7768 - mean_absolute_error: 16.7768\n",
      "Epoch 310: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 16.5701 - mean_absolute_error: 16.5701 - val_loss: 57.4366 - val_mean_absolute_error: 57.4366\n",
      "Epoch 311/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.5034 - mean_absolute_error: 16.5034\n",
      "Epoch 311: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 16.2280 - mean_absolute_error: 16.2280 - val_loss: 58.8593 - val_mean_absolute_error: 58.8593\n",
      "Epoch 312/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 17.0953 - mean_absolute_error: 17.0953\n",
      "Epoch 312: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 12ms/step - loss: 16.4097 - mean_absolute_error: 16.4097 - val_loss: 56.6030 - val_mean_absolute_error: 56.6030\n",
      "Epoch 313/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.6260 - mean_absolute_error: 15.6260\n",
      "Epoch 313: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.8318 - mean_absolute_error: 15.8318 - val_loss: 55.0180 - val_mean_absolute_error: 55.0180\n",
      "Epoch 314/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 16.2808 - mean_absolute_error: 16.2808\n",
      "Epoch 314: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 15.8681 - mean_absolute_error: 15.8681 - val_loss: 56.5401 - val_mean_absolute_error: 56.5401\n",
      "Epoch 315/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.7962 - mean_absolute_error: 15.7962\n",
      "Epoch 315: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 15.9743 - mean_absolute_error: 15.9743 - val_loss: 56.5316 - val_mean_absolute_error: 56.5316\n",
      "Epoch 316/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 15.4006 - mean_absolute_error: 15.4006\n",
      "Epoch 316: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 15.4006 - mean_absolute_error: 15.4006 - val_loss: 58.2297 - val_mean_absolute_error: 58.2297\n",
      "Epoch 317/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 14.7704 - mean_absolute_error: 14.7704\n",
      "Epoch 317: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 15.8774 - mean_absolute_error: 15.8774 - val_loss: 57.7361 - val_mean_absolute_error: 57.7361\n",
      "Epoch 318/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 17.5718 - mean_absolute_error: 17.5718\n",
      "Epoch 318: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 17.4539 - mean_absolute_error: 17.4539 - val_loss: 56.8089 - val_mean_absolute_error: 56.8089\n",
      "Epoch 319/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 15.8393 - mean_absolute_error: 15.8393\n",
      "Epoch 319: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.8192 - mean_absolute_error: 15.8192 - val_loss: 56.3293 - val_mean_absolute_error: 56.3293\n",
      "Epoch 320/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 15.0609 - mean_absolute_error: 15.0609\n",
      "Epoch 320: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.3775 - mean_absolute_error: 15.3775 - val_loss: 57.8267 - val_mean_absolute_error: 57.8267\n",
      "Epoch 321/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.6024 - mean_absolute_error: 15.6024\n",
      "Epoch 321: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 15.6523 - mean_absolute_error: 15.6523 - val_loss: 57.1088 - val_mean_absolute_error: 57.1088\n",
      "Epoch 322/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.2510 - mean_absolute_error: 16.2510\n",
      "Epoch 322: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.9552 - mean_absolute_error: 15.9552 - val_loss: 58.2612 - val_mean_absolute_error: 58.2612\n",
      "Epoch 323/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 15.5685 - mean_absolute_error: 15.5685\n",
      "Epoch 323: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.0673 - mean_absolute_error: 15.0673 - val_loss: 56.1622 - val_mean_absolute_error: 56.1622\n",
      "Epoch 324/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.9158 - mean_absolute_error: 15.9158\n",
      "Epoch 324: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.7904 - mean_absolute_error: 15.7904 - val_loss: 56.8790 - val_mean_absolute_error: 56.8790\n",
      "Epoch 325/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 15.4732 - mean_absolute_error: 15.4732\n",
      "Epoch 325: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.4629 - mean_absolute_error: 15.4629 - val_loss: 57.5739 - val_mean_absolute_error: 57.5739\n",
      "Epoch 326/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 15.9221 - mean_absolute_error: 15.9221\n",
      "Epoch 326: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.9504 - mean_absolute_error: 15.9504 - val_loss: 56.2929 - val_mean_absolute_error: 56.2929\n",
      "Epoch 327/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 14.6661 - mean_absolute_error: 14.6661\n",
      "Epoch 327: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.8739 - mean_absolute_error: 15.8739 - val_loss: 56.6572 - val_mean_absolute_error: 56.6572\n",
      "Epoch 328/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.0191 - mean_absolute_error: 14.0191\n",
      "Epoch 328: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.8158 - mean_absolute_error: 15.8158 - val_loss: 57.1699 - val_mean_absolute_error: 57.1699\n",
      "Epoch 329/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 16.2186 - mean_absolute_error: 16.2186\n",
      "Epoch 329: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 16.0197 - mean_absolute_error: 16.0197 - val_loss: 56.9215 - val_mean_absolute_error: 56.9215\n",
      "Epoch 330/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 16.5484 - mean_absolute_error: 16.5484\n",
      "Epoch 330: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.0332 - mean_absolute_error: 16.0332 - val_loss: 57.5617 - val_mean_absolute_error: 57.5617\n",
      "Epoch 331/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.3591 - mean_absolute_error: 15.3591\n",
      "Epoch 331: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.3916 - mean_absolute_error: 15.3916 - val_loss: 56.2127 - val_mean_absolute_error: 56.2127\n",
      "Epoch 332/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 16.1765 - mean_absolute_error: 16.1765\n",
      "Epoch 332: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 16.1777 - mean_absolute_error: 16.1777 - val_loss: 56.6343 - val_mean_absolute_error: 56.6343\n",
      "Epoch 333/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 14.4163 - mean_absolute_error: 14.4163\n",
      "Epoch 333: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 15.1928 - mean_absolute_error: 15.1928 - val_loss: 55.9194 - val_mean_absolute_error: 55.9194\n",
      "Epoch 334/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.7944 - mean_absolute_error: 15.7944\n",
      "Epoch 334: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.6740 - mean_absolute_error: 15.6740 - val_loss: 57.5498 - val_mean_absolute_error: 57.5498\n",
      "Epoch 335/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 13.9402 - mean_absolute_error: 13.9402\n",
      "Epoch 335: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.0347 - mean_absolute_error: 15.0347 - val_loss: 56.5308 - val_mean_absolute_error: 56.5308\n",
      "Epoch 336/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.5611 - mean_absolute_error: 15.5611\n",
      "Epoch 336: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.4071 - mean_absolute_error: 15.4071 - val_loss: 56.1516 - val_mean_absolute_error: 56.1516\n",
      "Epoch 337/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 16.8381 - mean_absolute_error: 16.8381\n",
      "Epoch 337: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 16.3506 - mean_absolute_error: 16.3506 - val_loss: 56.8536 - val_mean_absolute_error: 56.8536\n",
      "Epoch 338/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 17.2826 - mean_absolute_error: 17.2826\n",
      "Epoch 338: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 16.9746 - mean_absolute_error: 16.9746 - val_loss: 55.9898 - val_mean_absolute_error: 55.9898\n",
      "Epoch 339/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.5339 - mean_absolute_error: 15.5339\n",
      "Epoch 339: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.5268 - mean_absolute_error: 15.5268 - val_loss: 56.3426 - val_mean_absolute_error: 56.3426\n",
      "Epoch 340/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.3473 - mean_absolute_error: 15.3473\n",
      "Epoch 340: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.1932 - mean_absolute_error: 15.1932 - val_loss: 55.0861 - val_mean_absolute_error: 55.0861\n",
      "Epoch 341/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.4047 - mean_absolute_error: 15.4047\n",
      "Epoch 341: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.4330 - mean_absolute_error: 15.4330 - val_loss: 56.5684 - val_mean_absolute_error: 56.5684\n",
      "Epoch 342/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 14.5075 - mean_absolute_error: 14.5075\n",
      "Epoch 342: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.4843 - mean_absolute_error: 14.4843 - val_loss: 56.8739 - val_mean_absolute_error: 56.8739\n",
      "Epoch 343/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 15.6767 - mean_absolute_error: 15.6767\n",
      "Epoch 343: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.2055 - mean_absolute_error: 15.2055 - val_loss: 57.2353 - val_mean_absolute_error: 57.2353\n",
      "Epoch 344/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.2397 - mean_absolute_error: 15.2397\n",
      "Epoch 344: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.0289 - mean_absolute_error: 15.0289 - val_loss: 56.6970 - val_mean_absolute_error: 56.6970\n",
      "Epoch 345/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 16.2786 - mean_absolute_error: 16.2786\n",
      "Epoch 345: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 16.0951 - mean_absolute_error: 16.0951 - val_loss: 57.2667 - val_mean_absolute_error: 57.2667\n",
      "Epoch 346/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 15.6017 - mean_absolute_error: 15.6017\n",
      "Epoch 346: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.2978 - mean_absolute_error: 15.2978 - val_loss: 55.6655 - val_mean_absolute_error: 55.6655\n",
      "Epoch 347/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.2030 - mean_absolute_error: 15.2030\n",
      "Epoch 347: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.1001 - mean_absolute_error: 15.1001 - val_loss: 56.5569 - val_mean_absolute_error: 56.5569\n",
      "Epoch 348/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.7178 - mean_absolute_error: 15.7178\n",
      "Epoch 348: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.4820 - mean_absolute_error: 15.4820 - val_loss: 55.7345 - val_mean_absolute_error: 55.7345\n",
      "Epoch 349/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.5831 - mean_absolute_error: 15.5831\n",
      "Epoch 349: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 15.4258 - mean_absolute_error: 15.4258 - val_loss: 54.9916 - val_mean_absolute_error: 54.9916\n",
      "Epoch 350/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 15.7539 - mean_absolute_error: 15.7539\n",
      "Epoch 350: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.7107 - mean_absolute_error: 15.7107 - val_loss: 56.0903 - val_mean_absolute_error: 56.0903\n",
      "Epoch 351/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.6312 - mean_absolute_error: 14.6312\n",
      "Epoch 351: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.4846 - mean_absolute_error: 14.4846 - val_loss: 54.7503 - val_mean_absolute_error: 54.7503\n",
      "Epoch 352/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.1409 - mean_absolute_error: 15.1409\n",
      "Epoch 352: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.9556 - mean_absolute_error: 14.9556 - val_loss: 55.0978 - val_mean_absolute_error: 55.0978\n",
      "Epoch 353/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.2360 - mean_absolute_error: 14.2360\n",
      "Epoch 353: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.1733 - mean_absolute_error: 14.1733 - val_loss: 57.9310 - val_mean_absolute_error: 57.9310\n",
      "Epoch 354/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 14.2655 - mean_absolute_error: 14.2655\n",
      "Epoch 354: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.2655 - mean_absolute_error: 14.2655 - val_loss: 57.3950 - val_mean_absolute_error: 57.3950\n",
      "Epoch 355/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 16.3035 - mean_absolute_error: 16.3035\n",
      "Epoch 355: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.8100 - mean_absolute_error: 15.8100 - val_loss: 61.6582 - val_mean_absolute_error: 61.6582\n",
      "Epoch 356/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 16.3700 - mean_absolute_error: 16.3700\n",
      "Epoch 356: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 16.2916 - mean_absolute_error: 16.2916 - val_loss: 56.1271 - val_mean_absolute_error: 56.1271\n",
      "Epoch 357/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.7247 - mean_absolute_error: 14.7247\n",
      "Epoch 357: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.6090 - mean_absolute_error: 14.6090 - val_loss: 57.3251 - val_mean_absolute_error: 57.3251\n",
      "Epoch 358/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.2315 - mean_absolute_error: 15.2315\n",
      "Epoch 358: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.1497 - mean_absolute_error: 15.1497 - val_loss: 56.4681 - val_mean_absolute_error: 56.4681\n",
      "Epoch 359/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 14.3676 - mean_absolute_error: 14.3676\n",
      "Epoch 359: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.8421 - mean_absolute_error: 14.8421 - val_loss: 58.1584 - val_mean_absolute_error: 58.1584\n",
      "Epoch 360/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 15.1582 - mean_absolute_error: 15.1582\n",
      "Epoch 360: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 14ms/step - loss: 14.5891 - mean_absolute_error: 14.5891 - val_loss: 58.2375 - val_mean_absolute_error: 58.2375\n",
      "Epoch 361/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.3054 - mean_absolute_error: 14.3054\n",
      "Epoch 361: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.6681 - mean_absolute_error: 14.6681 - val_loss: 57.5425 - val_mean_absolute_error: 57.5425\n",
      "Epoch 362/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 14.3402 - mean_absolute_error: 14.3402\n",
      "Epoch 362: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.1334 - mean_absolute_error: 14.1334 - val_loss: 57.1075 - val_mean_absolute_error: 57.1075\n",
      "Epoch 363/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 15.1373 - mean_absolute_error: 15.1373\n",
      "Epoch 363: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.8626 - mean_absolute_error: 14.8626 - val_loss: 57.7225 - val_mean_absolute_error: 57.7225\n",
      "Epoch 364/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.2790 - mean_absolute_error: 15.2790\n",
      "Epoch 364: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.2174 - mean_absolute_error: 15.2174 - val_loss: 58.7518 - val_mean_absolute_error: 58.7518\n",
      "Epoch 365/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 15.6419 - mean_absolute_error: 15.6419\n",
      "Epoch 365: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.7767 - mean_absolute_error: 15.7767 - val_loss: 57.0347 - val_mean_absolute_error: 57.0347\n",
      "Epoch 366/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 15.0632 - mean_absolute_error: 15.0632\n",
      "Epoch 366: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.0632 - mean_absolute_error: 15.0632 - val_loss: 57.5661 - val_mean_absolute_error: 57.5661\n",
      "Epoch 367/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 16.9679 - mean_absolute_error: 16.9679\n",
      "Epoch 367: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 15.9876 - mean_absolute_error: 15.9876 - val_loss: 57.5654 - val_mean_absolute_error: 57.5654\n",
      "Epoch 368/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.3557 - mean_absolute_error: 15.3557\n",
      "Epoch 368: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.4660 - mean_absolute_error: 15.4660 - val_loss: 55.8177 - val_mean_absolute_error: 55.8177\n",
      "Epoch 369/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.6120 - mean_absolute_error: 14.6120\n",
      "Epoch 369: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.3724 - mean_absolute_error: 14.3724 - val_loss: 57.7686 - val_mean_absolute_error: 57.7686\n",
      "Epoch 370/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.4968 - mean_absolute_error: 14.4968\n",
      "Epoch 370: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.6480 - mean_absolute_error: 14.6480 - val_loss: 59.5571 - val_mean_absolute_error: 59.5571\n",
      "Epoch 371/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.7546 - mean_absolute_error: 15.7546\n",
      "Epoch 371: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.5883 - mean_absolute_error: 15.5883 - val_loss: 57.4977 - val_mean_absolute_error: 57.4977\n",
      "Epoch 372/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 15.1733 - mean_absolute_error: 15.1733\n",
      "Epoch 372: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.0064 - mean_absolute_error: 15.0064 - val_loss: 59.3559 - val_mean_absolute_error: 59.3559\n",
      "Epoch 373/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.3667 - mean_absolute_error: 14.3667\n",
      "Epoch 373: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.5976 - mean_absolute_error: 14.5976 - val_loss: 58.7383 - val_mean_absolute_error: 58.7383\n",
      "Epoch 374/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 15.6767 - mean_absolute_error: 15.6767\n",
      "Epoch 374: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.4948 - mean_absolute_error: 15.4948 - val_loss: 56.7826 - val_mean_absolute_error: 56.7826\n",
      "Epoch 375/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 14.2996 - mean_absolute_error: 14.2996\n",
      "Epoch 375: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.6297 - mean_absolute_error: 13.6297 - val_loss: 55.7379 - val_mean_absolute_error: 55.7379\n",
      "Epoch 376/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 14.5565 - mean_absolute_error: 14.5565\n",
      "Epoch 376: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.5655 - mean_absolute_error: 14.5655 - val_loss: 57.6873 - val_mean_absolute_error: 57.6873\n",
      "Epoch 377/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.1721 - mean_absolute_error: 15.1721\n",
      "Epoch 377: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 15.1196 - mean_absolute_error: 15.1196 - val_loss: 60.2332 - val_mean_absolute_error: 60.2332\n",
      "Epoch 378/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 15.1152 - mean_absolute_error: 15.1152\n",
      "Epoch 378: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.7470 - mean_absolute_error: 14.7470 - val_loss: 57.1657 - val_mean_absolute_error: 57.1657\n",
      "Epoch 379/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.4379 - mean_absolute_error: 14.4379\n",
      "Epoch 379: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.8830 - mean_absolute_error: 14.8830 - val_loss: 56.8654 - val_mean_absolute_error: 56.8654\n",
      "Epoch 380/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 15.1484 - mean_absolute_error: 15.1484\n",
      "Epoch 380: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.6423 - mean_absolute_error: 14.6423 - val_loss: 57.4241 - val_mean_absolute_error: 57.4241\n",
      "Epoch 381/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 14.8925 - mean_absolute_error: 14.8925\n",
      "Epoch 381: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 14.8158 - mean_absolute_error: 14.8158 - val_loss: 57.8145 - val_mean_absolute_error: 57.8145\n",
      "Epoch 382/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.6752 - mean_absolute_error: 14.6752\n",
      "Epoch 382: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.7055 - mean_absolute_error: 14.7055 - val_loss: 57.6283 - val_mean_absolute_error: 57.6283\n",
      "Epoch 383/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 14.9941 - mean_absolute_error: 14.9941\n",
      "Epoch 383: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.6058 - mean_absolute_error: 14.6058 - val_loss: 58.3366 - val_mean_absolute_error: 58.3366\n",
      "Epoch 384/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.8729 - mean_absolute_error: 14.8729\n",
      "Epoch 384: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.5288 - mean_absolute_error: 14.5288 - val_loss: 58.7623 - val_mean_absolute_error: 58.7623\n",
      "Epoch 385/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 13.6353 - mean_absolute_error: 13.6353\n",
      "Epoch 385: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 13.7142 - mean_absolute_error: 13.7142 - val_loss: 56.3042 - val_mean_absolute_error: 56.3042\n",
      "Epoch 386/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.6870 - mean_absolute_error: 13.6870\n",
      "Epoch 386: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.6428 - mean_absolute_error: 13.6428 - val_loss: 58.4191 - val_mean_absolute_error: 58.4191\n",
      "Epoch 387/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.0984 - mean_absolute_error: 14.0984\n",
      "Epoch 387: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 14.0739 - mean_absolute_error: 14.0739 - val_loss: 56.7311 - val_mean_absolute_error: 56.7311\n",
      "Epoch 388/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 13.9046 - mean_absolute_error: 13.9046\n",
      "Epoch 388: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 14.0829 - mean_absolute_error: 14.0829 - val_loss: 58.1465 - val_mean_absolute_error: 58.1465\n",
      "Epoch 389/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 13.7701 - mean_absolute_error: 13.7701\n",
      "Epoch 389: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 13.8230 - mean_absolute_error: 13.8230 - val_loss: 58.1455 - val_mean_absolute_error: 58.1455\n",
      "Epoch 390/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.0885 - mean_absolute_error: 14.0885\n",
      "Epoch 390: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 13.9721 - mean_absolute_error: 13.9721 - val_loss: 56.0258 - val_mean_absolute_error: 56.0258\n",
      "Epoch 391/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 15.3616 - mean_absolute_error: 15.3616\n",
      "Epoch 391: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 15.3616 - mean_absolute_error: 15.3616 - val_loss: 57.8770 - val_mean_absolute_error: 57.8770\n",
      "Epoch 392/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 14.1560 - mean_absolute_error: 14.1560\n",
      "Epoch 392: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.8495 - mean_absolute_error: 14.8495 - val_loss: 57.0491 - val_mean_absolute_error: 57.0491\n",
      "Epoch 393/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 15.0199 - mean_absolute_error: 15.0199\n",
      "Epoch 393: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.4331 - mean_absolute_error: 14.4331 - val_loss: 56.6383 - val_mean_absolute_error: 56.6383\n",
      "Epoch 394/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 15.2498 - mean_absolute_error: 15.2498\n",
      "Epoch 394: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.4909 - mean_absolute_error: 14.4909 - val_loss: 58.3625 - val_mean_absolute_error: 58.3625\n",
      "Epoch 395/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 13.9700 - mean_absolute_error: 13.9700\n",
      "Epoch 395: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.9522 - mean_absolute_error: 13.9522 - val_loss: 59.2981 - val_mean_absolute_error: 59.2981\n",
      "Epoch 396/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 13.7864 - mean_absolute_error: 13.7864\n",
      "Epoch 396: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.4268 - mean_absolute_error: 14.4268 - val_loss: 56.8145 - val_mean_absolute_error: 56.8145\n",
      "Epoch 397/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 14.6108 - mean_absolute_error: 14.6108\n",
      "Epoch 397: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.3879 - mean_absolute_error: 14.3879 - val_loss: 59.8025 - val_mean_absolute_error: 59.8025\n",
      "Epoch 398/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.0522 - mean_absolute_error: 14.0522\n",
      "Epoch 398: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.6868 - mean_absolute_error: 13.6868 - val_loss: 56.8187 - val_mean_absolute_error: 56.8187\n",
      "Epoch 399/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 14.4734 - mean_absolute_error: 14.4734\n",
      "Epoch 399: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.4102 - mean_absolute_error: 14.4102 - val_loss: 55.7735 - val_mean_absolute_error: 55.7735\n",
      "Epoch 400/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.8407 - mean_absolute_error: 13.8407\n",
      "Epoch 400: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.8407 - mean_absolute_error: 13.8407 - val_loss: 56.6226 - val_mean_absolute_error: 56.6226\n",
      "Epoch 401/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 14.4810 - mean_absolute_error: 14.4810\n",
      "Epoch 401: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.3491 - mean_absolute_error: 14.3491 - val_loss: 58.1209 - val_mean_absolute_error: 58.1209\n",
      "Epoch 402/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 12.2527 - mean_absolute_error: 12.2527\n",
      "Epoch 402: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 13.2018 - mean_absolute_error: 13.2018 - val_loss: 56.7325 - val_mean_absolute_error: 56.7325\n",
      "Epoch 403/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 16.0299 - mean_absolute_error: 16.0299\n",
      "Epoch 403: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 14.7575 - mean_absolute_error: 14.7575 - val_loss: 58.7584 - val_mean_absolute_error: 58.7584\n",
      "Epoch 404/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 13.2102 - mean_absolute_error: 13.2102\n",
      "Epoch 404: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.2265 - mean_absolute_error: 13.2265 - val_loss: 59.6842 - val_mean_absolute_error: 59.6842\n",
      "Epoch 405/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 13.4127 - mean_absolute_error: 13.4127\n",
      "Epoch 405: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.3962 - mean_absolute_error: 14.3962 - val_loss: 57.6841 - val_mean_absolute_error: 57.6841\n",
      "Epoch 406/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 12.4589 - mean_absolute_error: 12.4589\n",
      "Epoch 406: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.4555 - mean_absolute_error: 14.4555 - val_loss: 57.9952 - val_mean_absolute_error: 57.9952\n",
      "Epoch 407/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 13.7746 - mean_absolute_error: 13.7746\n",
      "Epoch 407: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.5259 - mean_absolute_error: 13.5259 - val_loss: 55.3704 - val_mean_absolute_error: 55.3704\n",
      "Epoch 408/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 15.5202 - mean_absolute_error: 15.5202\n",
      "Epoch 408: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 15.5488 - mean_absolute_error: 15.5488 - val_loss: 60.9150 - val_mean_absolute_error: 60.9150\n",
      "Epoch 409/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 14.4019 - mean_absolute_error: 14.4019\n",
      "Epoch 409: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.7083 - mean_absolute_error: 13.7083 - val_loss: 58.7798 - val_mean_absolute_error: 58.7798\n",
      "Epoch 410/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 13.7703 - mean_absolute_error: 13.7703\n",
      "Epoch 410: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.6729 - mean_absolute_error: 14.6729 - val_loss: 57.8382 - val_mean_absolute_error: 57.8382\n",
      "Epoch 411/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.3808 - mean_absolute_error: 14.3808\n",
      "Epoch 411: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.5030 - mean_absolute_error: 14.5030 - val_loss: 56.5336 - val_mean_absolute_error: 56.5336\n",
      "Epoch 412/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 13.8683 - mean_absolute_error: 13.8683\n",
      "Epoch 412: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.5147 - mean_absolute_error: 13.5147 - val_loss: 58.5725 - val_mean_absolute_error: 58.5725\n",
      "Epoch 413/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 14.8025 - mean_absolute_error: 14.8025\n",
      "Epoch 413: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.6957 - mean_absolute_error: 14.6957 - val_loss: 56.2101 - val_mean_absolute_error: 56.2101\n",
      "Epoch 414/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 11.9659 - mean_absolute_error: 11.9659\n",
      "Epoch 414: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.0539 - mean_absolute_error: 13.0539 - val_loss: 57.8353 - val_mean_absolute_error: 57.8353\n",
      "Epoch 415/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 14.5568 - mean_absolute_error: 14.5568\n",
      "Epoch 415: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.3926 - mean_absolute_error: 14.3926 - val_loss: 57.2665 - val_mean_absolute_error: 57.2665\n",
      "Epoch 416/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 14.1888 - mean_absolute_error: 14.1888\n",
      "Epoch 416: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.3477 - mean_absolute_error: 14.3477 - val_loss: 56.9946 - val_mean_absolute_error: 56.9946\n",
      "Epoch 417/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 14.4895 - mean_absolute_error: 14.4895\n",
      "Epoch 417: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.5861 - mean_absolute_error: 13.5861 - val_loss: 57.9031 - val_mean_absolute_error: 57.9031\n",
      "Epoch 418/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 14.2405 - mean_absolute_error: 14.2405\n",
      "Epoch 418: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.9531 - mean_absolute_error: 13.9531 - val_loss: 56.7596 - val_mean_absolute_error: 56.7596\n",
      "Epoch 419/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 13.1938 - mean_absolute_error: 13.1938\n",
      "Epoch 419: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.6050 - mean_absolute_error: 13.6050 - val_loss: 57.8226 - val_mean_absolute_error: 57.8226\n",
      "Epoch 420/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 15.8541 - mean_absolute_error: 15.8541\n",
      "Epoch 420: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 16.2988 - mean_absolute_error: 16.2988 - val_loss: 58.7527 - val_mean_absolute_error: 58.7527\n",
      "Epoch 421/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 15.7216 - mean_absolute_error: 15.7216\n",
      "Epoch 421: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.8354 - mean_absolute_error: 14.8354 - val_loss: 57.5467 - val_mean_absolute_error: 57.5467\n",
      "Epoch 422/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.4071 - mean_absolute_error: 14.4071\n",
      "Epoch 422: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 14.1610 - mean_absolute_error: 14.1610 - val_loss: 56.2016 - val_mean_absolute_error: 56.2016\n",
      "Epoch 423/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 13.9606 - mean_absolute_error: 13.9606\n",
      "Epoch 423: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.4542 - mean_absolute_error: 14.4542 - val_loss: 56.9219 - val_mean_absolute_error: 56.9219\n",
      "Epoch 424/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 13.6036 - mean_absolute_error: 13.6036\n",
      "Epoch 424: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.4564 - mean_absolute_error: 13.4564 - val_loss: 58.2566 - val_mean_absolute_error: 58.2566\n",
      "Epoch 425/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 12.8491 - mean_absolute_error: 12.8491\n",
      "Epoch 425: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.2277 - mean_absolute_error: 13.2277 - val_loss: 56.4230 - val_mean_absolute_error: 56.4230\n",
      "Epoch 426/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 13.8786 - mean_absolute_error: 13.8786\n",
      "Epoch 426: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.5780 - mean_absolute_error: 13.5780 - val_loss: 56.3250 - val_mean_absolute_error: 56.3250\n",
      "Epoch 427/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 14.0602 - mean_absolute_error: 14.0602\n",
      "Epoch 427: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.0585 - mean_absolute_error: 14.0585 - val_loss: 57.6947 - val_mean_absolute_error: 57.6947\n",
      "Epoch 428/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.3896 - mean_absolute_error: 13.3896\n",
      "Epoch 428: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 13.2752 - mean_absolute_error: 13.2752 - val_loss: 56.9926 - val_mean_absolute_error: 56.9926\n",
      "Epoch 429/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.6813 - mean_absolute_error: 14.6813\n",
      "Epoch 429: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.8875 - mean_absolute_error: 13.8875 - val_loss: 56.6880 - val_mean_absolute_error: 56.6880\n",
      "Epoch 430/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 12.7776 - mean_absolute_error: 12.7776\n",
      "Epoch 430: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 12.7542 - mean_absolute_error: 12.7542 - val_loss: 57.7003 - val_mean_absolute_error: 57.7003\n",
      "Epoch 431/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 13.0264 - mean_absolute_error: 13.0264\n",
      "Epoch 431: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.2772 - mean_absolute_error: 13.2772 - val_loss: 57.9095 - val_mean_absolute_error: 57.9095\n",
      "Epoch 432/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 13.4070 - mean_absolute_error: 13.4070\n",
      "Epoch 432: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.1799 - mean_absolute_error: 13.1799 - val_loss: 56.9323 - val_mean_absolute_error: 56.9323\n",
      "Epoch 433/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 11.8808 - mean_absolute_error: 11.8808\n",
      "Epoch 433: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 12ms/step - loss: 13.2680 - mean_absolute_error: 13.2680 - val_loss: 57.7782 - val_mean_absolute_error: 57.7782\n",
      "Epoch 434/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 13.6433 - mean_absolute_error: 13.6433\n",
      "Epoch 434: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.5766 - mean_absolute_error: 13.5766 - val_loss: 57.5914 - val_mean_absolute_error: 57.5914\n",
      "Epoch 435/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 12.9052 - mean_absolute_error: 12.9052\n",
      "Epoch 435: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 12.8385 - mean_absolute_error: 12.8385 - val_loss: 56.9265 - val_mean_absolute_error: 56.9265\n",
      "Epoch 436/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 12.7418 - mean_absolute_error: 12.7418\n",
      "Epoch 436: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 12.7418 - mean_absolute_error: 12.7418 - val_loss: 56.9443 - val_mean_absolute_error: 56.9443\n",
      "Epoch 437/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.9447 - mean_absolute_error: 13.9447\n",
      "Epoch 437: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.9447 - mean_absolute_error: 13.9447 - val_loss: 55.8569 - val_mean_absolute_error: 55.8569\n",
      "Epoch 438/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.8109 - mean_absolute_error: 14.8109\n",
      "Epoch 438: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 14.4735 - mean_absolute_error: 14.4735 - val_loss: 57.2537 - val_mean_absolute_error: 57.2537\n",
      "Epoch 439/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 12.5612 - mean_absolute_error: 12.5612\n",
      "Epoch 439: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 12.8305 - mean_absolute_error: 12.8305 - val_loss: 57.5231 - val_mean_absolute_error: 57.5231\n",
      "Epoch 440/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.7755 - mean_absolute_error: 14.7755\n",
      "Epoch 440: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.9655 - mean_absolute_error: 13.9655 - val_loss: 54.9253 - val_mean_absolute_error: 54.9253\n",
      "Epoch 441/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 13.7994 - mean_absolute_error: 13.7994\n",
      "Epoch 441: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.6885 - mean_absolute_error: 13.6885 - val_loss: 57.2952 - val_mean_absolute_error: 57.2952\n",
      "Epoch 442/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 13.6859 - mean_absolute_error: 13.6859\n",
      "Epoch 442: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 13.4735 - mean_absolute_error: 13.4735 - val_loss: 58.0764 - val_mean_absolute_error: 58.0764\n",
      "Epoch 443/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 15.1666 - mean_absolute_error: 15.1666\n",
      "Epoch 443: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 14.8636 - mean_absolute_error: 14.8636 - val_loss: 57.4044 - val_mean_absolute_error: 57.4044\n",
      "Epoch 444/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 12.0648 - mean_absolute_error: 12.0648\n",
      "Epoch 444: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.6904 - mean_absolute_error: 12.6904 - val_loss: 55.5092 - val_mean_absolute_error: 55.5092\n",
      "Epoch 445/500\n",
      "27/40 [===================>..........] - ETA: 0s - loss: 13.7281 - mean_absolute_error: 13.7281\n",
      "Epoch 445: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 14.5046 - mean_absolute_error: 14.5046 - val_loss: 55.1045 - val_mean_absolute_error: 55.1045\n",
      "Epoch 446/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.3067 - mean_absolute_error: 13.3067\n",
      "Epoch 446: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.1433 - mean_absolute_error: 13.1433 - val_loss: 56.2382 - val_mean_absolute_error: 56.2382\n",
      "Epoch 447/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 14.7895 - mean_absolute_error: 14.7895\n",
      "Epoch 447: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 14.3776 - mean_absolute_error: 14.3776 - val_loss: 57.4900 - val_mean_absolute_error: 57.4900\n",
      "Epoch 448/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 13.3252 - mean_absolute_error: 13.3252\n",
      "Epoch 448: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.4793 - mean_absolute_error: 12.4793 - val_loss: 58.7357 - val_mean_absolute_error: 58.7357\n",
      "Epoch 449/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 13.7531 - mean_absolute_error: 13.7531\n",
      "Epoch 449: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.8211 - mean_absolute_error: 13.8211 - val_loss: 58.9862 - val_mean_absolute_error: 58.9862\n",
      "Epoch 450/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 14.4922 - mean_absolute_error: 14.4922\n",
      "Epoch 450: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 14.3867 - mean_absolute_error: 14.3867 - val_loss: 59.4239 - val_mean_absolute_error: 59.4239\n",
      "Epoch 451/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 14.5872 - mean_absolute_error: 14.5872\n",
      "Epoch 451: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.9783 - mean_absolute_error: 13.9783 - val_loss: 57.5102 - val_mean_absolute_error: 57.5102\n",
      "Epoch 452/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 10.9006 - mean_absolute_error: 10.9006\n",
      "Epoch 452: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.6798 - mean_absolute_error: 13.6798 - val_loss: 57.9150 - val_mean_absolute_error: 57.9150\n",
      "Epoch 453/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.9729 - mean_absolute_error: 13.9729\n",
      "Epoch 453: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.8070 - mean_absolute_error: 13.8070 - val_loss: 57.8328 - val_mean_absolute_error: 57.8328\n",
      "Epoch 454/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 12.9579 - mean_absolute_error: 12.9579\n",
      "Epoch 454: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.9018 - mean_absolute_error: 12.9018 - val_loss: 57.3209 - val_mean_absolute_error: 57.3209\n",
      "Epoch 455/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 14.0962 - mean_absolute_error: 14.0962\n",
      "Epoch 455: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.9027 - mean_absolute_error: 13.9027 - val_loss: 59.0000 - val_mean_absolute_error: 59.0000\n",
      "Epoch 456/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.4555 - mean_absolute_error: 13.4555\n",
      "Epoch 456: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.4737 - mean_absolute_error: 13.4737 - val_loss: 57.4004 - val_mean_absolute_error: 57.4004\n",
      "Epoch 457/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 14.0553 - mean_absolute_error: 14.0553\n",
      "Epoch 457: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.8373 - mean_absolute_error: 13.8373 - val_loss: 57.3432 - val_mean_absolute_error: 57.3432\n",
      "Epoch 458/500\n",
      "27/40 [===================>..........] - ETA: 0s - loss: 11.6904 - mean_absolute_error: 11.6904\n",
      "Epoch 458: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7844 - mean_absolute_error: 12.7844 - val_loss: 56.8800 - val_mean_absolute_error: 56.8800\n",
      "Epoch 459/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 14.3350 - mean_absolute_error: 14.3350\n",
      "Epoch 459: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 14.2207 - mean_absolute_error: 14.2207 - val_loss: 59.2341 - val_mean_absolute_error: 59.2341\n",
      "Epoch 460/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.9082 - mean_absolute_error: 13.9082\n",
      "Epoch 460: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.9082 - mean_absolute_error: 13.9082 - val_loss: 56.8485 - val_mean_absolute_error: 56.8485\n",
      "Epoch 461/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 12.5568 - mean_absolute_error: 12.5568\n",
      "Epoch 461: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 14.4149 - mean_absolute_error: 14.4149 - val_loss: 56.1490 - val_mean_absolute_error: 56.1490\n",
      "Epoch 462/500\n",
      "36/40 [==========================>...] - ETA: 0s - loss: 12.9856 - mean_absolute_error: 12.9856\n",
      "Epoch 462: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.4122 - mean_absolute_error: 13.4122 - val_loss: 57.3927 - val_mean_absolute_error: 57.3927\n",
      "Epoch 463/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 12.9345 - mean_absolute_error: 12.9345\n",
      "Epoch 463: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.9054 - mean_absolute_error: 12.9054 - val_loss: 56.0359 - val_mean_absolute_error: 56.0359\n",
      "Epoch 464/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 13.6431 - mean_absolute_error: 13.6431\n",
      "Epoch 464: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.1134 - mean_absolute_error: 13.1134 - val_loss: 55.7541 - val_mean_absolute_error: 55.7541\n",
      "Epoch 465/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 12.5662 - mean_absolute_error: 12.5662\n",
      "Epoch 465: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.5662 - mean_absolute_error: 12.5662 - val_loss: 57.6378 - val_mean_absolute_error: 57.6378\n",
      "Epoch 466/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 13.5974 - mean_absolute_error: 13.5974\n",
      "Epoch 466: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.8530 - mean_absolute_error: 13.8530 - val_loss: 56.3290 - val_mean_absolute_error: 56.3290\n",
      "Epoch 467/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 12.5984 - mean_absolute_error: 12.5984\n",
      "Epoch 467: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 1s 13ms/step - loss: 12.5984 - mean_absolute_error: 12.5984 - val_loss: 58.0690 - val_mean_absolute_error: 58.0690\n",
      "Epoch 468/500\n",
      "38/40 [===========================>..] - ETA: 0s - loss: 13.5578 - mean_absolute_error: 13.5578\n",
      "Epoch 468: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.3251 - mean_absolute_error: 13.3251 - val_loss: 57.2748 - val_mean_absolute_error: 57.2748\n",
      "Epoch 469/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.5487 - mean_absolute_error: 13.5487\n",
      "Epoch 469: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.5487 - mean_absolute_error: 13.5487 - val_loss: 57.7380 - val_mean_absolute_error: 57.7380\n",
      "Epoch 470/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 14.6582 - mean_absolute_error: 14.6582\n",
      "Epoch 470: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 14.1952 - mean_absolute_error: 14.1952 - val_loss: 55.2840 - val_mean_absolute_error: 55.2840\n",
      "Epoch 471/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 13.4063 - mean_absolute_error: 13.4063\n",
      "Epoch 471: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.0336 - mean_absolute_error: 13.0336 - val_loss: 58.1418 - val_mean_absolute_error: 58.1418\n",
      "Epoch 472/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 13.3156 - mean_absolute_error: 13.3156\n",
      "Epoch 472: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.9593 - mean_absolute_error: 12.9593 - val_loss: 56.5617 - val_mean_absolute_error: 56.5617\n",
      "Epoch 473/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.3735 - mean_absolute_error: 13.3735\n",
      "Epoch 473: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 13.3735 - mean_absolute_error: 13.3735 - val_loss: 56.8859 - val_mean_absolute_error: 56.8859\n",
      "Epoch 474/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 11.5569 - mean_absolute_error: 11.5569\n",
      "Epoch 474: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.8984 - mean_absolute_error: 12.8984 - val_loss: 57.6761 - val_mean_absolute_error: 57.6761\n",
      "Epoch 475/500\n",
      "25/40 [=================>............] - ETA: 0s - loss: 11.9957 - mean_absolute_error: 11.9957\n",
      "Epoch 475: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.0291 - mean_absolute_error: 13.0291 - val_loss: 57.8458 - val_mean_absolute_error: 57.8458\n",
      "Epoch 476/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 12.8144 - mean_absolute_error: 12.8144\n",
      "Epoch 476: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.6493 - mean_absolute_error: 12.6493 - val_loss: 57.8950 - val_mean_absolute_error: 57.8950\n",
      "Epoch 477/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 13.3519 - mean_absolute_error: 13.3519\n",
      "Epoch 477: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7794 - mean_absolute_error: 12.7794 - val_loss: 56.6088 - val_mean_absolute_error: 56.6088\n",
      "Epoch 478/500\n",
      "27/40 [===================>..........] - ETA: 0s - loss: 13.5830 - mean_absolute_error: 13.5830\n",
      "Epoch 478: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.4047 - mean_absolute_error: 12.4047 - val_loss: 57.1684 - val_mean_absolute_error: 57.1684\n",
      "Epoch 479/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 13.4355 - mean_absolute_error: 13.4355\n",
      "Epoch 479: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.1637 - mean_absolute_error: 13.1637 - val_loss: 57.5918 - val_mean_absolute_error: 57.5918\n",
      "Epoch 480/500\n",
      "29/40 [====================>.........] - ETA: 0s - loss: 11.4888 - mean_absolute_error: 11.4888\n",
      "Epoch 480: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.7693 - mean_absolute_error: 12.7693 - val_loss: 55.7233 - val_mean_absolute_error: 55.7233\n",
      "Epoch 481/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 12.0145 - mean_absolute_error: 12.0145\n",
      "Epoch 481: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.1554 - mean_absolute_error: 12.1554 - val_loss: 57.1961 - val_mean_absolute_error: 57.1961\n",
      "Epoch 482/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 13.4000 - mean_absolute_error: 13.4000\n",
      "Epoch 482: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.9542 - mean_absolute_error: 12.9542 - val_loss: 57.4275 - val_mean_absolute_error: 57.4275\n",
      "Epoch 483/500\n",
      "30/40 [=====================>........] - ETA: 0s - loss: 13.3899 - mean_absolute_error: 13.3899\n",
      "Epoch 483: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7781 - mean_absolute_error: 12.7781 - val_loss: 57.8960 - val_mean_absolute_error: 57.8960\n",
      "Epoch 484/500\n",
      "28/40 [====================>.........] - ETA: 0s - loss: 11.7729 - mean_absolute_error: 11.7729\n",
      "Epoch 484: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 14.5064 - mean_absolute_error: 14.5064 - val_loss: 58.1275 - val_mean_absolute_error: 58.1275\n",
      "Epoch 485/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 12.3513 - mean_absolute_error: 12.3513\n",
      "Epoch 485: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.5063 - mean_absolute_error: 13.5063 - val_loss: 57.5824 - val_mean_absolute_error: 57.5824\n",
      "Epoch 486/500\n",
      "33/40 [=======================>......] - ETA: 0s - loss: 13.4878 - mean_absolute_error: 13.4878\n",
      "Epoch 486: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.4450 - mean_absolute_error: 13.4450 - val_loss: 56.5857 - val_mean_absolute_error: 56.5857\n",
      "Epoch 487/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.5600 - mean_absolute_error: 13.5600\n",
      "Epoch 487: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.5623 - mean_absolute_error: 13.5623 - val_loss: 57.6532 - val_mean_absolute_error: 57.6532\n",
      "Epoch 488/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 13.8556 - mean_absolute_error: 13.8556\n",
      "Epoch 488: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.4907 - mean_absolute_error: 13.4907 - val_loss: 55.2619 - val_mean_absolute_error: 55.2619\n",
      "Epoch 489/500\n",
      "26/40 [==================>...........] - ETA: 0s - loss: 11.6452 - mean_absolute_error: 11.6452\n",
      "Epoch 489: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.2716 - mean_absolute_error: 12.2716 - val_loss: 56.4261 - val_mean_absolute_error: 56.4261\n",
      "Epoch 490/500\n",
      "39/40 [============================>.] - ETA: 0s - loss: 13.0233 - mean_absolute_error: 13.0233\n",
      "Epoch 490: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 12.9757 - mean_absolute_error: 12.9757 - val_loss: 58.2767 - val_mean_absolute_error: 58.2767\n",
      "Epoch 491/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 12.6671 - mean_absolute_error: 12.6671\n",
      "Epoch 491: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 12.6671 - mean_absolute_error: 12.6671 - val_loss: 58.5985 - val_mean_absolute_error: 58.5985\n",
      "Epoch 492/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.1528 - mean_absolute_error: 13.1528\n",
      "Epoch 492: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 13.1528 - mean_absolute_error: 13.1528 - val_loss: 59.6484 - val_mean_absolute_error: 59.6484\n",
      "Epoch 493/500\n",
      "31/40 [======================>.......] - ETA: 0s - loss: 12.9019 - mean_absolute_error: 12.9019\n",
      "Epoch 493: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 12.8754 - mean_absolute_error: 12.8754 - val_loss: 58.4773 - val_mean_absolute_error: 58.4773\n",
      "Epoch 494/500\n",
      "40/40 [==============================] - ETA: 0s - loss: 11.8462 - mean_absolute_error: 11.8462\n",
      "Epoch 494: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 11.8462 - mean_absolute_error: 11.8462 - val_loss: 59.0551 - val_mean_absolute_error: 59.0551\n",
      "Epoch 495/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 12.5797 - mean_absolute_error: 12.5797\n",
      "Epoch 495: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.4216 - mean_absolute_error: 12.4216 - val_loss: 57.2785 - val_mean_absolute_error: 57.2785\n",
      "Epoch 496/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 14.2218 - mean_absolute_error: 14.2218\n",
      "Epoch 496: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.9364 - mean_absolute_error: 13.9364 - val_loss: 56.2635 - val_mean_absolute_error: 56.2635\n",
      "Epoch 497/500\n",
      "37/40 [==========================>...] - ETA: 0s - loss: 12.6239 - mean_absolute_error: 12.6239\n",
      "Epoch 497: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.7747 - mean_absolute_error: 12.7747 - val_loss: 55.1178 - val_mean_absolute_error: 55.1178\n",
      "Epoch 498/500\n",
      "35/40 [=========================>....] - ETA: 0s - loss: 11.6460 - mean_absolute_error: 11.6460\n",
      "Epoch 498: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 12.9680 - mean_absolute_error: 12.9680 - val_loss: 57.5902 - val_mean_absolute_error: 57.5902\n",
      "Epoch 499/500\n",
      "32/40 [=======================>......] - ETA: 0s - loss: 12.4756 - mean_absolute_error: 12.4756\n",
      "Epoch 499: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 12.6318 - mean_absolute_error: 12.6318 - val_loss: 56.9226 - val_mean_absolute_error: 56.9226\n",
      "Epoch 500/500\n",
      "34/40 [========================>.....] - ETA: 0s - loss: 13.3289 - mean_absolute_error: 13.3289\n",
      "Epoch 500: val_loss did not improve from 50.37542\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 13.3450 - mean_absolute_error: 13.3450 - val_loss: 57.4991 - val_mean_absolute_error: 57.4991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x132d5891450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(X_train, y_train, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bdec9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wights file of the best model :\n",
    "wights_file = 'Weights-012--50.37542.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03f621cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.33632584e+01],\n",
       "       [ 2.57763977e+01],\n",
       "       [ 1.24536886e+01],\n",
       "       [ 1.02707567e+01],\n",
       "       [ 9.47497177e+01],\n",
       "       [ 8.89441586e+00],\n",
       "       [ 1.76847183e+02],\n",
       "       [ 1.43474233e+00],\n",
       "       [ 1.15040169e+01],\n",
       "       [ 1.88322866e+00],\n",
       "       [ 3.51107521e+01],\n",
       "       [ 2.86823608e+02],\n",
       "       [ 3.10230591e+02],\n",
       "       [ 1.37755716e+00],\n",
       "       [ 3.37032776e+02],\n",
       "       [ 2.30733776e+01],\n",
       "       [ 1.75000412e+02],\n",
       "       [ 7.05648865e+02],\n",
       "       [ 8.70865784e+01],\n",
       "       [ 1.99848783e+00],\n",
       "       [ 3.44419022e+01],\n",
       "       [-9.31786120e-01],\n",
       "       [ 3.36472750e+00],\n",
       "       [ 1.31666880e+01],\n",
       "       [ 4.15328789e+00],\n",
       "       [ 1.87511432e+00],\n",
       "       [ 9.15882528e-01],\n",
       "       [ 4.13325787e+00],\n",
       "       [ 1.71672094e+00],\n",
       "       [ 1.23355888e+02],\n",
       "       [ 4.07270241e+01],\n",
       "       [ 2.66444187e+01],\n",
       "       [ 3.52214470e+01],\n",
       "       [ 5.14102936e+01],\n",
       "       [-1.34368384e+00],\n",
       "       [ 1.21117994e-01],\n",
       "       [ 4.86644058e+01],\n",
       "       [ 2.46498432e+01],\n",
       "       [ 1.09588037e+03],\n",
       "       [ 5.09038210e+00],\n",
       "       [ 2.66035652e+01],\n",
       "       [ 1.97176397e+00],\n",
       "       [ 1.80347061e+01],\n",
       "       [ 1.71353741e+01],\n",
       "       [ 1.87236588e+02],\n",
       "       [ 1.44399595e+01],\n",
       "       [ 5.88320251e+02],\n",
       "       [ 1.18437777e+01],\n",
       "       [ 2.20220518e+00],\n",
       "       [ 1.36986008e+02],\n",
       "       [ 2.85327778e+01],\n",
       "       [ 3.23558350e+01],\n",
       "       [ 3.28291626e+01],\n",
       "       [ 8.14104652e+00],\n",
       "       [ 4.94925916e-01],\n",
       "       [ 2.21984234e+01],\n",
       "       [ 7.02549601e+00],\n",
       "       [ 1.00131502e+01],\n",
       "       [ 4.84335052e+02],\n",
       "       [ 5.12915373e+00],\n",
       "       [ 5.71051931e+00],\n",
       "       [ 5.86431551e+00],\n",
       "       [ 2.47575140e+00],\n",
       "       [-6.68299913e+00],\n",
       "       [ 3.73263397e+02],\n",
       "       [ 3.78182449e+01],\n",
       "       [ 4.06594849e+00],\n",
       "       [ 4.04268694e+00],\n",
       "       [-6.33547354e+00],\n",
       "       [ 3.18979511e+01],\n",
       "       [ 2.83245178e+02],\n",
       "       [ 2.58086510e+01],\n",
       "       [ 9.04322433e+00],\n",
       "       [ 2.12538834e+02],\n",
       "       [ 4.99281931e+00],\n",
       "       [ 6.62657309e+00],\n",
       "       [ 3.02456684e+01],\n",
       "       [ 5.87707937e-01],\n",
       "       [ 1.99896545e+01],\n",
       "       [ 5.22191544e+01],\n",
       "       [ 6.07789192e+01],\n",
       "       [ 3.90116644e+00],\n",
       "       [ 1.60451263e+02],\n",
       "       [ 3.00674103e+02],\n",
       "       [ 4.70664139e+01],\n",
       "       [ 1.56448914e+02],\n",
       "       [ 1.55627375e+01],\n",
       "       [ 2.85828018e+00],\n",
       "       [ 3.82670898e+01],\n",
       "       [ 7.53506517e+00],\n",
       "       [ 3.34367096e+02],\n",
       "       [ 1.27378550e+01],\n",
       "       [ 1.22442268e+02],\n",
       "       [ 7.19890070e+00],\n",
       "       [ 3.75456285e+00],\n",
       "       [ 1.51993692e+00],\n",
       "       [ 4.03618393e+01],\n",
       "       [ 3.64519272e+01],\n",
       "       [ 5.77398717e-01],\n",
       "       [ 6.62128878e+00],\n",
       "       [ 1.16163277e+02],\n",
       "       [ 6.10294762e+01],\n",
       "       [ 2.55128193e+01],\n",
       "       [ 1.81687637e+02],\n",
       "       [ 9.02408524e+01],\n",
       "       [-1.02554953e+00],\n",
       "       [ 9.76919079e+00],\n",
       "       [ 1.88620698e+00],\n",
       "       [ 1.28701267e+01],\n",
       "       [ 1.88192928e+00],\n",
       "       [ 2.41213274e+00],\n",
       "       [-2.69646227e-01],\n",
       "       [ 4.72362614e+00],\n",
       "       [ 8.55690289e+00],\n",
       "       [ 4.30033779e+00],\n",
       "       [ 4.11513290e+01],\n",
       "       [ 2.06201687e+01],\n",
       "       [ 1.17852724e+00],\n",
       "       [ 2.33198746e+02],\n",
       "       [ 1.02976179e+01],\n",
       "       [ 4.57257080e+00],\n",
       "       [-1.24324064e+01],\n",
       "       [ 2.01943073e+01],\n",
       "       [ 6.35624084e+01],\n",
       "       [ 1.33636703e+02],\n",
       "       [ 1.24629784e+01],\n",
       "       [ 3.19494858e+01],\n",
       "       [-1.85892260e+00],\n",
       "       [ 1.95640457e+02],\n",
       "       [ 3.80496292e+01],\n",
       "       [ 8.39932346e+00],\n",
       "       [ 1.00732622e+01],\n",
       "       [-1.07318747e+00],\n",
       "       [ 1.55522146e+01],\n",
       "       [ 8.32136822e+00],\n",
       "       [ 2.42593212e+01],\n",
       "       [ 5.52605057e+01],\n",
       "       [ 2.37343842e+02],\n",
       "       [ 3.91095018e+00],\n",
       "       [ 2.50652943e+01],\n",
       "       [ 4.91919891e+02],\n",
       "       [ 3.90741062e+00],\n",
       "       [ 2.72758884e+01],\n",
       "       [ 2.21358891e+01],\n",
       "       [-7.10669184e+00],\n",
       "       [ 5.08048676e+02],\n",
       "       [ 3.46701393e+01],\n",
       "       [ 1.09416618e+02],\n",
       "       [ 2.68721151e+00],\n",
       "       [ 5.92826614e+01],\n",
       "       [-4.80679893e+00],\n",
       "       [ 4.56046200e+00],\n",
       "       [ 5.01352310e+00],\n",
       "       [ 1.39049375e+00],\n",
       "       [ 7.63417661e-01],\n",
       "       [ 7.32391787e+00],\n",
       "       [ 1.25085821e+01],\n",
       "       [ 5.14178693e-01],\n",
       "       [ 3.95744263e+02],\n",
       "       [ 2.49712563e+01],\n",
       "       [ 1.26401746e+00],\n",
       "       [ 7.30364304e+01],\n",
       "       [ 4.94993935e+01],\n",
       "       [ 1.74035871e+00],\n",
       "       [ 2.51785870e+01],\n",
       "       [ 2.10412693e+00],\n",
       "       [ 2.03206015e+00],\n",
       "       [ 2.85921726e+01],\n",
       "       [ 5.39766729e-01],\n",
       "       [ 1.59472151e+01],\n",
       "       [-5.78619308e+01],\n",
       "       [ 7.93656845e+01],\n",
       "       [-6.37852252e-01],\n",
       "       [ 9.16515768e-01],\n",
       "       [ 9.01061249e+00],\n",
       "       [ 4.83906317e+00],\n",
       "       [ 8.23571396e+00],\n",
       "       [ 1.33923852e+00],\n",
       "       [-3.78294802e+00],\n",
       "       [ 1.78455105e+01],\n",
       "       [ 2.33045197e+01],\n",
       "       [ 3.02805573e+02],\n",
       "       [ 6.26304960e+00],\n",
       "       [ 2.18154812e+01],\n",
       "       [ 1.36945124e+01],\n",
       "       [ 1.32024246e+02],\n",
       "       [ 2.34969234e+01],\n",
       "       [ 5.04356098e+00],\n",
       "       [ 2.52521477e+01],\n",
       "       [-7.10570574e+00],\n",
       "       [ 6.36354399e+00],\n",
       "       [ 4.26315308e+00],\n",
       "       [ 1.09427042e+01],\n",
       "       [-9.93003428e-01],\n",
       "       [ 1.25825202e+00],\n",
       "       [ 7.09538984e+00],\n",
       "       [ 1.89446350e+02],\n",
       "       [ 2.10327101e+00],\n",
       "       [ 4.07019501e+01],\n",
       "       [ 2.83820095e+01],\n",
       "       [ 4.61502304e+01],\n",
       "       [ 1.71869202e+01],\n",
       "       [ 2.25174194e+02],\n",
       "       [ 7.64587927e+00],\n",
       "       [-1.32881422e+01],\n",
       "       [ 4.71834259e+02],\n",
       "       [ 1.17940931e+01],\n",
       "       [-4.24896479e+00],\n",
       "       [ 9.05405235e+00],\n",
       "       [-2.92288446e+00],\n",
       "       [ 2.59703827e+02],\n",
       "       [ 6.43027878e+01],\n",
       "       [ 9.10011368e+01],\n",
       "       [ 3.76952744e+00],\n",
       "       [ 9.03053284e+00],\n",
       "       [-2.26114101e+01],\n",
       "       [-3.70588839e-01],\n",
       "       [ 2.55141006e+02],\n",
       "       [ 2.88852940e+01],\n",
       "       [ 2.53773880e+00],\n",
       "       [ 2.50107971e+02],\n",
       "       [ 1.79905069e+00],\n",
       "       [ 6.38792267e+01],\n",
       "       [ 3.09612691e-01],\n",
       "       [ 5.23255777e+00],\n",
       "       [ 2.92657070e+01],\n",
       "       [ 7.83127642e+00],\n",
       "       [ 8.99075925e-01],\n",
       "       [ 2.61618757e+00],\n",
       "       [ 2.63044977e+00],\n",
       "       [ 1.52942400e+01],\n",
       "       [ 1.71327438e+02],\n",
       "       [-1.58314097e+00],\n",
       "       [ 2.20176563e+01],\n",
       "       [ 1.77520978e+00],\n",
       "       [ 3.13880157e+00],\n",
       "       [ 9.36397266e+00],\n",
       "       [-8.63910007e+00],\n",
       "       [ 2.52979696e-01],\n",
       "       [ 1.77175766e+02],\n",
       "       [ 1.91484487e+00],\n",
       "       [ 2.68075705e+00],\n",
       "       [ 7.04683352e+00],\n",
       "       [ 5.86135406e+01],\n",
       "       [ 2.17518559e+01],\n",
       "       [ 9.58018208e+00],\n",
       "       [ 4.12274094e+01],\n",
       "       [ 2.24767818e+01],\n",
       "       [ 3.79193954e+01],\n",
       "       [ 1.92022610e+01],\n",
       "       [ 2.33295870e+00],\n",
       "       [ 6.84619370e+01],\n",
       "       [ 1.51146162e+00],\n",
       "       [ 4.36066055e+01],\n",
       "       [-4.95302505e+01],\n",
       "       [ 1.05178583e+00],\n",
       "       [ 2.83144257e+02],\n",
       "       [ 9.47577894e-01],\n",
       "       [ 4.93798828e+01],\n",
       "       [ 1.06807337e+01],\n",
       "       [-1.81527689e-01],\n",
       "       [ 9.69753036e+01],\n",
       "       [ 3.36252213e+01],\n",
       "       [ 6.78801575e+01],\n",
       "       [ 1.12542760e+00],\n",
       "       [ 4.26885509e+00],\n",
       "       [ 3.06168175e+00],\n",
       "       [ 1.79180679e+01],\n",
       "       [ 1.07388016e+02],\n",
       "       [ 1.39765775e+00],\n",
       "       [ 7.34963913e+01],\n",
       "       [ 6.27817535e+00],\n",
       "       [ 2.81901741e+00],\n",
       "       [ 3.91259689e+01],\n",
       "       [ 3.37261505e+01],\n",
       "       [ 3.40853653e+01],\n",
       "       [ 3.55340500e+01],\n",
       "       [ 3.86484861e+00],\n",
       "       [ 1.69272316e+00],\n",
       "       [-3.73238602e+01],\n",
       "       [ 3.72144356e+01],\n",
       "       [ 3.36274433e+00],\n",
       "       [ 8.17198181e+01],\n",
       "       [-2.77255297e+00],\n",
       "       [-1.79705584e+00],\n",
       "       [ 2.92866087e+00],\n",
       "       [ 1.96834469e+01],\n",
       "       [ 1.99257832e+01],\n",
       "       [ 7.15103579e+00],\n",
       "       [ 2.24330017e+02],\n",
       "       [ 5.14779129e+01],\n",
       "       [ 7.43676805e+00],\n",
       "       [ 8.58097970e-01],\n",
       "       [ 1.63567104e+01],\n",
       "       [ 7.61676252e-01],\n",
       "       [-2.53023958e+00],\n",
       "       [ 2.41504612e+01],\n",
       "       [-6.48259699e-01],\n",
       "       [ 1.94704711e+00],\n",
       "       [ 1.60656033e+01],\n",
       "       [ 1.43634491e+02],\n",
       "       [ 1.46629560e+00],\n",
       "       [ 2.45677614e+00],\n",
       "       [ 1.15396873e+02],\n",
       "       [ 9.99617481e+00],\n",
       "       [ 1.66341034e+02],\n",
       "       [ 6.08180923e+01],\n",
       "       [ 4.08842564e+00],\n",
       "       [ 6.33063078e+00],\n",
       "       [ 5.47998390e+01],\n",
       "       [-1.60111487e+00],\n",
       "       [ 2.78781281e+02],\n",
       "       [ 3.32474001e-02],\n",
       "       [ 1.45143242e+01],\n",
       "       [ 6.20053577e+00],\n",
       "       [ 5.36783752e+01],\n",
       "       [ 2.87703278e+02],\n",
       "       [ 5.77160788e+00],\n",
       "       [ 3.28923874e+01],\n",
       "       [ 3.36745834e+01],\n",
       "       [ 5.61745644e+00],\n",
       "       [ 6.55293608e+00],\n",
       "       [-2.75939608e+00],\n",
       "       [ 1.20472183e+01],\n",
       "       [ 4.22972931e+02],\n",
       "       [ 5.26711731e+02],\n",
       "       [ 7.15282393e+00],\n",
       "       [ 3.78726044e+01],\n",
       "       [-6.04160213e+00],\n",
       "       [ 2.33266907e+02],\n",
       "       [ 2.29231310e+00],\n",
       "       [ 3.43832207e+01],\n",
       "       [ 1.24530160e+00],\n",
       "       [ 3.53818817e+01],\n",
       "       [ 1.95336092e+00],\n",
       "       [ 1.42080612e+01],\n",
       "       [ 3.85531235e+00],\n",
       "       [ 3.67602631e+02],\n",
       "       [ 1.91373098e+00],\n",
       "       [ 8.28978348e+01],\n",
       "       [ 3.00189266e+01],\n",
       "       [ 8.92863941e+00],\n",
       "       [ 8.06726170e+00],\n",
       "       [ 7.80488968e+01],\n",
       "       [ 1.01743309e+02],\n",
       "       [ 3.57316971e+00],\n",
       "       [ 1.91337234e+02],\n",
       "       [ 7.38404691e-01],\n",
       "       [ 2.40217300e+02],\n",
       "       [ 4.29385681e+01],\n",
       "       [ 3.96911383e+00],\n",
       "       [ 1.54078329e+00],\n",
       "       [ 6.89450407e+00],\n",
       "       [ 8.93189850e+01],\n",
       "       [ 1.81956528e+02],\n",
       "       [-3.07689250e-01],\n",
       "       [ 5.80481291e+00],\n",
       "       [ 3.66949997e+01],\n",
       "       [ 1.79221857e+00],\n",
       "       [ 4.12302933e+01],\n",
       "       [ 3.91933044e+02],\n",
       "       [ 4.03918028e+00],\n",
       "       [ 1.47095165e+01],\n",
       "       [ 2.84239960e+00],\n",
       "       [ 1.57196741e+01],\n",
       "       [ 1.51908356e+02],\n",
       "       [ 6.51090860e+00],\n",
       "       [-7.07784271e+00],\n",
       "       [ 3.71545219e+00],\n",
       "       [ 5.04614441e+02],\n",
       "       [ 5.76739645e+00],\n",
       "       [ 5.49482765e+01],\n",
       "       [ 2.28102665e+01],\n",
       "       [ 1.54494123e+01],\n",
       "       [ 2.15884972e+00],\n",
       "       [ 4.25500793e+01],\n",
       "       [ 1.64539322e+02],\n",
       "       [-1.56130660e+00],\n",
       "       [ 3.46686745e+01],\n",
       "       [ 2.44449472e+00],\n",
       "       [ 5.20994282e+00],\n",
       "       [ 2.59953995e+01],\n",
       "       [ 8.73134079e+01],\n",
       "       [ 7.00914383e+01],\n",
       "       [ 2.17565346e+00],\n",
       "       [ 9.40386429e+01],\n",
       "       [ 4.23368912e+01],\n",
       "       [ 4.03045258e+02],\n",
       "       [ 3.92341232e+01],\n",
       "       [ 5.57219887e+00],\n",
       "       [ 1.59626226e+01],\n",
       "       [ 3.14415771e+02],\n",
       "       [ 1.26346107e+02],\n",
       "       [ 1.71767288e+02],\n",
       "       [ 2.42225742e+01],\n",
       "       [ 7.97405100e+00],\n",
       "       [ 2.97773552e+00],\n",
       "       [ 3.80790939e+01],\n",
       "       [ 2.82887974e+01],\n",
       "       [ 2.56094723e+01],\n",
       "       [ 1.59730484e+02]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = NN_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b44fc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.972583251524522, 56.37715002173767, 0.8588191966761305)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0802ad27",
   "metadata": {},
   "source": [
    "## KNN Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d390a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=3)\n",
    "knn_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72d8ad02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.10000000e+01],\n",
       "       [2.30000000e+01],\n",
       "       [1.03333333e+01],\n",
       "       [1.53333333e+01],\n",
       "       [1.07333333e+02],\n",
       "       [9.66666667e+00],\n",
       "       [1.06000000e+02],\n",
       "       [6.66666667e-01],\n",
       "       [1.33333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [3.13333333e+01],\n",
       "       [4.01666667e+02],\n",
       "       [2.91666667e+02],\n",
       "       [0.00000000e+00],\n",
       "       [3.43000000e+02],\n",
       "       [6.33333333e+00],\n",
       "       [1.59666667e+02],\n",
       "       [6.32333333e+02],\n",
       "       [8.23333333e+01],\n",
       "       [1.26666667e+01],\n",
       "       [3.46666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [2.33333333e+00],\n",
       "       [1.00000000e+01],\n",
       "       [1.66666667e+00],\n",
       "       [1.33333333e+00],\n",
       "       [0.00000000e+00],\n",
       "       [5.00000000e+00],\n",
       "       [1.33333333e+00],\n",
       "       [1.17333333e+02],\n",
       "       [3.63333333e+01],\n",
       "       [1.43333333e+01],\n",
       "       [1.56666667e+01],\n",
       "       [3.46666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [3.56666667e+01],\n",
       "       [1.30000000e+01],\n",
       "       [9.81666667e+02],\n",
       "       [2.66666667e+00],\n",
       "       [1.03333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [8.66666667e+00],\n",
       "       [2.00000000e+01],\n",
       "       [1.63333333e+02],\n",
       "       [2.60000000e+01],\n",
       "       [7.03333333e+02],\n",
       "       [1.30000000e+01],\n",
       "       [1.83333333e+01],\n",
       "       [1.27000000e+02],\n",
       "       [1.76666667e+01],\n",
       "       [2.70000000e+01],\n",
       "       [3.50000000e+01],\n",
       "       [1.06666667e+01],\n",
       "       [3.33333333e-01],\n",
       "       [2.30000000e+01],\n",
       "       [4.00000000e+00],\n",
       "       [3.00000000e+00],\n",
       "       [5.40666667e+02],\n",
       "       [5.66666667e+00],\n",
       "       [1.00000000e+00],\n",
       "       [3.66666667e+00],\n",
       "       [3.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [4.06666667e+02],\n",
       "       [3.96666667e+01],\n",
       "       [3.66666667e+00],\n",
       "       [2.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.60000000e+01],\n",
       "       [2.97666667e+02],\n",
       "       [2.90000000e+01],\n",
       "       [1.10000000e+01],\n",
       "       [3.04333333e+02],\n",
       "       [6.66666667e-01],\n",
       "       [8.33333333e+00],\n",
       "       [6.66666667e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.26666667e+01],\n",
       "       [5.26666667e+01],\n",
       "       [6.63333333e+01],\n",
       "       [3.33333333e+00],\n",
       "       [1.54666667e+02],\n",
       "       [2.96333333e+02],\n",
       "       [6.40000000e+01],\n",
       "       [2.06000000e+02],\n",
       "       [2.40000000e+01],\n",
       "       [1.83333333e+01],\n",
       "       [4.20000000e+01],\n",
       "       [1.10000000e+01],\n",
       "       [2.67333333e+02],\n",
       "       [1.06666667e+01],\n",
       "       [2.00000000e+02],\n",
       "       [4.00000000e+00],\n",
       "       [3.33333333e-01],\n",
       "       [6.66666667e-01],\n",
       "       [3.76666667e+01],\n",
       "       [3.40000000e+01],\n",
       "       [3.33333333e-01],\n",
       "       [5.00000000e+00],\n",
       "       [8.20000000e+01],\n",
       "       [1.36333333e+02],\n",
       "       [8.00000000e+00],\n",
       "       [2.52333333e+02],\n",
       "       [6.80000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [1.36666667e+01],\n",
       "       [3.33333333e-01],\n",
       "       [1.90000000e+01],\n",
       "       [3.33333333e-01],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.33333333e+00],\n",
       "       [6.66666667e+00],\n",
       "       [2.00000000e+00],\n",
       "       [5.80000000e+01],\n",
       "       [1.13333333e+01],\n",
       "       [6.66666667e-01],\n",
       "       [2.69333333e+02],\n",
       "       [5.93333333e+01],\n",
       "       [1.33333333e+00],\n",
       "       [1.66666667e+00],\n",
       "       [2.53333333e+01],\n",
       "       [3.93333333e+01],\n",
       "       [1.02000000e+02],\n",
       "       [4.66666667e+00],\n",
       "       [7.43333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [2.91000000e+02],\n",
       "       [4.20000000e+01],\n",
       "       [3.33333333e+00],\n",
       "       [6.33333333e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.36666667e+01],\n",
       "       [5.66666667e+00],\n",
       "       [9.00000000e+00],\n",
       "       [4.50000000e+01],\n",
       "       [2.19333333e+02],\n",
       "       [3.33333333e+00],\n",
       "       [7.66666667e+00],\n",
       "       [3.82333333e+02],\n",
       "       [2.39333333e+02],\n",
       "       [7.66666667e+00],\n",
       "       [2.03333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [4.71333333e+02],\n",
       "       [7.43333333e+01],\n",
       "       [9.46666667e+01],\n",
       "       [6.66666667e-01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [3.33333333e+00],\n",
       "       [3.00000000e+00],\n",
       "       [3.33333333e-01],\n",
       "       [3.33333333e-01],\n",
       "       [3.66666667e+00],\n",
       "       [8.66666667e+00],\n",
       "       [0.00000000e+00],\n",
       "       [4.03000000e+02],\n",
       "       [1.76666667e+01],\n",
       "       [6.66666667e-01],\n",
       "       [4.70000000e+01],\n",
       "       [4.76666667e+01],\n",
       "       [2.00000000e+00],\n",
       "       [2.83333333e+01],\n",
       "       [1.66666667e+00],\n",
       "       [6.66666667e-01],\n",
       "       [2.03333333e+01],\n",
       "       [3.33333333e-01],\n",
       "       [1.40000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [1.24000000e+02],\n",
       "       [0.00000000e+00],\n",
       "       [6.66666667e-01],\n",
       "       [7.00000000e+00],\n",
       "       [3.33333333e+00],\n",
       "       [9.66666667e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.16666667e+01],\n",
       "       [1.80000000e+01],\n",
       "       [1.65333333e+02],\n",
       "       [1.00000000e+00],\n",
       "       [2.23333333e+01],\n",
       "       [1.53333333e+01],\n",
       "       [1.48666667e+02],\n",
       "       [4.40000000e+01],\n",
       "       [1.33333333e+00],\n",
       "       [1.23333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [3.66666667e+00],\n",
       "       [1.00000000e+00],\n",
       "       [2.36666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [9.00000000e+00],\n",
       "       [2.37666667e+02],\n",
       "       [1.66666667e+00],\n",
       "       [2.93333333e+01],\n",
       "       [2.20000000e+01],\n",
       "       [3.46666667e+01],\n",
       "       [1.60000000e+01],\n",
       "       [2.34333333e+02],\n",
       "       [6.06666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [6.05333333e+02],\n",
       "       [1.83333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [1.60000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [2.56000000e+02],\n",
       "       [7.96666667e+01],\n",
       "       [8.06666667e+01],\n",
       "       [1.33333333e+00],\n",
       "       [5.66666667e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [3.01000000e+02],\n",
       "       [1.43333333e+01],\n",
       "       [6.66666667e-01],\n",
       "       [2.27333333e+02],\n",
       "       [3.33333333e-01],\n",
       "       [6.50000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [3.33333333e+00],\n",
       "       [1.76666667e+01],\n",
       "       [5.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.33333333e+00],\n",
       "       [3.33333333e-01],\n",
       "       [9.00000000e+00],\n",
       "       [1.01666667e+02],\n",
       "       [0.00000000e+00],\n",
       "       [3.43333333e+01],\n",
       "       [1.66666667e+00],\n",
       "       [1.00000000e+00],\n",
       "       [7.33333333e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [1.92666667e+02],\n",
       "       [2.00000000e+00],\n",
       "       [3.33333333e+00],\n",
       "       [7.66666667e+00],\n",
       "       [5.03333333e+01],\n",
       "       [6.00000000e+00],\n",
       "       [1.30000000e+01],\n",
       "       [3.30000000e+01],\n",
       "       [1.96666667e+01],\n",
       "       [2.83333333e+01],\n",
       "       [1.83333333e+01],\n",
       "       [3.00000000e+00],\n",
       "       [7.53333333e+01],\n",
       "       [0.00000000e+00],\n",
       "       [4.40000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.91000000e+02],\n",
       "       [0.00000000e+00],\n",
       "       [6.00000000e+01],\n",
       "       [2.00000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [9.70000000e+01],\n",
       "       [1.96666667e+01],\n",
       "       [5.83333333e+01],\n",
       "       [6.66666667e-01],\n",
       "       [8.00000000e+00],\n",
       "       [6.66666667e-01],\n",
       "       [1.86666667e+01],\n",
       "       [6.76666667e+01],\n",
       "       [3.33333333e-01],\n",
       "       [5.96666667e+01],\n",
       "       [3.00000000e+00],\n",
       "       [1.66666667e+00],\n",
       "       [2.43333333e+01],\n",
       "       [2.56666667e+01],\n",
       "       [2.86666667e+01],\n",
       "       [2.70000000e+01],\n",
       "       [3.33333333e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [2.86666667e+01],\n",
       "       [2.00000000e+00],\n",
       "       [9.30000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [4.03333333e+01],\n",
       "       [1.86666667e+01],\n",
       "       [1.33333333e+00],\n",
       "       [3.45000000e+02],\n",
       "       [6.83333333e+01],\n",
       "       [1.20000000e+01],\n",
       "       [2.00000000e+00],\n",
       "       [2.40000000e+01],\n",
       "       [3.33333333e-01],\n",
       "       [0.00000000e+00],\n",
       "       [2.56666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [6.66666667e-01],\n",
       "       [1.73333333e+01],\n",
       "       [9.60000000e+01],\n",
       "       [0.00000000e+00],\n",
       "       [1.66666667e+00],\n",
       "       [1.58666667e+02],\n",
       "       [1.83333333e+01],\n",
       "       [1.64333333e+02],\n",
       "       [1.01666667e+02],\n",
       "       [1.33333333e+00],\n",
       "       [7.33333333e+00],\n",
       "       [4.36666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [2.38666667e+02],\n",
       "       [0.00000000e+00],\n",
       "       [1.16666667e+01],\n",
       "       [3.00000000e+00],\n",
       "       [5.90000000e+01],\n",
       "       [3.61333333e+02],\n",
       "       [3.66666667e+00],\n",
       "       [3.16666667e+01],\n",
       "       [3.50000000e+01],\n",
       "       [2.66666667e+00],\n",
       "       [1.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [8.00000000e+00],\n",
       "       [3.98333333e+02],\n",
       "       [5.84666667e+02],\n",
       "       [9.33333333e+00],\n",
       "       [2.06666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [3.40666667e+02],\n",
       "       [6.66666667e-01],\n",
       "       [3.10000000e+01],\n",
       "       [6.66666667e-01],\n",
       "       [2.26666667e+01],\n",
       "       [0.00000000e+00],\n",
       "       [2.33333333e+01],\n",
       "       [3.33333333e+00],\n",
       "       [4.73666667e+02],\n",
       "       [0.00000000e+00],\n",
       "       [7.73333333e+01],\n",
       "       [3.10000000e+01],\n",
       "       [1.60000000e+01],\n",
       "       [5.66666667e+00],\n",
       "       [5.36666667e+01],\n",
       "       [6.76666667e+01],\n",
       "       [4.33333333e+00],\n",
       "       [1.96333333e+02],\n",
       "       [0.00000000e+00],\n",
       "       [2.63000000e+02],\n",
       "       [3.20000000e+01],\n",
       "       [6.33333333e+00],\n",
       "       [1.33333333e+00],\n",
       "       [4.00000000e+00],\n",
       "       [7.66666667e+01],\n",
       "       [2.65000000e+02],\n",
       "       [0.00000000e+00],\n",
       "       [3.66666667e+00],\n",
       "       [2.46666667e+01],\n",
       "       [3.33333333e-01],\n",
       "       [3.20000000e+01],\n",
       "       [3.62333333e+02],\n",
       "       [1.00000000e+00],\n",
       "       [1.90000000e+01],\n",
       "       [2.00000000e+00],\n",
       "       [2.33333333e+01],\n",
       "       [1.34333333e+02],\n",
       "       [3.33333333e+00],\n",
       "       [0.00000000e+00],\n",
       "       [5.00000000e+00],\n",
       "       [6.75000000e+02],\n",
       "       [2.33333333e+00],\n",
       "       [4.86666667e+01],\n",
       "       [4.26666667e+01],\n",
       "       [6.00000000e+00],\n",
       "       [6.66666667e-01],\n",
       "       [4.90000000e+01],\n",
       "       [1.74333333e+02],\n",
       "       [0.00000000e+00],\n",
       "       [4.80000000e+01],\n",
       "       [2.00000000e+00],\n",
       "       [1.33333333e+00],\n",
       "       [1.60000000e+01],\n",
       "       [2.40000000e+01],\n",
       "       [4.70000000e+01],\n",
       "       [3.33333333e-01],\n",
       "       [7.06666667e+01],\n",
       "       [4.06666667e+01],\n",
       "       [3.93666667e+02],\n",
       "       [3.83333333e+01],\n",
       "       [2.66666667e+00],\n",
       "       [3.56666667e+01],\n",
       "       [2.55333333e+02],\n",
       "       [1.59666667e+02],\n",
       "       [1.18666667e+02],\n",
       "       [1.46666667e+01],\n",
       "       [9.33333333e+00],\n",
       "       [2.00000000e+00],\n",
       "       [3.76666667e+01],\n",
       "       [1.46666667e+01],\n",
       "       [1.53333333e+01],\n",
       "       [1.44000000e+02]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_reg.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2773caf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26.948462177888608, 66.33341269935978, 0.8045507104730336)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate evaluation metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    " \n",
    "mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c85aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
